{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2658,
     "status": "ok",
     "timestamp": 1593529191823,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "CWWt-S-AGLJe",
    "outputId": "0679798d-9bbd-42f4-be73-9a14e284fc3b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import make_scorer,accuracy_score, precision_score, recall_score,f1_score,confusion_matrix,balanced_accuracy_score\n",
    "from scipy.sparse import csr_matrix,issparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer as Normalizer\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer,PowerTransformer,MinMaxScaler,MaxAbsScaler,RobustScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime \n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.preprocessing import Normalizer as Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2237,
     "status": "ok",
     "timestamp": 1593529234575,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "s9zVCQbzpFAj"
   },
   "outputs": [],
   "source": [
    "\n",
    "df01=pd.read_csv(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\TechCntVctUsnm_D1906.csv',index_col=False)\n",
    "#df01.drop(columns='editor',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1593529238382,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "gQ5iO6Dk5rJ2",
    "outputId": "469ab035-31a9-41b9-8f3b-661bb26912fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edInput</th>\n",
       "      <th>editor</th>\n",
       "      <th>usScName</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>DigitalTrends</td>\n",
       "      <td>By_digitaltrends model crew use driveable tile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>DigitalTrends</td>\n",
       "      <td>By_digitaltrends device feed Oreos without use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>DigitalTrends</td>\n",
       "      <td>By_digitaltrends old version @windows critical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>DigitalTrends</td>\n",
       "      <td>By_digitaltrends UK intelligent agency want tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>DigitalTrends</td>\n",
       "      <td>By_digitaltrends Cleaning pet get easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>DigitalTrends</td>\n",
       "      <td>By_digitaltrends Curiosity rover find evidence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>DigitalTrends</td>\n",
       "      <td>By_digitaltrends room build lego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>DigitalTrends</td>\n",
       "      <td>By_digitaltrends robot play pet go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>Ronald_vanLoon</td>\n",
       "      <td>By_ronald_vanloon #userexperience #ux heart #d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5007</td>\n",
       "      <td>Ronald_vanLoon</td>\n",
       "      <td>By_ronald_vanloon Describe understand bayesian...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edInput  editor        usScName  \\\n",
       "0        1    5007   DigitalTrends   \n",
       "1        1    5007   DigitalTrends   \n",
       "2        1    5007   DigitalTrends   \n",
       "3        1    5007   DigitalTrends   \n",
       "4        1    5007   DigitalTrends   \n",
       "5        1    5007   DigitalTrends   \n",
       "6        1    5007   DigitalTrends   \n",
       "7        1    5007   DigitalTrends   \n",
       "8        1    5007  Ronald_vanLoon   \n",
       "9        1    5007  Ronald_vanLoon   \n",
       "\n",
       "                                                text  \n",
       "0  By_digitaltrends model crew use driveable tile...  \n",
       "1  By_digitaltrends device feed Oreos without use...  \n",
       "2  By_digitaltrends old version @windows critical...  \n",
       "3  By_digitaltrends UK intelligent agency want tr...  \n",
       "4             By_digitaltrends Cleaning pet get easy  \n",
       "5  By_digitaltrends Curiosity rover find evidence...  \n",
       "6                   By_digitaltrends room build lego  \n",
       "7                 By_digitaltrends robot play pet go  \n",
       "8  By_ronald_vanloon #userexperience #ux heart #d...  \n",
       "9  By_ronald_vanloon Describe understand bayesian...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1593529243603,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "gTQcFOFWDLyu"
   },
   "outputs": [],
   "source": [
    "SEED=7\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1593529247796,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "ZkAndDcD5src"
   },
   "outputs": [],
   "source": [
    "y_vect=np.array(df01.edInput)\n",
    "text_vect=np.array(df01.text[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1593529249879,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "CGTuGltQ59BV"
   },
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_all, y_test =train_test_split(text_vect,\n",
    "            y_vect,random_state=SEED,test_size=0.1,stratify=y_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1593529253073,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "y97BnumawDnv",
    "outputId": "75ba14ce-16d9-4aee-fe5f-f02e2699059f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2643,
     "status": "ok",
     "timestamp": 1593529257511,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "6EHZ5xGZ6AFD",
    "outputId": "df2b753d-134c-40a3-e3ae-000ec3ab63dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12951, 14000) (1439, 14000)\n"
     ]
    }
   ],
   "source": [
    "#Use count vectorizer then tfid\n",
    "#!!!!!!!!! we can add a column with a flag value that shows the tweet has pic or video into word vector\n",
    "\n",
    "lemma_vect =  CountVectorizer(tokenizer=None,token_pattern='\\S+',\n",
    "                             min_df=1,lowercase=False,stop_words=None,ngram_range=(1,5),max_features=14000)\n",
    "X_train=lemma_vect.fit_transform(X_train_raw)\n",
    "X_test=lemma_vect.transform(X_test_raw)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 357504,
     "status": "ok",
     "timestamp": 1593529618194,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "V4lbSxrf3nXO",
    "outputId": "0610b23b-68ec-4939-b0a9-844e42f747c2"
   },
   "source": [
    "svd= TruncatedSVD(n_components=5000)\n",
    "\n",
    "\n",
    "X_train_rd = svd.fit_transform(X_train_tmp)\n",
    "X_test_rd = svd.transform(X_test_tmp)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "feature_names=lemma_vect.get_feature_names()\n",
    "best_features = [feature_names[i] for i in svd.components_[0].argsort()[::-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 835,
     "status": "ok",
     "timestamp": 1593529690410,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "2T3OI-ZPLP7Y",
    "outputId": "048b2ec1-ed99-4887-b788-44ffae028f00"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5ea175783ecc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJgYA8kT6E2x"
   },
   "outputs": [],
   "source": [
    "#X_train1, X_val, y_train, y_val = train_test_split(X_train, y_train_all, test_size=0.1,stratify=y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 694,
     "status": "ok",
     "timestamp": 1593529694312,
     "user": {
      "displayName": "tekin yavuz",
      "photoUrl": "",
      "userId": "13253690195323552980"
     },
     "user_tz": 240
    },
    "id": "oA32-RC46H7U"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "del text_vect\n",
    "del df01\n",
    "del y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    spcfc= confusion_matrix(y_true, y_pred)[0,0]/(confusion_matrix(y_true,y_pred)[0,0] + confusion_matrix(y_true, y_pred)[0,1])\n",
    "    return spcfc\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "FeatureRD=TruncatedSVD(n_components=1500)\n",
    "quantile=QuantileTransformer(output_distribution='uniform')\n",
    "powertr= PowerTransformer(method='yeo-johnson')\n",
    "myscoring = {'accuracy' : make_scorer(accuracy_score),\n",
    "             'balanced_acc': make_scorer(balanced_accuracy_score),\n",
    "             'specificity' : make_scorer(specificity),  \n",
    "           'precision' : make_scorer( precision_score),\n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "            'tp': make_scorer(tp), 'tn': make_scorer(tn),\n",
    "            'fp': make_scorer(fp), 'fn': make_scorer(fn)}\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TweetVect(CountVectorizer):\n",
    "    def __init__(self,max_features=700,ngram_range=(1,3),tokenizer=None,token_pattern='\\S+',min_df=1,lowercase=False,stop_words=None):\n",
    "        super().__init__(tokenizer=None,token_pattern='\\S+',\\\n",
    "                    min_df=1,lowercase=False,stop_words=None,ngram_range=ngram_range,max_features=max_features)\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fit_transform(X)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "         return super().fit_transform(X).toarray()\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        return super().transform(X).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed: 46.2min\n",
      "[Parallel(n_jobs=2)]: Done 361 tasks      | elapsed: 187.9min\n",
      "[Parallel(n_jobs=2)]: Done 600 out of 600 | elapsed: 382.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params with lemma:\n",
      "{'classifier': LinearSVC(C=0.01, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=3000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0), 'classifier__C': 0.01, 'prep': MinMaxScaler(copy=True, feature_range=(0, 1)), 'vect__max_features': 7000, 'vect__ngram_range': (1, 5)}\n",
      "\n",
      "Best cross-validation score with lemma: 0.78602\n",
      "Test-set score with lemma: 0.76361\n",
      "Best specificty: 0.72956\n",
      "Best balanced accuracy: 0.76361\n",
      "Best precision: 0.95959\n",
      "Best f1_score: 0.87116\n",
      "[[ 116   43]\n",
      " [ 259 1021]]\n",
      "116 43 259 1021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv2 = StratifiedShuffleSplit(n_splits=5, test_size=0.1,train_size=0.9, random_state=SEED) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeonl = Pipeline([('vect',TweetVect()),('prep', MinMaxScaler()),\n",
    "                     ('classifier',LinearSVC(class_weight = 'balanced', max_iter=3000))\n",
    "                   ])\n",
    "\n",
    "param_one = [{  'vect__ngram_range': [(1, 5)]\n",
    "                 ,'vect__max_features': [150,300,450,700,1500,2500,3500,5000]\n",
    "                 ,'prep': [MinMaxScaler(),StandardScaler(with_mean=False),powertr,MaxAbsScaler()] \n",
    "                 ,'classifier': [LinearSVC(class_weight = 'balanced', max_iter=3000)] \n",
    "                 ,'classifier__C': [0.001,0.01, 0.1, 1, 10, 100]\n",
    "                  }]\n",
    "\n",
    "\n",
    "\n",
    "gridone = GridSearchCV(pipeonl, param_one, cv=cv2,scoring=myscoring,refit='balanced_acc',verbose=2,n_jobs=2)\n",
    "gridone.fit(X_train_raw, y_train_all)\n",
    "best_mdlone = gridone.best_estimator_\n",
    "\n",
    "print(\"Best params with lemma:\\n{}\\n\".format(gridone.best_params_))\n",
    "print(\"Best cross-validation score with lemma: {:.5f}\".format(gridone.best_score_))\n",
    "print(\"Test-set score with lemma: {:.5f}\".format(gridone.score(X_test_raw, y_test)))\n",
    "y_pred = best_mdlone.predict(X_test_raw)\n",
    "print(\"Best specificty: {:.5f}\".format(specificity(y_test,y_pred)))\n",
    "print(\"Best balanced accuracy: {:.5f}\".format(balanced_accuracy_score(y_test,y_pred)))\n",
    "print(\"Best precision: {:.5f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Best f1_score: {:.5f}\".format(f1_score(y_test,y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(tn,fp,fn,tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(gridone.cv_results_)\n",
    "df.to_csv(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\Results\\gridspcfcRnPC_400to700_5000to9000_D1906.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM with probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pipeline for production use joblib or pickle to dump that pipelin without Model; check this method works\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train,X_test,y_train,y_test = make_my_dataset()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect',CountVectorizer()),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('clf',LinearSVC())\n",
    "])\n",
    "\n",
    "# Instead of 'just' fitting the pipeline on the training\n",
    "# data, do cross-validation too so that you know if it's\n",
    "# overfitting.\n",
    "# This returns an array of values, each having the score \n",
    "# for an individual run.\n",
    "# - cv=3 means that we're doing 3-fold cross validation\n",
    "# - You can select any metric to score your pipeline\n",
    "scores = cross_val_scores(pipeline,X_train,y_train,cv=3,\n",
    "    scoring='f1_micro')\n",
    "\n",
    "#https://amueller.github.io/COMS4995-s18/slides/aml-13-022818-resampling-imbalanced-data/#9\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "scores = cross_validate(LogisticRegression(),\n",
    "                        X_train, y_train, cv=10, scoring=('roc_auc', 'average_precision'))\n",
    "scores['test_roc_auc'].mean(), scores['test_average_precision'].mean()\n",
    "\n",
    "# with the information above, you can be more \n",
    "# comfortable to train on the whole dataset\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "y_preds = pipeline.predict(x_test)\n",
    "\n",
    "mean_f1 = f1_score(y_test, y_preds, average='micro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if input vector X is sparse then use Standardscaler(mean=False)\n",
    "pipe = Pipeline([('svd', FeatureRD),('prep', StandardScaler()),('classifier', LinearSVC(class_weight = 'balanced'))])\n",
    "\n",
    "param_grid = [\n",
    "\n",
    "                {'svd__n_components':[400,750,1500,2500,5000]\n",
    "                 ,'classifier': [LinearSVC(class_weight = 'balanced')] \n",
    "                 ,'classifier__C': [0.01, 0.1, 1, 10, 100]\n",
    "                 ,'prep': [StandardScaler(),MinMaxScaler(),powertr]\n",
    "                 \n",
    "                 \n",
    "                }\n",
    "\n",
    "             ]\n",
    "cv2 = StratifiedShuffleSplit(n_splits=5, test_size=0.1,train_size=0.9, random_state=SEED) \n",
    "gridlnr = GridSearchCV(pipe, param_grid, cv=cv2,scoring=myscoring,refit='accuracy',verbose=2,n_jobs=2)\n",
    "gridlnr.fit(X_train, y_train_all)\n",
    "best_model = gridlnr.best_estimator_\n",
    "print(\"Best params with lemma:\\n{}\\n\".format(gridlnr.best_params_))\n",
    "print(\"Best cross-validation score with lemma: {:.2f}\".format(gridlnr.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "piperbf = Pipeline([('svd', FeatureRD),('prep', StandardScaler()),('classifier', SVC(class_weight = 'balanced'))])\n",
    "\n",
    "param_gridrbf = [\n",
    "\n",
    "                {'classifier': [SVC(class_weight = 'balanced')] \n",
    "                 ,'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "                 ,'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "                 ,'prep': [StandardScaler(),MinMaxScaler(),powertr,None]\n",
    "                 ,'svd__n_components':[200,400,750,1500,2500,5000]\n",
    "                 \n",
    "                }\n",
    "\n",
    "             ]\n",
    "\n",
    "gridrbf = GridSearchCV(piperbf, param_gridrbf, cv=cv2,scoring=myscoring,refit='accuracy',verbose=1,n_jobs=2)\n",
    "gridrbf.fit(X_train, y_train_all)\n",
    "best_model = gridrbf.best_estimator_\n",
    "print(\"Best params with lemma:\\n{}\\n\".format(gridrbf.best_params_))\n",
    "print(\"Best cross-validation score with lemma: {:.2f}\".format(gridrbf.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fnl=gridrbf.transform(X_test)\n",
    "print(\"Test-set score with lemma: {:.2f}\".format(gridrbf.score(X_test, y_test)))\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Best specificity: {:.5f}\".format(specificity(y_test,y_pred)))\n",
    "print(\"Best accuracy: {:.5f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Best precision: {:.5f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Best f1_score: {:.5f}\".format(f1_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:  7.3min finished\n",
      "c:\\users\\tekin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params with lemma:\n",
      "{'classifier': LinearSVC(C=10, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0), 'classifier__C': 10, 'prep': MinMaxScaler(copy=True, feature_range=(0, 1)), 'svd__n_components': 1500}\n",
      "\n",
      "Best cross-validation score with lemma: 0.85833\n",
      "Test-set score with lemma: 0.85962\n",
      "Best test specificty: 0.43396\n",
      "Best test accuracy: 0.85962\n",
      "Best test balanced accuracy: 0.67323\n",
      "Best test precision: 0.92846\n",
      "Best test f1_score: 0.92041\n"
     ]
    }
   ],
   "source": [
    "lemma_vect =  CountVectorizer(tokenizer=None,token_pattern='\\S+',\n",
    "                             min_df=1,lowercase=False,stop_words=None,ngram_range=(1,4),max_features=14000)\n",
    "X_train=lemma_vect.fit_transform(X_train_raw)\n",
    "X_test=lemma_vect.transform(X_test_raw)\n",
    "\n",
    "pipetwo = Pipeline([('svd', FeatureRD),('prep', MinMaxScaler()),\n",
    "                     ('classifier',LinearSVC(class_weight = 'balanced'))\n",
    "                   ])\n",
    "\n",
    "param_two = [{ 'classifier': [LinearSVC(class_weight = 'balanced')] \n",
    "                 ,'classifier__C': [10]\n",
    "                 ,'svd__n_components':[1500]\n",
    "                 ,'prep': [MinMaxScaler(),StandardScaler()] }]\n",
    "\n",
    "\n",
    "\n",
    "gridtwo = GridSearchCV(pipetwo, param_two, cv=cv2,scoring=myscoring,refit='balanced_acc',verbose=2,n_jobs=2)\n",
    "gridtwo.fit(X_train, y_train_all)\n",
    "best_mdltwo = gridtwo.best_estimator_\n",
    "\n",
    "print(\"Best params with lemma:\\n{}\\n\".format(gridtwo.best_params_))\n",
    "print(\"Best cross-validation score with lemma: {:.5f}\".format(gridtwo.best_score_))\n",
    "print(\"Test-set score with lemma: {:.5f}\".format(gridtwo.score(X_test, y_test)))\n",
    "y_pred = best_mdltwo.predict(X_test)\n",
    "print(\"Best test specificty: {:.5f}\".format(specificity(y_test,y_pred)))\n",
    "print(\"Best test accuracy: {:.5f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Best test balanced accuracy: {:.5f}\".format(balanced_accuracy_score(y_test,y_pred)))\n",
    "print(\"Best test precision: {:.5f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Best test f1_score: {:.5f}\".format(f1_score(y_test,y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMNGUzozLHIoS5eXUUjF6jO",
   "collapsed_sections": [],
   "name": "MlpGridsrc.ipynb",
   "provenance": [
    {
     "file_id": "1y8LAw3Jz2Qs7hLUa0cOotzT6x6b9Usn_",
     "timestamp": 1593473706717
    },
    {
     "file_id": "1fyCxe4QDXo_hOlU9hCsVk4aBl0UwRQ52",
     "timestamp": 1593430661864
    },
    {
     "file_id": "1fuG1L-OtSzPRE40u4WMs93-aR6ZX2FVl",
     "timestamp": 1591257790043
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
