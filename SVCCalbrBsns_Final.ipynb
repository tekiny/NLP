{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import make_scorer,accuracy_score, precision_score, recall_score,f1_score,confusion_matrix,balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.calibration import CalibratedClassifierCV as SVCclbr\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "#from TweetVect import TweetVect\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer,PowerTransformer,MinMaxScaler,MaxAbsScaler,RobustScaler\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edInput</th>\n",
       "      <th>editor</th>\n",
       "      <th>usScName</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>business</td>\n",
       "      <td>By_business state link Chinese hack group use malware steal sms text message high rank military government target accord cybersecurity company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>Inc</td>\n",
       "      <td>By_inc Developing empathy compassion daily habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>BW</td>\n",
       "      <td>By_bw argentine startup want build better bee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>business</td>\n",
       "      <td>By_business South Korean export fall 11th straight month October global trade gloom persist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>business</td>\n",
       "      <td>By_business Oil set weekly drop rise Saudi output trade woe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>Inc</td>\n",
       "      <td>By_inc Hiring hard way find identify true star employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>business</td>\n",
       "      <td>By_business Qantas ground three Boeing 737 jet find crack near wing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>HarvardBiz</td>\n",
       "      <td>By_harvardbiz true believer power democratic politic make big important change want play personal role that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>Inc</td>\n",
       "      <td>By_inc New research prove kill make strong really true @mindazetlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5004</td>\n",
       "      <td>HarvardBiz</td>\n",
       "      <td>By_harvardbiz female lead company get early funding world would better off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edInput  editor    usScName                                                                                                                                            text\n",
       "0  1        5004    business    By_business state link Chinese hack group use malware steal sms text message high rank military government target accord cybersecurity company\n",
       "1  1        5004    Inc         By_inc Developing empathy compassion daily habit                                                                                              \n",
       "2  1        5004    BW          By_bw argentine startup want build better bee                                                                                                 \n",
       "3  1        5004    business    By_business South Korean export fall 11th straight month October global trade gloom persist                                                   \n",
       "4  1        5004    business    By_business Oil set weekly drop rise Saudi output trade woe                                                                                   \n",
       "5  1        5004    Inc         By_inc Hiring hard way find identify true star employee                                                                                       \n",
       "6  1        5004    business    By_business Qantas ground three Boeing 737 jet find crack near wing                                                                           \n",
       "7  1        5004    HarvardBiz  By_harvardbiz true believer power democratic politic make big important change want play personal role that                                   \n",
       "8  1        5004    Inc         By_inc New research prove kill make strong really true @mindazetlin                                                                           \n",
       "9  1        5004    HarvardBiz  By_harvardbiz female lead company get early funding world would better off                                                                    "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 3000)\n",
    "df01=pd.read_csv(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\BsnsCntVctUsnm_D1911.csv',index_col=False)\n",
    "df01.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=7\n",
    "np.random.seed(SEED)\n",
    "y_vect=np.array(df01.edInput)\n",
    "text_vect=np.array(df01.text[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(text_vect,\n",
    "            y_vect,random_state=SEED,test_size=0.1,stratify=y_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By_businessinsider Trump preside ' big strategic defeat US since early day ww2 European ally ignore threat back Huawei\n"
     ]
    }
   ],
   "source": [
    "print(X_test[23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "class TweetVect(CountVectorizer):\n",
    "    def __init__(self,max_features=1500,ngram_range=(1,5),tokenizer=None,token_pattern='\\S+',min_df=1,lowercase=False,stop_words=None):\n",
    "        super().__init__(tokenizer=None,token_pattern='\\S+',\\\n",
    "                    min_df=1,lowercase=False,stop_words=None,ngram_range=ngram_range,max_features=max_features)\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fit_transform(X)\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "         return super().fit_transform(X).toarray()\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        return super().transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lemma_vect =  CountVectorizer(tokenizer=None,token_pattern='\\S+',\n",
    "                             min_df=1,lowercase=False,stop_words=None,ngram_range=(1,5),max_features=4000)\n",
    "X_train=lemma_vect.fit_transform(X_train_raw)\n",
    "X_test=lemma_vect.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    spcfc= confusion_matrix(y_true, y_pred)[0,0]/(confusion_matrix(y_true,y_pred)[0,0] + confusion_matrix(y_true, y_pred)[0,1])\n",
    "    return spcfc\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "\n",
    "\n",
    "myscoring = {'accuracy' : make_scorer(accuracy_score),\n",
    "             'balanced_acc': make_scorer(balanced_accuracy_score),\n",
    "             'specificity' : make_scorer(specificity),  \n",
    "           'precision' : make_scorer( precision_score),\n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "            'tp': make_scorer(tp), 'tn': make_scorer(tn),\n",
    "            'fp': make_scorer(fp), 'fn': make_scorer(fn)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4664 \n",
      " 8807\n"
     ]
    }
   ],
   "source": [
    "negative = len(y_vect[y_vect==0])\n",
    "positive = len(y_vect[y_vect==1])\n",
    "print(negative,'\\n',positive)\n",
    "total = negative + positive\n",
    "weight_for_0 = (1 / negative)*(total)/2.0 \n",
    "weight_for_1 = (1 / positive)*(total)/2.0\n",
    "#weight_for_1 = 100\n",
    "\n",
    "scale_pos_weight = negative/positive\n",
    "num_round = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(text_vect,\n",
    "            y_vect,random_state=SEED,test_size=0.1,stratify=y_vect)\n",
    "vect=CountVectorizer(max_features=4000,ngram_range=(1,5),tokenizer=None,token_pattern='\\S+',min_df=1,lowercase=False,stop_words=None)\n",
    "X_train=vect.fit_transform(X_train)\n",
    "X_train=X_train.toarray()\n",
    "scl=MinMaxScaler()\n",
    "X_train=scl.fit_transform(X_train)\n",
    "clf3 = LinearSVC(class_weight = 'balanced',C=0.01, max_iter=10000)\n",
    "clfLC=LC(class_weight = 'balanced',C=0.01)                \n",
    "\n",
    "clf3.fit(X_train,y_train)\n",
    "clfLC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7826409495548962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7203264094955489"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=vect.transform(X_test)\n",
    "X_test=X_test.toarray()\n",
    "X_test=scl.transform(X_test)\n",
    "print(clf3.score(X_test,y_test))\n",
    "clfLC.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set score with lemma: 0.78264\n",
      "Best specificty: 0.83512\n",
      "Best balanced accuracy: 0.79497\n",
      "Best precision: 0.89623\n",
      "Best f1_score: 0.81947\n",
      "tn,fp,fn,tp: 390 77 216 665\n"
     ]
    }
   ],
   "source": [
    "print(\"Test-set score with lemma: {:.5f}\".format(clf3.score(X_test,y_test)))\n",
    "y_pred = clf3.predict(X_test)\n",
    "print(\"Best specificty: {:.5f}\".format(specificity(y_test,y_pred)))\n",
    "print(\"Best balanced accuracy: {:.5f}\".format(balanced_accuracy_score(y_test,y_pred)))\n",
    "print(\"Best precision: {:.5f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Best f1_score: {:.5f}\".format(f1_score(y_test,y_pred)))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('tn,fp,fn,tp:',tn,fp,fn,tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set score with lemma: 0.72033\n",
      "Best specificty: 0.84582\n",
      "Best balanced accuracy: 0.74981\n",
      "Best precision: 0.88889\n",
      "Best f1_score: 0.75343\n",
      "tn,fp,fn,tp: 395 72 305 576\n"
     ]
    }
   ],
   "source": [
    "print(\"Test-set score with lemma: {:.5f}\".format(clfLC.score(X_test,y_test)))\n",
    "y_pred = clfLC.predict(X_test)\n",
    "print(\"Best specificty: {:.5f}\".format(specificity(y_test,y_pred)))\n",
    "print(\"Best balanced accuracy: {:.5f}\".format(balanced_accuracy_score(y_test,y_pred)))\n",
    "print(\"Best precision: {:.5f}\".format(precision_score(y_test,y_pred)))\n",
    "print(\"Best f1_score: {:.5f}\".format(f1_score(y_test,y_pred)))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('tn,fp,fn,tp:',tn,fp,fn,tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated = SVCclbr(clf3, method='sigmoid', cv=5)\n",
    "calibrated.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "np.set_printoptions(precision=2, threshold=np.inf)\n",
    "#print(calibrated.predict_proba(X_test)[:,1])\n",
    "\n",
    "#inpTech=[' #userexperience #ux heart #digitaltransformation @rautsan read #digital #innovation #ai #artificialintelligence #ml #machinelearning #deeplearning #dl Cc @dpatil @hackingdata']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\tekin\\\\Desktop\\\\ML\\\\Tweedy\\\\deploy\\\\BusinessCalib.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vect,r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessVect.pkl')\n",
    "joblib.dump(scl,r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessScale.pkl')\n",
    "\n",
    "joblib.dump(clf3,r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessLnrSVC.pkl')\n",
    "joblib.dump(calibrated,r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessCalib.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vect,scl,clf3,calibrated\n",
    "vect=joblib.load(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessVect.pkl')\n",
    "scl=joblib.load(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessScale.pkl')\n",
    "clf3=joblib.load(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessLnrSVC.pkl')\n",
    "calibrated=joblib.load(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessCalib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resSVC,prbSVC,clbSVCres: [0] [[0.6 0.4]] [0]\n"
     ]
    }
   ],
   "source": [
    "inpTech=['@rautsan read #digital #innovation #ai #artificialintelligence #ml #machinelearning #deeplearning #dl Cc @dpatil @hackingdata']\n",
    "\n",
    "inpTech=['By_businessinsider car enthusiast love peelable paint']\n",
    "#inpTech=[\"By_businessinsider Trump preside ' big strategic defeat US since early day ww2 European ally ignore threat back Huawei\"]\n",
    "#inpTech=[\"a b c d \"]\n",
    "inp1=vect.transform(inpTech)\n",
    "inp1=inp1.toarray()\n",
    "inp=scl.transform(inp1)\n",
    "prbSVC=calibrated.predict_proba(inp)\n",
    "#prbSVCsg=calibrate1.predict_proba(inp)\n",
    "#prbcalib=calib.predict_proba(inp)\n",
    "#prbLC=calibrate2.predict_proba(inp)\n",
    "resSVC=clf3.predict(inp)\n",
    "clbSVCres=calibrated.predict(inp)\n",
    "#clbLCres=calibrate2.predict(inp)\n",
    "#clbSVCsigres=calibrate1.predict(inp)\n",
    "#calibres=calib.predict(inp)\n",
    "print(\"resSVC,prbSVC,clbSVCres:\",resSVC,prbSVC,clbSVCres)\n",
    "#print(calibrated.score(X_test,y_test))\n",
    "#print(clf3.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.54826e-02 9.84517e-01]\n",
      " [1.26861e-02 9.87314e-01]\n",
      " [1.30379e-01 8.69621e-01]\n",
      " [1.26577e-01 8.73423e-01]\n",
      " [1.14777e-02 9.88522e-01]\n",
      " [2.11338e-02 9.78866e-01]\n",
      " [8.28728e-02 9.17127e-01]\n",
      " [5.38482e-02 9.46152e-01]\n",
      " [2.42363e-01 7.57637e-01]\n",
      " [5.48875e-02 9.45113e-01]\n",
      " [5.28490e-03 9.94715e-01]\n",
      " [8.20438e-02 9.17956e-01]\n",
      " [2.60634e-02 9.73937e-01]\n",
      " [3.54505e-03 9.96455e-01]\n",
      " [4.09799e-02 9.59020e-01]\n",
      " [3.40382e-01 6.59618e-01]\n",
      " [5.62026e-03 9.94380e-01]\n",
      " [2.83598e-02 9.71640e-01]\n",
      " [6.45258e-03 9.93547e-01]\n",
      " [4.30768e-02 9.56923e-01]\n",
      " [3.00037e-01 6.99963e-01]\n",
      " [4.64221e-02 9.53578e-01]\n",
      " [2.03062e-01 7.96938e-01]\n",
      " [2.31224e-01 7.68776e-01]\n",
      " [2.19291e-01 7.80709e-01]\n",
      " [8.28728e-02 9.17127e-01]\n",
      " [3.17630e-02 9.68237e-01]\n",
      " [3.23559e-01 6.76441e-01]\n",
      " [5.41242e-03 9.94588e-01]\n",
      " [8.15496e-02 9.18450e-01]\n",
      " [1.33556e-02 9.86644e-01]\n",
      " [9.75574e-02 9.02443e-01]\n",
      " [4.72148e-02 9.52785e-01]\n",
      " [1.56692e-03 9.98433e-01]\n",
      " [4.31901e-02 9.56810e-01]\n",
      " [3.25149e-02 9.67485e-01]\n",
      " [2.57056e-02 9.74294e-01]\n",
      " [4.05161e-02 9.59484e-01]\n",
      " [3.67627e-02 9.63237e-01]\n",
      " [1.36272e-01 8.63728e-01]\n",
      " [7.01732e-02 9.29827e-01]\n",
      " [9.76413e-02 9.02359e-01]\n",
      " [9.64130e-02 9.03587e-01]\n",
      " [1.30763e-01 8.69237e-01]\n",
      " [1.11459e-02 9.88854e-01]\n",
      " [4.17616e-01 5.82384e-01]\n",
      " [1.71159e-02 9.82884e-01]\n",
      " [4.13880e-02 9.58612e-01]\n",
      " [3.24263e-03 9.96757e-01]\n",
      " [1.02261e-02 9.89774e-01]\n",
      " [1.08639e-01 8.91361e-01]\n",
      " [5.00959e-02 9.49904e-01]\n",
      " [1.26486e-01 8.73514e-01]\n",
      " [2.68904e-01 7.31096e-01]\n",
      " [1.45828e-01 8.54172e-01]\n",
      " [1.80594e-02 9.81941e-01]\n",
      " [3.38032e-02 9.66197e-01]\n",
      " [2.39661e-03 9.97603e-01]\n",
      " [7.86657e-04 9.99213e-01]\n",
      " [5.35236e-02 9.46476e-01]\n",
      " [1.38498e-02 9.86150e-01]\n",
      " [6.75625e-01 3.24375e-01]\n",
      " [4.95660e-02 9.50434e-01]\n",
      " [7.72669e-02 9.22733e-01]\n",
      " [5.35251e-03 9.94647e-01]\n",
      " [5.52122e-02 9.44788e-01]\n",
      " [2.54355e-01 7.45645e-01]\n",
      " [2.26896e-01 7.73104e-01]\n",
      " [3.74340e-01 6.25660e-01]\n",
      " [2.82209e-01 7.17791e-01]\n",
      " [1.13743e-02 9.88626e-01]\n",
      " [2.19483e-02 9.78052e-01]\n",
      " [2.23725e-02 9.77627e-01]\n",
      " [1.04877e-01 8.95123e-01]\n",
      " [2.16728e-01 7.83272e-01]\n",
      " [3.71882e-01 6.28118e-01]\n",
      " [9.33593e-02 9.06641e-01]\n",
      " [7.01144e-02 9.29886e-01]\n",
      " [1.65018e-01 8.34982e-01]\n",
      " [5.11966e-02 9.48803e-01]\n",
      " [2.22311e-03 9.97777e-01]\n",
      " [2.11664e-02 9.78834e-01]\n",
      " [3.66787e-02 9.63321e-01]\n",
      " [1.77471e-02 9.82253e-01]\n",
      " [4.05311e-01 5.94689e-01]\n",
      " [3.52401e-01 6.47599e-01]\n",
      " [8.32791e-02 9.16721e-01]\n",
      " [7.80053e-02 9.21995e-01]\n",
      " [2.23379e-02 9.77662e-01]\n",
      " [1.07565e-01 8.92435e-01]\n",
      " [3.43244e-01 6.56756e-01]\n",
      " [1.77110e-01 8.22890e-01]\n",
      " [3.07204e-03 9.96928e-01]\n",
      " [2.57823e-01 7.42177e-01]\n",
      " [3.41626e-01 6.58374e-01]\n",
      " [2.19990e-02 9.78001e-01]\n",
      " [9.99526e-03 9.90005e-01]\n",
      " [2.75959e-02 9.72404e-01]\n",
      " [2.90216e-01 7.09784e-01]\n",
      " [5.60516e-03 9.94395e-01]\n",
      " [1.18625e-01 8.81375e-01]\n",
      " [2.74386e-03 9.97256e-01]\n",
      " [1.54031e-01 8.45969e-01]\n",
      " [5.86429e-02 9.41357e-01]\n",
      " [3.99324e-01 6.00676e-01]\n",
      " [4.60868e-02 9.53913e-01]\n",
      " [1.03771e-02 9.89623e-01]\n",
      " [4.31850e-03 9.95681e-01]\n",
      " [5.03472e-03 9.94965e-01]\n",
      " [4.72598e-02 9.52740e-01]\n",
      " [2.52433e-02 9.74757e-01]\n",
      " [1.82278e-02 9.81772e-01]\n",
      " [1.59983e-01 8.40017e-01]\n",
      " [2.05496e-03 9.97945e-01]\n",
      " [3.59483e-01 6.40517e-01]\n",
      " [5.55117e-01 4.44883e-01]\n",
      " [1.60719e-01 8.39281e-01]\n",
      " [5.02017e-03 9.94980e-01]\n",
      " [1.67560e-02 9.83244e-01]\n",
      " [3.97290e-02 9.60271e-01]\n",
      " [3.13500e-02 9.68650e-01]\n",
      " [7.23736e-03 9.92763e-01]\n",
      " [8.67368e-02 9.13263e-01]\n",
      " [2.00320e-02 9.79968e-01]\n",
      " [2.03413e-01 7.96587e-01]\n",
      " [1.90596e-02 9.80940e-01]\n",
      " [3.12266e-01 6.87734e-01]\n",
      " [3.02679e-03 9.96973e-01]\n",
      " [3.66339e-02 9.63366e-01]\n",
      " [6.55487e-02 9.34451e-01]\n",
      " [1.82301e-02 9.81770e-01]\n",
      " [2.02911e-01 7.97089e-01]\n",
      " [1.20923e-02 9.87908e-01]\n",
      " [1.71186e-02 9.82881e-01]\n",
      " [6.09573e-01 3.90427e-01]\n",
      " [1.24955e-01 8.75045e-01]\n",
      " [2.89709e-02 9.71029e-01]\n",
      " [1.24381e-02 9.87562e-01]\n",
      " [3.70998e-01 6.29002e-01]\n",
      " [2.41625e-02 9.75837e-01]\n",
      " [4.76845e-01 5.23155e-01]\n",
      " [4.80514e-02 9.51949e-01]\n",
      " [3.55068e-01 6.44932e-01]\n",
      " [4.88104e-02 9.51190e-01]\n",
      " [2.04248e-02 9.79575e-01]\n",
      " [5.67090e-02 9.43291e-01]\n",
      " [1.77544e-01 8.22456e-01]\n",
      " [3.49488e-02 9.65051e-01]\n",
      " [4.89340e-02 9.51066e-01]\n",
      " [1.69996e-02 9.83000e-01]\n",
      " [5.49045e-03 9.94510e-01]\n",
      " [1.50457e-02 9.84954e-01]\n",
      " [5.46096e-01 4.53904e-01]\n",
      " [1.15491e-01 8.84509e-01]\n",
      " [4.86749e-02 9.51325e-01]\n",
      " [2.17378e-01 7.82622e-01]\n",
      " [3.76154e-02 9.62385e-01]\n",
      " [2.92457e-01 7.07543e-01]\n",
      " [3.52145e-03 9.96479e-01]\n",
      " [2.11901e-03 9.97881e-01]\n",
      " [2.46103e-02 9.75390e-01]\n",
      " [6.58979e-02 9.34102e-01]\n",
      " [1.05336e-01 8.94664e-01]\n",
      " [3.46613e-01 6.53387e-01]\n",
      " [9.96474e-02 9.00353e-01]\n",
      " [4.25586e-02 9.57441e-01]\n",
      " [3.92952e-01 6.07048e-01]\n",
      " [3.71228e-01 6.28772e-01]\n",
      " [1.14915e-01 8.85085e-01]\n",
      " [1.96303e-02 9.80370e-01]\n",
      " [5.03583e-02 9.49642e-01]\n",
      " [1.30520e-01 8.69480e-01]\n",
      " [1.32894e-01 8.67106e-01]\n",
      " [1.03373e-01 8.96627e-01]\n",
      " [1.51575e-01 8.48425e-01]\n",
      " [5.45302e-02 9.45470e-01]\n",
      " [1.45688e-01 8.54312e-01]\n",
      " [2.80108e-02 9.71989e-01]\n",
      " [1.40278e-01 8.59722e-01]\n",
      " [1.67931e-01 8.32069e-01]\n",
      " [6.15491e-02 9.38451e-01]\n",
      " [7.31151e-02 9.26885e-01]\n",
      " [2.40813e-03 9.97592e-01]\n",
      " [1.46645e-01 8.53355e-01]\n",
      " [2.59790e-02 9.74021e-01]\n",
      " [1.90195e-02 9.80980e-01]\n",
      " [4.56417e-02 9.54358e-01]\n",
      " [3.14138e-01 6.85862e-01]\n",
      " [3.79284e-02 9.62072e-01]\n",
      " [7.16604e-02 9.28340e-01]\n",
      " [3.13172e-03 9.96868e-01]\n",
      " [1.71217e-01 8.28783e-01]\n",
      " [2.39313e-01 7.60687e-01]\n",
      " [1.47376e-02 9.85262e-01]\n",
      " [9.13633e-02 9.08637e-01]\n",
      " [2.94361e-02 9.70564e-01]\n",
      " [8.68591e-04 9.99131e-01]\n",
      " [1.55809e-01 8.44191e-01]\n",
      " [2.29660e-02 9.77034e-01]\n",
      " [2.51702e-01 7.48298e-01]\n",
      " [7.74576e-03 9.92254e-01]\n",
      " [9.28783e-02 9.07122e-01]\n",
      " [4.49245e-03 9.95508e-01]\n",
      " [5.94766e-03 9.94052e-01]\n",
      " [2.02235e-01 7.97765e-01]\n",
      " [3.03630e-01 6.96370e-01]\n",
      " [4.21199e-02 9.57880e-01]\n",
      " [8.38977e-02 9.16102e-01]\n",
      " [1.09050e-01 8.90950e-01]\n",
      " [1.53738e-01 8.46262e-01]\n",
      " [6.43651e-03 9.93563e-01]\n",
      " [9.90442e-03 9.90096e-01]\n",
      " [4.75108e-01 5.24892e-01]\n",
      " [5.61197e-02 9.43880e-01]\n",
      " [4.07615e-01 5.92385e-01]\n",
      " [1.35392e-03 9.98646e-01]\n",
      " [2.85457e-02 9.71454e-01]\n",
      " [7.63381e-02 9.23662e-01]\n",
      " [1.52356e-01 8.47644e-01]\n",
      " [3.86183e-03 9.96138e-01]\n",
      " [3.30958e-02 9.66904e-01]\n",
      " [3.56757e-02 9.64324e-01]\n",
      " [1.32902e-02 9.86710e-01]\n",
      " [2.98089e-01 7.01911e-01]\n",
      " [2.80733e-01 7.19267e-01]\n",
      " [1.10971e-02 9.88903e-01]\n",
      " [5.34569e-02 9.46543e-01]\n",
      " [6.08575e-02 9.39143e-01]\n",
      " [8.04588e-02 9.19541e-01]\n",
      " [3.11365e-02 9.68864e-01]\n",
      " [2.46057e-01 7.53943e-01]\n",
      " [2.30300e-01 7.69700e-01]\n",
      " [1.42909e-01 8.57091e-01]\n",
      " [2.54217e-01 7.45783e-01]\n",
      " [6.63804e-03 9.93362e-01]\n",
      " [1.11130e-01 8.88870e-01]\n",
      " [6.49626e-02 9.35037e-01]\n",
      " [1.89445e-02 9.81055e-01]\n",
      " [9.52196e-02 9.04780e-01]\n",
      " [1.68745e-01 8.31255e-01]\n",
      " [5.32518e-01 4.67482e-01]\n",
      " [1.47360e-01 8.52640e-01]\n",
      " [2.24376e-02 9.77562e-01]\n",
      " [4.74780e-02 9.52522e-01]\n",
      " [7.48046e-02 9.25195e-01]\n",
      " [2.83521e-02 9.71648e-01]\n",
      " [4.05631e-03 9.95944e-01]\n",
      " [1.16911e-01 8.83089e-01]\n",
      " [1.37638e-01 8.62362e-01]\n",
      " [7.39184e-01 2.60816e-01]\n",
      " [1.97816e-01 8.02184e-01]\n",
      " [7.10999e-02 9.28900e-01]\n",
      " [4.89504e-02 9.51050e-01]\n",
      " [9.37231e-02 9.06277e-01]\n",
      " [8.19237e-02 9.18076e-01]\n",
      " [3.14037e-02 9.68596e-01]\n",
      " [3.12771e-03 9.96872e-01]\n",
      " [2.74088e-03 9.97259e-01]\n",
      " [1.44551e-01 8.55449e-01]\n",
      " [4.78535e-01 5.21465e-01]\n",
      " [6.82622e-02 9.31738e-01]\n",
      " [7.97038e-02 9.20296e-01]\n",
      " [2.88869e-02 9.71113e-01]\n",
      " [1.88163e-02 9.81184e-01]\n",
      " [2.05959e-02 9.79404e-01]\n",
      " [2.66405e-02 9.73359e-01]\n",
      " [8.34695e-03 9.91653e-01]\n",
      " [9.09420e-02 9.09058e-01]\n",
      " [4.13302e-03 9.95867e-01]\n",
      " [4.16880e-03 9.95831e-01]\n",
      " [5.22554e-02 9.47745e-01]\n",
      " [5.63882e-02 9.43612e-01]\n",
      " [2.32060e-03 9.97679e-01]\n",
      " [3.76110e-03 9.96239e-01]\n",
      " [1.39413e-01 8.60587e-01]\n",
      " [1.59558e-02 9.84044e-01]\n",
      " [4.19229e-03 9.95808e-01]\n",
      " [4.11462e-02 9.58854e-01]\n",
      " [8.00103e-02 9.19990e-01]\n",
      " [1.21241e-02 9.87876e-01]\n",
      " [1.58571e-02 9.84143e-01]\n",
      " [1.27582e-02 9.87242e-01]\n",
      " [1.74775e-03 9.98252e-01]\n",
      " [3.50701e-01 6.49299e-01]\n",
      " [2.02165e-01 7.97835e-01]\n",
      " [8.67172e-03 9.91328e-01]\n",
      " [7.42146e-02 9.25785e-01]\n",
      " [1.10998e-01 8.89002e-01]\n",
      " [2.22135e-01 7.77865e-01]\n",
      " [3.55683e-03 9.96443e-01]\n",
      " [1.97246e-01 8.02754e-01]\n",
      " [5.89394e-03 9.94106e-01]\n",
      " [2.48692e-02 9.75131e-01]\n",
      " [3.78101e-02 9.62190e-01]\n",
      " [4.17443e-02 9.58256e-01]\n",
      " [1.21662e-02 9.87834e-01]\n",
      " [4.86109e-02 9.51389e-01]\n",
      " [2.32534e-01 7.67466e-01]\n",
      " [3.24314e-02 9.67569e-01]\n",
      " [4.33105e-03 9.95669e-01]\n",
      " [3.65132e-02 9.63487e-01]\n",
      " [1.10106e-01 8.89894e-01]\n",
      " [5.54861e-01 4.45139e-01]\n",
      " [2.85796e-02 9.71420e-01]\n",
      " [1.65384e-01 8.34616e-01]\n",
      " [2.21978e-02 9.77802e-01]\n",
      " [4.48804e-02 9.55120e-01]\n",
      " [3.35571e-02 9.66443e-01]\n",
      " [3.97615e-01 6.02385e-01]\n",
      " [2.64288e-02 9.73571e-01]\n",
      " [1.47675e-01 8.52325e-01]\n",
      " [6.32795e-02 9.36721e-01]\n",
      " [1.74480e-01 8.25520e-01]\n",
      " [4.44154e-02 9.55585e-01]\n",
      " [1.36647e-02 9.86335e-01]\n",
      " [3.78182e-01 6.21818e-01]\n",
      " [1.35871e-01 8.64129e-01]\n",
      " [2.66037e-03 9.97340e-01]\n",
      " [2.29920e-01 7.70080e-01]\n",
      " [4.28201e-02 9.57180e-01]\n",
      " [3.23302e-01 6.76698e-01]\n",
      " [2.26576e-02 9.77342e-01]\n",
      " [6.76922e-03 9.93231e-01]\n",
      " [5.21010e-01 4.78990e-01]\n",
      " [8.12833e-01 1.87167e-01]\n",
      " [2.04095e-01 7.95905e-01]\n",
      " [9.98739e-02 9.00126e-01]\n",
      " [6.10827e-03 9.93892e-01]\n",
      " [6.01680e-02 9.39832e-01]\n",
      " [1.16642e-01 8.83358e-01]\n",
      " [3.15492e-02 9.68451e-01]\n",
      " [8.86844e-02 9.11316e-01]\n",
      " [3.84846e-02 9.61515e-01]\n",
      " [7.13397e-03 9.92866e-01]\n",
      " [8.49007e-02 9.15099e-01]\n",
      " [2.46947e-02 9.75305e-01]\n",
      " [2.87536e-02 9.71246e-01]\n",
      " [4.95794e-03 9.95042e-01]\n",
      " [1.27065e-02 9.87294e-01]\n",
      " [1.78959e-02 9.82104e-01]\n",
      " [6.94110e-02 9.30589e-01]\n",
      " [1.44170e-02 9.85583e-01]\n",
      " [1.65058e-01 8.34942e-01]\n",
      " [5.56346e-02 9.44365e-01]\n",
      " [1.27672e-01 8.72328e-01]\n",
      " [1.01085e-02 9.89891e-01]\n",
      " [7.49810e-02 9.25019e-01]\n",
      " [2.49697e-02 9.75030e-01]\n",
      " [1.13506e-03 9.98865e-01]\n",
      " [5.22585e-02 9.47741e-01]\n",
      " [6.41797e-02 9.35820e-01]\n",
      " [2.29244e-03 9.97708e-01]\n",
      " [9.81918e-02 9.01808e-01]\n",
      " [1.50672e-02 9.84933e-01]\n",
      " [4.44406e-01 5.55594e-01]\n",
      " [3.07439e-01 6.92561e-01]\n",
      " [1.57151e-01 8.42849e-01]\n",
      " [1.47481e-01 8.52519e-01]\n",
      " [1.70944e-01 8.29056e-01]\n",
      " [6.75837e-02 9.32416e-01]\n",
      " [2.17854e-02 9.78215e-01]\n",
      " [4.22400e-01 5.77600e-01]\n",
      " [2.47021e-02 9.75298e-01]\n",
      " [5.01496e-03 9.94985e-01]\n",
      " [6.25236e-02 9.37476e-01]\n",
      " [4.04444e-01 5.95556e-01]\n",
      " [1.56387e-01 8.43613e-01]\n",
      " [5.77403e-01 4.22597e-01]\n",
      " [2.11970e-02 9.78803e-01]\n",
      " [4.24629e-01 5.75371e-01]\n",
      " [6.28661e-01 3.71339e-01]\n",
      " [8.60392e-03 9.91396e-01]\n",
      " [2.87986e-01 7.12014e-01]\n",
      " [6.21435e-02 9.37857e-01]\n",
      " [1.43074e-01 8.56926e-01]\n",
      " [2.71446e-02 9.72855e-01]\n",
      " [5.57008e-02 9.44299e-01]\n",
      " [6.34573e-02 9.36543e-01]\n",
      " [1.45177e-01 8.54823e-01]\n",
      " [5.84666e-01 4.15334e-01]\n",
      " [5.24615e-04 9.99475e-01]\n",
      " [1.52838e-01 8.47162e-01]\n",
      " [4.87785e-01 5.12215e-01]\n",
      " [6.59022e-03 9.93410e-01]\n",
      " [5.78693e-02 9.42131e-01]\n",
      " [2.26511e-02 9.77349e-01]\n",
      " [1.35719e-01 8.64281e-01]\n",
      " [2.43371e-01 7.56629e-01]\n",
      " [2.69877e-01 7.30123e-01]\n",
      " [1.01558e-01 8.98442e-01]\n",
      " [3.45681e-02 9.65432e-01]\n",
      " [2.21002e-02 9.77900e-01]\n",
      " [3.88475e-02 9.61153e-01]\n",
      " [2.20855e-02 9.77914e-01]\n",
      " [2.39804e-02 9.76020e-01]\n",
      " [7.29421e-03 9.92706e-01]\n",
      " [8.35658e-03 9.91643e-01]\n",
      " [3.84217e-02 9.61578e-01]\n",
      " [8.56288e-03 9.91437e-01]\n",
      " [1.41643e-01 8.58357e-01]\n",
      " [2.18785e-03 9.97812e-01]\n",
      " [3.87906e-02 9.61209e-01]\n",
      " [5.71808e-03 9.94282e-01]\n",
      " [4.28008e-03 9.95720e-01]\n",
      " [5.30225e-01 4.69775e-01]\n",
      " [3.44247e-01 6.55753e-01]\n",
      " [3.85989e-02 9.61401e-01]\n",
      " [4.48214e-01 5.51786e-01]\n",
      " [5.78845e-01 4.21155e-01]\n",
      " [1.44854e-02 9.85515e-01]\n",
      " [4.54456e-02 9.54554e-01]\n",
      " [1.22699e-03 9.98773e-01]\n",
      " [1.42393e-01 8.57607e-01]\n",
      " [2.54803e-02 9.74520e-01]\n",
      " [3.54968e-03 9.96450e-01]\n",
      " [1.38880e-01 8.61120e-01]\n",
      " [7.12677e-02 9.28732e-01]\n",
      " [3.60263e-02 9.63974e-01]\n",
      " [2.40705e-01 7.59295e-01]\n",
      " [1.44825e-01 8.55175e-01]\n",
      " [5.45496e-03 9.94545e-01]\n",
      " [7.22055e-02 9.27795e-01]\n",
      " [1.41559e-01 8.58441e-01]\n",
      " [1.47038e-01 8.52962e-01]\n",
      " [5.19145e-02 9.48085e-01]\n",
      " [1.36139e-02 9.86386e-01]\n",
      " [1.56432e-03 9.98436e-01]\n",
      " [7.04742e-03 9.92953e-01]\n",
      " [3.79367e-02 9.62063e-01]\n",
      " [2.08154e-01 7.91846e-01]\n",
      " [2.53243e-01 7.46757e-01]\n",
      " [1.25782e-02 9.87422e-01]\n",
      " [4.21840e-02 9.57816e-01]\n",
      " [1.13253e-01 8.86747e-01]\n",
      " [1.30263e-02 9.86974e-01]\n",
      " [2.99303e-02 9.70070e-01]\n",
      " [3.92319e-02 9.60768e-01]\n",
      " [1.40788e-03 9.98592e-01]\n",
      " [3.99263e-02 9.60074e-01]\n",
      " [2.31565e-02 9.76844e-01]\n",
      " [4.31254e-02 9.56875e-01]\n",
      " [4.22975e-03 9.95770e-01]\n",
      " [9.41304e-02 9.05870e-01]\n",
      " [3.23015e-01 6.76985e-01]\n",
      " [1.59367e-02 9.84063e-01]\n",
      " [1.50881e-01 8.49119e-01]\n",
      " [7.80903e-02 9.21910e-01]\n",
      " [1.24720e-01 8.75280e-01]\n",
      " [3.21642e-02 9.67836e-01]\n",
      " [8.46308e-03 9.91537e-01]\n",
      " [2.11871e-02 9.78813e-01]\n",
      " [2.69690e-02 9.73031e-01]\n",
      " [8.52665e-03 9.91473e-01]\n",
      " [6.34957e-01 3.65043e-01]\n",
      " [3.01046e-01 6.98954e-01]\n",
      " [1.70187e-01 8.29813e-01]\n",
      " [8.56340e-02 9.14366e-01]\n",
      " [5.31506e-03 9.94685e-01]\n",
      " [5.23783e-02 9.47622e-01]\n",
      " [2.48688e-01 7.51312e-01]\n",
      " [3.19846e-01 6.80154e-01]\n",
      " [1.90004e-01 8.09996e-01]\n",
      " [1.29944e-01 8.70056e-01]\n",
      " [1.02132e-01 8.97868e-01]\n",
      " [2.13276e-02 9.78672e-01]\n",
      " [7.41960e-02 9.25804e-01]\n",
      " [8.75481e-02 9.12452e-01]\n",
      " [8.93626e-03 9.91064e-01]\n",
      " [3.51936e-01 6.48064e-01]\n",
      " [4.47138e-02 9.55286e-01]\n",
      " [2.48289e-02 9.75171e-01]\n",
      " [5.92846e-02 9.40715e-01]\n",
      " [2.05967e-01 7.94033e-01]\n",
      " [2.58396e-01 7.41604e-01]\n",
      " [3.86278e-02 9.61372e-01]\n",
      " [1.81068e-02 9.81893e-01]\n",
      " [4.19466e-03 9.95805e-01]\n",
      " [7.20718e-02 9.27928e-01]\n",
      " [1.55989e-02 9.84401e-01]\n",
      " [1.05072e-01 8.94928e-01]\n",
      " [1.83741e-02 9.81626e-01]\n",
      " [1.15469e-01 8.84531e-01]\n",
      " [3.35025e-02 9.66497e-01]\n",
      " [1.68794e-01 8.31206e-01]\n",
      " [4.88709e-02 9.51129e-01]\n",
      " [1.41946e-02 9.85805e-01]\n",
      " [1.98271e-01 8.01729e-01]\n",
      " [2.07046e-01 7.92954e-01]\n",
      " [1.26720e-01 8.73280e-01]\n",
      " [6.95561e-03 9.93044e-01]\n",
      " [2.77474e-03 9.97225e-01]\n",
      " [2.52752e-01 7.47248e-01]\n",
      " [8.04863e-03 9.91951e-01]\n",
      " [8.80502e-02 9.11950e-01]\n",
      " [1.12897e-01 8.87103e-01]\n",
      " [4.85148e-01 5.14852e-01]\n",
      " [3.67989e-03 9.96320e-01]\n",
      " [3.20253e-01 6.79747e-01]\n",
      " [9.60607e-02 9.03939e-01]\n",
      " [1.65409e-01 8.34591e-01]\n",
      " [8.77064e-03 9.91229e-01]\n",
      " [2.17120e-01 7.82880e-01]\n",
      " [8.14427e-02 9.18557e-01]\n",
      " [2.24838e-03 9.97752e-01]\n",
      " [6.36613e-02 9.36339e-01]\n",
      " [2.27299e-01 7.72701e-01]\n",
      " [1.93937e-01 8.06063e-01]\n",
      " [1.09632e-02 9.89037e-01]\n",
      " [2.45103e-01 7.54897e-01]\n",
      " [1.41206e-02 9.85879e-01]\n",
      " [1.69228e-01 8.30772e-01]\n",
      " [1.95439e-02 9.80456e-01]\n",
      " [6.15212e-02 9.38479e-01]\n",
      " [2.03626e-01 7.96374e-01]\n",
      " [7.73313e-03 9.92267e-01]\n",
      " [8.64492e-02 9.13551e-01]\n",
      " [1.93231e-01 8.06769e-01]\n",
      " [1.10869e-01 8.89131e-01]\n",
      " [2.24987e-03 9.97750e-01]\n",
      " [1.73415e-03 9.98266e-01]\n",
      " [2.56349e-02 9.74365e-01]\n",
      " [7.05229e-02 9.29477e-01]\n",
      " [8.65685e-03 9.91343e-01]\n",
      " [5.70346e-03 9.94297e-01]\n",
      " [2.68269e-02 9.73173e-01]\n",
      " [1.91331e-01 8.08669e-01]\n",
      " [2.09135e-01 7.90865e-01]\n",
      " [1.13663e-01 8.86337e-01]\n",
      " [8.82131e-02 9.11787e-01]\n",
      " [1.62141e-01 8.37859e-01]\n",
      " [1.63472e-01 8.36528e-01]\n",
      " [1.02698e-01 8.97302e-01]\n",
      " [1.75810e-01 8.24190e-01]\n",
      " [6.41793e-02 9.35821e-01]\n",
      " [6.30266e-02 9.36973e-01]\n",
      " [1.17807e-01 8.82193e-01]\n",
      " [3.75264e-01 6.24736e-01]\n",
      " [3.07323e-01 6.92677e-01]\n",
      " [2.57101e-02 9.74290e-01]\n",
      " [5.55715e-02 9.44429e-01]\n",
      " [2.52045e-01 7.47955e-01]\n",
      " [6.85006e-02 9.31499e-01]\n",
      " [5.98845e-01 4.01155e-01]\n",
      " [4.30066e-02 9.56993e-01]\n",
      " [3.15736e-01 6.84264e-01]\n",
      " [8.37740e-02 9.16226e-01]\n",
      " [3.97902e-02 9.60210e-01]\n",
      " [1.93820e-02 9.80618e-01]\n",
      " [5.14463e-02 9.48554e-01]\n",
      " [7.47034e-03 9.92530e-01]\n",
      " [1.47473e-02 9.85253e-01]\n",
      " [7.40051e-02 9.25995e-01]\n",
      " [9.20644e-03 9.90794e-01]\n",
      " [1.94727e-02 9.80527e-01]\n",
      " [2.02782e-01 7.97218e-01]\n",
      " [4.43409e-02 9.55659e-01]\n",
      " [1.25426e-01 8.74574e-01]\n",
      " [1.89251e-02 9.81075e-01]\n",
      " [3.75053e-02 9.62495e-01]\n",
      " [3.06215e-01 6.93785e-01]\n",
      " [1.84978e-02 9.81502e-01]\n",
      " [2.92657e-01 7.07343e-01]\n",
      " [3.98160e-03 9.96018e-01]\n",
      " [1.19446e-01 8.80554e-01]\n",
      " [4.70421e-01 5.29579e-01]\n",
      " [3.89792e-01 6.10208e-01]\n",
      " [2.05198e-01 7.94802e-01]\n",
      " [7.55768e-02 9.24423e-01]\n",
      " [1.03910e-02 9.89609e-01]\n",
      " [1.18280e-01 8.81720e-01]\n",
      " [3.33441e-02 9.66656e-01]\n",
      " [1.67519e-01 8.32481e-01]\n",
      " [1.12825e-01 8.87175e-01]\n",
      " [4.03979e-02 9.59602e-01]\n",
      " [7.80998e-02 9.21900e-01]\n",
      " [8.08723e-02 9.19128e-01]\n",
      " [1.37587e-02 9.86241e-01]\n",
      " [9.21944e-03 9.90781e-01]\n",
      " [4.14668e-02 9.58533e-01]\n",
      " [3.50508e-01 6.49492e-01]\n",
      " [5.64859e-01 4.35141e-01]\n",
      " [1.89988e-02 9.81001e-01]\n",
      " [4.06468e-01 5.93532e-01]\n",
      " [3.38424e-01 6.61576e-01]\n",
      " [1.72289e-02 9.82771e-01]\n",
      " [6.02004e-02 9.39800e-01]\n",
      " [3.16981e-02 9.68302e-01]\n",
      " [9.14948e-03 9.90851e-01]\n",
      " [8.79237e-03 9.91208e-01]\n",
      " [3.14414e-02 9.68559e-01]\n",
      " [8.38636e-02 9.16136e-01]\n",
      " [9.46461e-03 9.90535e-01]\n",
      " [5.59087e-02 9.44091e-01]\n",
      " [5.84989e-02 9.41501e-01]\n",
      " [2.37300e-02 9.76270e-01]\n",
      " [1.62238e-02 9.83776e-01]\n",
      " [8.33106e-02 9.16689e-01]\n",
      " [5.79953e-02 9.42005e-01]\n",
      " [7.43414e-02 9.25659e-01]\n",
      " [7.70227e-02 9.22977e-01]\n",
      " [6.24306e-02 9.37569e-01]\n",
      " [6.49140e-01 3.50860e-01]\n",
      " [1.01222e-01 8.98778e-01]\n",
      " [1.09423e-01 8.90577e-01]\n",
      " [1.57220e-02 9.84278e-01]\n",
      " [1.59770e-02 9.84023e-01]\n",
      " [7.75065e-02 9.22494e-01]\n",
      " [4.30242e-02 9.56976e-01]\n",
      " [5.98493e-02 9.40151e-01]\n",
      " [2.72603e-01 7.27397e-01]\n",
      " [1.08900e-01 8.91100e-01]\n",
      " [6.25185e-02 9.37481e-01]\n",
      " [2.74349e-02 9.72565e-01]\n",
      " [1.23609e-03 9.98764e-01]\n",
      " [3.11622e-02 9.68838e-01]\n",
      " [2.10076e-03 9.97899e-01]\n",
      " [9.67716e-02 9.03228e-01]\n",
      " [4.67836e-02 9.53216e-01]\n",
      " [2.62043e-02 9.73796e-01]\n",
      " [2.08975e-02 9.79102e-01]\n",
      " [1.31216e-01 8.68784e-01]\n",
      " [1.02479e-01 8.97521e-01]\n",
      " [8.88007e-02 9.11199e-01]\n",
      " [3.15482e-02 9.68452e-01]\n",
      " [9.63639e-03 9.90364e-01]\n",
      " [1.96374e-01 8.03626e-01]\n",
      " [6.39643e-03 9.93604e-01]\n",
      " [2.42337e-01 7.57663e-01]\n",
      " [9.13263e-02 9.08674e-01]\n",
      " [1.62653e-01 8.37347e-01]\n",
      " [6.10152e-02 9.38985e-01]\n",
      " [2.92147e-02 9.70785e-01]\n",
      " [1.81753e-03 9.98182e-01]\n",
      " [8.31341e-02 9.16866e-01]\n",
      " [5.65634e-02 9.43437e-01]\n",
      " [8.04723e-01 1.95277e-01]\n",
      " [4.00198e-02 9.59980e-01]\n",
      " [5.51146e-03 9.94489e-01]\n",
      " [2.75441e-02 9.72456e-01]\n",
      " [1.86894e-02 9.81311e-01]\n",
      " [2.07977e-01 7.92023e-01]\n",
      " [4.56805e-02 9.54320e-01]\n",
      " [8.15364e-04 9.99185e-01]\n",
      " [7.63377e-02 9.23662e-01]\n",
      " [7.60749e-02 9.23925e-01]\n",
      " [5.07277e-03 9.94927e-01]\n",
      " [4.76862e-02 9.52314e-01]\n",
      " [4.17896e-01 5.82104e-01]\n",
      " [5.16789e-03 9.94832e-01]\n",
      " [2.70820e-02 9.72918e-01]\n",
      " [9.02246e-02 9.09775e-01]\n",
      " [1.45030e-01 8.54970e-01]\n",
      " [2.20719e-02 9.77928e-01]\n",
      " [9.85655e-03 9.90143e-01]\n",
      " [8.00103e-02 9.19990e-01]\n",
      " [3.44994e-02 9.65501e-01]\n",
      " [9.49947e-02 9.05005e-01]\n",
      " [7.43245e-01 2.56755e-01]\n",
      " [1.78718e-02 9.82128e-01]\n",
      " [8.09510e-02 9.19049e-01]\n",
      " [1.27906e-02 9.87209e-01]\n",
      " [2.75007e-01 7.24993e-01]\n",
      " [5.87225e-02 9.41278e-01]\n",
      " [6.62734e-02 9.33727e-01]\n",
      " [4.95688e-02 9.50431e-01]\n",
      " [8.52522e-02 9.14748e-01]\n",
      " [1.13086e-02 9.88691e-01]\n",
      " [4.86110e-02 9.51389e-01]\n",
      " [2.61124e-01 7.38876e-01]\n",
      " [1.44221e-01 8.55779e-01]\n",
      " [1.88688e-03 9.98113e-01]\n",
      " [2.76855e-02 9.72314e-01]\n",
      " [5.05724e-03 9.94943e-01]\n",
      " [4.85153e-03 9.95148e-01]\n",
      " [5.01788e-03 9.94982e-01]\n",
      " [6.98249e-02 9.30175e-01]\n",
      " [1.19010e-03 9.98810e-01]\n",
      " [1.58159e-02 9.84184e-01]\n",
      " [1.50479e-01 8.49521e-01]\n",
      " [1.63232e-01 8.36768e-01]\n",
      " [3.08975e-02 9.69102e-01]\n",
      " [1.22984e-01 8.77016e-01]\n",
      " [1.71534e-01 8.28466e-01]\n",
      " [1.93013e-01 8.06987e-01]\n",
      " [1.99861e-02 9.80014e-01]\n",
      " [9.75250e-02 9.02475e-01]\n",
      " [9.40505e-02 9.05949e-01]\n",
      " [4.84675e-02 9.51532e-01]\n",
      " [7.10805e-02 9.28920e-01]\n",
      " [5.44834e-03 9.94552e-01]\n",
      " [1.45692e-02 9.85431e-01]\n",
      " [1.19322e-02 9.88068e-01]\n",
      " [5.29541e-02 9.47046e-01]\n",
      " [3.67048e-02 9.63295e-01]\n",
      " [4.07148e-02 9.59285e-01]\n",
      " [4.34812e-01 5.65188e-01]\n",
      " [1.02705e-02 9.89729e-01]\n",
      " [1.01506e-01 8.98494e-01]\n",
      " [4.16026e-03 9.95840e-01]\n",
      " [3.75699e-01 6.24301e-01]\n",
      " [3.83210e-01 6.16790e-01]\n",
      " [3.68982e-03 9.96310e-01]\n",
      " [6.03257e-02 9.39674e-01]\n",
      " [2.40321e-02 9.75968e-01]\n",
      " [5.58969e-02 9.44103e-01]\n",
      " [3.52808e-02 9.64719e-01]\n",
      " [6.28490e-02 9.37151e-01]\n",
      " [4.24274e-02 9.57573e-01]\n",
      " [1.81776e-02 9.81822e-01]\n",
      " [3.18677e-01 6.81323e-01]\n",
      " [9.43864e-03 9.90561e-01]\n",
      " [3.90597e-01 6.09403e-01]\n",
      " [6.59725e-02 9.34027e-01]\n",
      " [1.61201e-01 8.38799e-01]\n",
      " [1.34040e-01 8.65960e-01]\n",
      " [2.78650e-01 7.21350e-01]\n",
      " [1.47457e-01 8.52543e-01]\n",
      " [3.30150e-02 9.66985e-01]\n",
      " [3.86469e-02 9.61353e-01]\n",
      " [5.49993e-02 9.45001e-01]\n",
      " [1.48217e-01 8.51783e-01]\n",
      " [6.03514e-02 9.39649e-01]\n",
      " [3.18310e-02 9.68169e-01]\n",
      " [3.04898e-02 9.69510e-01]\n",
      " [2.31399e-01 7.68601e-01]\n",
      " [7.58567e-03 9.92414e-01]\n",
      " [4.01670e-02 9.59833e-01]\n",
      " [1.78158e-02 9.82184e-01]\n",
      " [6.04588e-02 9.39541e-01]\n",
      " [1.48718e-01 8.51282e-01]\n",
      " [6.02835e-02 9.39717e-01]\n",
      " [2.85147e-02 9.71485e-01]\n",
      " [2.10537e-02 9.78946e-01]\n",
      " [2.02999e-02 9.79700e-01]\n",
      " [1.24721e-01 8.75279e-01]\n",
      " [1.04041e-02 9.89596e-01]\n",
      " [2.61082e-02 9.73892e-01]\n",
      " [9.99091e-02 9.00091e-01]\n",
      " [8.62075e-03 9.91379e-01]\n",
      " [1.09039e-01 8.90961e-01]\n",
      " [8.31927e-03 9.91681e-01]\n",
      " [1.35469e-01 8.64531e-01]\n",
      " [5.45329e-02 9.45467e-01]\n",
      " [2.44001e-02 9.75600e-01]\n",
      " [1.06662e-01 8.93338e-01]\n",
      " [2.43682e-02 9.75632e-01]\n",
      " [1.28649e-02 9.87135e-01]\n",
      " [9.28217e-03 9.90718e-01]\n",
      " [9.35302e-03 9.90647e-01]\n",
      " [3.55040e-02 9.64496e-01]\n",
      " [1.12642e-02 9.88736e-01]\n",
      " [5.34169e-03 9.94658e-01]\n",
      " [1.75460e-02 9.82454e-01]\n",
      " [3.35185e-01 6.64815e-01]\n",
      " [3.22316e-02 9.67768e-01]\n",
      " [5.29612e-01 4.70388e-01]\n",
      " [7.59123e-02 9.24088e-01]\n",
      " [7.65736e-02 9.23426e-01]\n",
      " [7.04484e-03 9.92955e-01]\n",
      " [1.04718e-01 8.95282e-01]\n",
      " [1.50063e-01 8.49937e-01]\n",
      " [1.41481e-01 8.58519e-01]\n",
      " [2.89495e-02 9.71050e-01]\n",
      " [1.72914e-02 9.82709e-01]\n",
      " [7.15429e-01 2.84571e-01]\n",
      " [1.95817e-01 8.04183e-01]\n",
      " [3.31916e-02 9.66808e-01]\n",
      " [5.87279e-03 9.94127e-01]\n",
      " [2.45165e-01 7.54835e-01]\n",
      " [5.37879e-02 9.46212e-01]\n",
      " [1.10110e-01 8.89890e-01]\n",
      " [3.36414e-01 6.63586e-01]\n",
      " [3.91800e-01 6.08200e-01]\n",
      " [1.18226e-01 8.81774e-01]\n",
      " [1.40050e-03 9.98600e-01]\n",
      " [5.66253e-02 9.43375e-01]\n",
      " [2.75833e-02 9.72417e-01]\n",
      " [1.08932e-01 8.91068e-01]\n",
      " [2.97584e-02 9.70242e-01]\n",
      " [3.27234e-01 6.72766e-01]\n",
      " [3.73321e-02 9.62668e-01]\n",
      " [4.96693e-01 5.03307e-01]\n",
      " [1.62005e-02 9.83799e-01]\n",
      " [1.17396e-01 8.82604e-01]\n",
      " [2.37663e-02 9.76234e-01]\n",
      " [1.77502e-02 9.82250e-01]\n",
      " [2.35685e-03 9.97643e-01]\n",
      " [2.28924e-01 7.71076e-01]\n",
      " [1.00655e-02 9.89934e-01]\n",
      " [1.21201e-01 8.78799e-01]\n",
      " [1.56663e-02 9.84334e-01]\n",
      " [1.66686e-01 8.33314e-01]\n",
      " [3.56162e-02 9.64384e-01]\n",
      " [1.20627e-01 8.79373e-01]\n",
      " [3.11840e-03 9.96882e-01]\n",
      " [3.36774e-02 9.66323e-01]\n",
      " [1.97075e-01 8.02925e-01]\n",
      " [6.82541e-02 9.31746e-01]\n",
      " [5.21858e-02 9.47814e-01]\n",
      " [5.72031e-02 9.42797e-01]\n",
      " [1.97410e-01 8.02590e-01]\n",
      " [2.42745e-02 9.75725e-01]\n",
      " [6.60777e-02 9.33922e-01]\n",
      " [2.19543e-01 7.80457e-01]\n",
      " [3.68689e-01 6.31311e-01]\n",
      " [2.43312e-02 9.75669e-01]\n",
      " [4.58214e-01 5.41786e-01]\n",
      " [4.86935e-02 9.51306e-01]\n",
      " [2.49928e-01 7.50072e-01]\n",
      " [1.20264e-01 8.79736e-01]\n",
      " [1.72205e-01 8.27795e-01]\n",
      " [4.55288e-02 9.54471e-01]\n",
      " [4.22350e-02 9.57765e-01]\n",
      " [3.98934e-01 6.01066e-01]\n",
      " [1.71360e-01 8.28640e-01]\n",
      " [9.20306e-04 9.99080e-01]\n",
      " [7.62619e-03 9.92374e-01]\n",
      " [1.35674e-01 8.64326e-01]\n",
      " [2.26972e-01 7.73028e-01]\n",
      " [4.81740e-01 5.18260e-01]\n",
      " [7.43388e-03 9.92566e-01]\n",
      " [2.06154e-03 9.97938e-01]\n",
      " [5.87638e-02 9.41236e-01]\n",
      " [3.81019e-02 9.61898e-01]\n",
      " [4.46320e-01 5.53680e-01]\n",
      " [9.45090e-03 9.90549e-01]\n",
      " [1.90319e-02 9.80968e-01]\n",
      " [7.45351e-02 9.25465e-01]\n",
      " [4.89826e-02 9.51017e-01]\n",
      " [6.33094e-03 9.93669e-01]\n",
      " [1.34146e-02 9.86585e-01]\n",
      " [1.75724e-02 9.82428e-01]\n",
      " [5.28163e-01 4.71837e-01]\n",
      " [3.17590e-02 9.68241e-01]\n",
      " [3.40440e-01 6.59560e-01]\n",
      " [2.49322e-02 9.75068e-01]\n",
      " [4.86288e-02 9.51371e-01]\n",
      " [1.23660e-01 8.76340e-01]\n",
      " [6.71823e-02 9.32818e-01]\n",
      " [4.83085e-02 9.51691e-01]\n",
      " [7.70888e-03 9.92291e-01]\n",
      " [4.03949e-02 9.59605e-01]\n",
      " [7.61665e-02 9.23834e-01]\n",
      " [3.67979e-01 6.32021e-01]\n",
      " [9.98453e-02 9.00155e-01]\n",
      " [1.15486e-02 9.88451e-01]\n",
      " [2.05406e-02 9.79459e-01]\n",
      " [2.03989e-01 7.96011e-01]\n",
      " [5.16422e-02 9.48358e-01]\n",
      " [1.83094e-01 8.16906e-01]\n",
      " [1.31068e-01 8.68932e-01]\n",
      " [6.16967e-01 3.83033e-01]\n",
      " [2.64927e-02 9.73507e-01]\n",
      " [6.29893e-01 3.70107e-01]\n",
      " [4.22429e-02 9.57757e-01]\n",
      " [2.26240e-01 7.73760e-01]\n",
      " [4.69052e-02 9.53095e-01]\n",
      " [1.91591e-03 9.98084e-01]\n",
      " [1.78724e-01 8.21276e-01]\n",
      " [9.29144e-02 9.07086e-01]\n",
      " [1.00497e-01 8.99503e-01]\n",
      " [8.49760e-02 9.15024e-01]\n",
      " [4.00374e-02 9.59963e-01]\n",
      " [1.39147e-02 9.86085e-01]\n",
      " [3.29875e-01 6.70125e-01]\n",
      " [6.97370e-02 9.30263e-01]\n",
      " [9.30462e-02 9.06954e-01]\n",
      " [7.38102e-02 9.26190e-01]\n",
      " [6.23083e-02 9.37692e-01]\n",
      " [3.83987e-02 9.61601e-01]\n",
      " [3.32132e-02 9.66787e-01]\n",
      " [6.42757e-02 9.35724e-01]\n",
      " [1.20403e-02 9.87960e-01]\n",
      " [3.65651e-03 9.96343e-01]\n",
      " [7.21387e-02 9.27861e-01]\n",
      " [1.35676e-02 9.86432e-01]\n",
      " [1.54462e-01 8.45538e-01]\n",
      " [8.42303e-02 9.15770e-01]\n",
      " [3.09517e-02 9.69048e-01]\n",
      " [1.01843e-01 8.98157e-01]\n",
      " [5.15530e-03 9.94845e-01]\n",
      " [2.20676e-01 7.79324e-01]\n",
      " [6.57957e-03 9.93420e-01]\n",
      " [7.53544e-03 9.92465e-01]\n",
      " [1.11824e-01 8.88176e-01]\n",
      " [2.69474e-02 9.73053e-01]\n",
      " [4.01359e-02 9.59864e-01]\n",
      " [4.38367e-01 5.61633e-01]\n",
      " [7.19344e-02 9.28066e-01]\n",
      " [1.47880e-02 9.85212e-01]\n",
      " [5.79359e-02 9.42064e-01]\n",
      " [1.10278e-01 8.89722e-01]\n",
      " [8.08324e-02 9.19168e-01]\n",
      " [1.24098e-02 9.87590e-01]\n",
      " [2.06474e-02 9.79353e-01]\n",
      " [8.49945e-02 9.15006e-01]\n",
      " [1.56218e-01 8.43782e-01]\n",
      " [4.14114e-02 9.58589e-01]\n",
      " [2.38254e-02 9.76175e-01]\n",
      " [2.50496e-02 9.74950e-01]\n",
      " [1.42256e-02 9.85774e-01]\n",
      " [3.00313e-02 9.69969e-01]\n",
      " [8.42348e-02 9.15765e-01]\n",
      " [3.83946e-01 6.16054e-01]\n",
      " [7.61137e-02 9.23886e-01]\n",
      " [3.08979e-02 9.69102e-01]\n",
      " [9.71151e-02 9.02885e-01]\n",
      " [3.08369e-02 9.69163e-01]\n",
      " [1.67426e-03 9.98326e-01]\n",
      " [1.48340e-02 9.85166e-01]\n",
      " [5.68251e-02 9.43175e-01]\n",
      " [2.32470e-02 9.76753e-01]\n",
      " [2.79159e-01 7.20841e-01]\n",
      " [3.08512e-02 9.69149e-01]\n",
      " [1.59292e-01 8.40708e-01]\n",
      " [5.30591e-03 9.94694e-01]\n",
      " [1.44451e-01 8.55549e-01]\n",
      " [1.35630e-02 9.86437e-01]\n",
      " [5.20515e-01 4.79485e-01]\n",
      " [1.21202e-01 8.78798e-01]\n",
      " [4.60007e-02 9.53999e-01]\n",
      " [2.20480e-01 7.79520e-01]\n",
      " [1.90297e-01 8.09703e-01]\n",
      " [7.67759e-03 9.92322e-01]\n",
      " [6.04587e-01 3.95413e-01]\n",
      " [2.75733e-02 9.72427e-01]\n",
      " [1.11221e-03 9.98888e-01]\n",
      " [4.42139e-01 5.57861e-01]\n",
      " [2.92506e-01 7.07494e-01]\n",
      " [7.42853e-02 9.25715e-01]\n",
      " [7.02244e-02 9.29776e-01]\n",
      " [3.00159e-02 9.69984e-01]\n",
      " [6.33537e-01 3.66463e-01]\n",
      " [1.89243e-02 9.81076e-01]\n",
      " [6.64626e-02 9.33537e-01]\n",
      " [7.16706e-03 9.92833e-01]\n",
      " [2.42807e-02 9.75719e-01]\n",
      " [1.81998e-02 9.81800e-01]\n",
      " [1.92022e-01 8.07978e-01]\n",
      " [7.28737e-02 9.27126e-01]\n",
      " [7.51192e-02 9.24881e-01]\n",
      " [3.64401e-03 9.96356e-01]\n",
      " [2.26397e-02 9.77360e-01]\n",
      " [1.62134e-01 8.37866e-01]\n",
      " [8.04609e-02 9.19539e-01]\n",
      " [4.72904e-01 5.27096e-01]\n",
      " [3.42583e-02 9.65742e-01]\n",
      " [2.14580e-02 9.78542e-01]\n",
      " [4.05105e-01 5.94895e-01]\n",
      " [9.42733e-03 9.90573e-01]\n",
      " [2.53773e-01 7.46227e-01]\n",
      " [1.27706e-01 8.72294e-01]\n",
      " [3.61578e-01 6.38422e-01]\n",
      " [4.61137e-01 5.38863e-01]\n",
      " [2.40830e-01 7.59170e-01]\n",
      " [1.09725e-01 8.90275e-01]\n",
      " [6.80902e-02 9.31910e-01]\n",
      " [6.53491e-02 9.34651e-01]\n",
      " [3.42414e-02 9.65759e-01]\n",
      " [1.04880e-01 8.95120e-01]\n",
      " [9.13655e-02 9.08634e-01]\n",
      " [1.02708e-01 8.97292e-01]\n",
      " [2.39928e-02 9.76007e-01]\n",
      " [1.75070e-02 9.82493e-01]\n",
      " [4.27662e-01 5.72338e-01]\n",
      " [1.93494e-01 8.06506e-01]\n",
      " [1.55131e-02 9.84487e-01]\n",
      " [8.23850e-03 9.91762e-01]\n",
      " [2.31070e-03 9.97689e-01]\n",
      " [1.45270e-01 8.54730e-01]\n",
      " [3.51574e-02 9.64843e-01]\n",
      " [4.63972e-02 9.53603e-01]\n",
      " [2.42406e-02 9.75759e-01]\n",
      " [3.44914e-03 9.96551e-01]\n",
      " [8.97182e-03 9.91028e-01]\n",
      " [1.15377e-01 8.84623e-01]\n",
      " [2.49985e-01 7.50015e-01]\n",
      " [4.64158e-02 9.53584e-01]\n",
      " [2.93649e-03 9.97064e-01]\n",
      " [1.22189e-01 8.77811e-01]\n",
      " [3.13841e-01 6.86159e-01]\n",
      " [2.63560e-02 9.73644e-01]\n",
      " [9.69474e-02 9.03053e-01]\n",
      " [5.31347e-02 9.46865e-01]\n",
      " [3.13332e-01 6.86668e-01]\n",
      " [9.04153e-02 9.09585e-01]\n",
      " [7.82492e-03 9.92175e-01]\n",
      " [3.28773e-01 6.71227e-01]\n",
      " [1.09649e-01 8.90351e-01]\n",
      " [2.67656e-01 7.32344e-01]\n",
      " [9.38847e-03 9.90612e-01]\n",
      " [9.83329e-02 9.01667e-01]\n",
      " [6.29981e-02 9.37002e-01]\n",
      " [5.55783e-02 9.44422e-01]\n",
      " [5.90725e-02 9.40927e-01]\n",
      " [8.86522e-03 9.91135e-01]\n",
      " [2.54571e-01 7.45429e-01]\n",
      " [4.01809e-01 5.98191e-01]\n",
      " [2.60346e-01 7.39654e-01]\n",
      " [3.43836e-01 6.56164e-01]\n",
      " [4.51371e-02 9.54863e-01]\n",
      " [4.70925e-03 9.95291e-01]\n",
      " [1.50070e-02 9.84993e-01]\n",
      " [1.91669e-02 9.80833e-01]\n",
      " [2.03341e-02 9.79666e-01]\n",
      " [4.35338e-02 9.56466e-01]\n",
      " [8.11363e-02 9.18864e-01]\n",
      " [2.75824e-01 7.24176e-01]\n",
      " [4.34498e-02 9.56550e-01]\n",
      " [1.19376e-01 8.80624e-01]\n",
      " [6.23910e-02 9.37609e-01]\n",
      " [1.02212e-01 8.97788e-01]\n",
      " [6.13614e-02 9.38639e-01]\n",
      " [7.01228e-03 9.92988e-01]\n",
      " [5.44801e-02 9.45520e-01]\n",
      " [7.15414e-02 9.28459e-01]\n",
      " [5.55753e-02 9.44425e-01]\n",
      " [2.93885e-01 7.06115e-01]\n",
      " [3.01540e-01 6.98460e-01]\n",
      " [1.31319e-01 8.68681e-01]\n",
      " [2.14693e-02 9.78531e-01]\n",
      " [9.25298e-02 9.07470e-01]\n",
      " [8.61642e-02 9.13836e-01]\n",
      " [3.75617e-03 9.96244e-01]\n",
      " [3.06408e-02 9.69359e-01]\n",
      " [5.09865e-01 4.90135e-01]\n",
      " [1.69326e-01 8.30674e-01]\n",
      " [2.61544e-02 9.73846e-01]\n",
      " [2.00214e-02 9.79979e-01]\n",
      " [8.96532e-02 9.10347e-01]\n",
      " [1.60262e-01 8.39738e-01]\n",
      " [1.42897e-02 9.85710e-01]\n",
      " [1.09881e-02 9.89012e-01]\n",
      " [9.16200e-02 9.08380e-01]\n",
      " [3.39939e-01 6.60061e-01]\n",
      " [1.47822e-01 8.52178e-01]\n",
      " [1.38951e-02 9.86105e-01]\n",
      " [1.26399e-02 9.87360e-01]\n",
      " [1.85671e-01 8.14329e-01]\n",
      " [1.67628e-01 8.32372e-01]\n",
      " [7.32664e-02 9.26734e-01]\n",
      " [3.02928e-03 9.96971e-01]\n",
      " [5.23630e-02 9.47637e-01]\n",
      " [5.08256e-02 9.49174e-01]\n",
      " [7.73447e-02 9.22655e-01]\n",
      " [7.59405e-02 9.24060e-01]\n",
      " [3.90525e-02 9.60948e-01]\n",
      " [4.52797e-02 9.54720e-01]\n",
      " [2.70911e-02 9.72909e-01]\n",
      " [2.80646e-01 7.19354e-01]\n",
      " [3.52848e-02 9.64715e-01]\n",
      " [8.29038e-02 9.17096e-01]\n",
      " [3.58599e-01 6.41401e-01]\n",
      " [1.96994e-01 8.03006e-01]\n",
      " [4.86615e-02 9.51339e-01]\n",
      " [2.22527e-01 7.77473e-01]\n",
      " [3.93173e-02 9.60683e-01]\n",
      " [4.08906e-01 5.91094e-01]\n",
      " [1.79902e-01 8.20098e-01]\n",
      " [3.30689e-02 9.66931e-01]\n",
      " [2.15859e-02 9.78414e-01]\n",
      " [3.62586e-03 9.96374e-01]\n",
      " [1.17642e-01 8.82358e-01]\n",
      " [1.69771e-02 9.83023e-01]\n",
      " [8.22857e-02 9.17714e-01]\n",
      " [1.59309e-01 8.40691e-01]\n",
      " [1.67049e-01 8.32951e-01]\n",
      " [4.58057e-02 9.54194e-01]\n",
      " [1.72475e-02 9.82753e-01]\n",
      " [4.04575e-02 9.59543e-01]\n",
      " [6.43526e-02 9.35647e-01]\n",
      " [2.88523e-02 9.71148e-01]\n",
      " [9.31871e-02 9.06813e-01]\n",
      " [3.90119e-02 9.60988e-01]\n",
      " [2.72263e-01 7.27737e-01]\n",
      " [2.75765e-02 9.72423e-01]\n",
      " [9.38701e-03 9.90613e-01]\n",
      " [2.95390e-02 9.70461e-01]\n",
      " [1.37091e-01 8.62909e-01]\n",
      " [1.60501e-01 8.39499e-01]\n",
      " [3.87011e-03 9.96130e-01]\n",
      " [1.34199e-02 9.86580e-01]\n",
      " [3.37999e-03 9.96620e-01]\n",
      " [2.45585e-02 9.75441e-01]\n",
      " [1.03641e-01 8.96359e-01]\n",
      " [7.54353e-03 9.92456e-01]\n",
      " [2.26899e-01 7.73101e-01]\n",
      " [6.75122e-02 9.32488e-01]\n",
      " [1.61369e-02 9.83863e-01]\n",
      " [2.74145e-02 9.72585e-01]\n",
      " [3.72118e-02 9.62788e-01]\n",
      " [4.08335e-03 9.95917e-01]\n",
      " [7.43015e-02 9.25698e-01]\n",
      " [3.30849e-03 9.96692e-01]\n",
      " [1.69771e-01 8.30229e-01]\n",
      " [2.72674e-02 9.72733e-01]\n",
      " [5.23876e-01 4.76124e-01]\n",
      " [1.25249e-01 8.74751e-01]\n",
      " [4.03125e-01 5.96875e-01]\n",
      " [2.10617e-02 9.78938e-01]\n",
      " [2.80172e-01 7.19828e-01]\n",
      " [7.21731e-02 9.27827e-01]\n",
      " [8.93650e-03 9.91063e-01]\n",
      " [2.11218e-04 9.99789e-01]\n",
      " [9.67653e-03 9.90323e-01]\n",
      " [1.26549e-02 9.87345e-01]\n",
      " [7.34991e-03 9.92650e-01]\n",
      " [1.45912e-01 8.54088e-01]\n",
      " [1.84973e-02 9.81503e-01]\n",
      " [5.17153e-02 9.48285e-01]\n",
      " [3.63198e-03 9.96368e-01]\n",
      " [1.98607e-01 8.01393e-01]\n",
      " [6.06110e-02 9.39389e-01]\n",
      " [4.42815e-02 9.55718e-01]\n",
      " [4.60784e-01 5.39216e-01]\n",
      " [5.97194e-01 4.02806e-01]\n",
      " [2.64875e-01 7.35125e-01]\n",
      " [9.50876e-02 9.04912e-01]\n",
      " [5.11531e-01 4.88469e-01]\n",
      " [3.88092e-01 6.11908e-01]\n",
      " [1.53325e-01 8.46675e-01]\n",
      " [7.14854e-03 9.92851e-01]\n",
      " [5.20435e-02 9.47956e-01]\n",
      " [3.83724e-03 9.96163e-01]\n",
      " [2.82421e-01 7.17579e-01]\n",
      " [1.47316e-01 8.52684e-01]\n",
      " [3.36205e-03 9.96638e-01]\n",
      " [4.80856e-03 9.95191e-01]\n",
      " [2.99903e-01 7.00097e-01]\n",
      " [3.58234e-01 6.41766e-01]\n",
      " [5.47505e-01 4.52495e-01]\n",
      " [7.60601e-02 9.23940e-01]\n",
      " [6.31698e-02 9.36830e-01]\n",
      " [4.64456e-02 9.53554e-01]\n",
      " [1.14117e-01 8.85883e-01]\n",
      " [4.44774e-01 5.55226e-01]\n",
      " [2.99675e-02 9.70032e-01]\n",
      " [4.60686e-02 9.53931e-01]\n",
      " [1.57623e-01 8.42377e-01]\n",
      " [2.46155e-01 7.53845e-01]\n",
      " [5.63044e-03 9.94370e-01]\n",
      " [3.96275e-02 9.60372e-01]\n",
      " [9.46257e-03 9.90537e-01]\n",
      " [1.86774e-03 9.98132e-01]\n",
      " [3.39016e-02 9.66098e-01]\n",
      " [5.61196e-02 9.43880e-01]\n",
      " [1.18822e-02 9.88118e-01]\n",
      " [6.32142e-02 9.36786e-01]\n",
      " [2.23881e-01 7.76119e-01]\n",
      " [3.18620e-01 6.81380e-01]\n",
      " [1.12371e-02 9.88763e-01]\n",
      " [2.47076e-03 9.97529e-01]\n",
      " [4.09267e-02 9.59073e-01]\n",
      " [3.95295e-01 6.04705e-01]\n",
      " [4.03797e-02 9.59620e-01]\n",
      " [3.27809e-02 9.67219e-01]\n",
      " [2.84388e-01 7.15612e-01]\n",
      " [4.84100e-02 9.51590e-01]\n",
      " [6.78232e-01 3.21768e-01]\n",
      " [9.77817e-02 9.02218e-01]\n",
      " [2.69734e-02 9.73027e-01]\n",
      " [7.81411e-02 9.21859e-01]\n",
      " [1.02559e-01 8.97441e-01]\n",
      " [1.33906e-01 8.66094e-01]\n",
      " [3.80889e-03 9.96191e-01]\n",
      " [9.56316e-02 9.04368e-01]\n",
      " [1.37994e-01 8.62006e-01]\n",
      " [2.86244e-02 9.71376e-01]\n",
      " [1.27141e-02 9.87286e-01]\n",
      " [1.18363e-01 8.81637e-01]\n",
      " [6.19890e-02 9.38011e-01]\n",
      " [7.96732e-03 9.92033e-01]\n",
      " [2.20426e-02 9.77957e-01]\n",
      " [2.70956e-02 9.72904e-01]\n",
      " [5.40862e-02 9.45914e-01]\n",
      " [3.14731e-02 9.68527e-01]\n",
      " [1.11528e-02 9.88847e-01]\n",
      " [2.32315e-01 7.67685e-01]\n",
      " [4.13587e-02 9.58641e-01]\n",
      " [9.37057e-03 9.90629e-01]\n",
      " [1.17337e-01 8.82663e-01]\n",
      " [1.18598e-02 9.88140e-01]\n",
      " [2.99344e-02 9.70066e-01]\n",
      " [2.16793e-02 9.78321e-01]\n",
      " [6.66417e-01 3.33583e-01]\n",
      " [2.22545e-01 7.77455e-01]\n",
      " [1.91114e-01 8.08886e-01]\n",
      " [1.92326e-02 9.80767e-01]\n",
      " [3.27436e-02 9.67256e-01]\n",
      " [4.37741e-02 9.56226e-01]\n",
      " [1.70178e-01 8.29822e-01]\n",
      " [9.49033e-02 9.05097e-01]\n",
      " [1.96291e-01 8.03709e-01]\n",
      " [7.76406e-02 9.22359e-01]\n",
      " [2.81744e-01 7.18256e-01]\n",
      " [2.40079e-01 7.59921e-01]\n",
      " [1.07267e-01 8.92733e-01]\n",
      " [4.20242e-02 9.57976e-01]\n",
      " [6.76449e-02 9.32355e-01]\n",
      " [2.85789e-02 9.71421e-01]\n",
      " [4.86702e-01 5.13298e-01]\n",
      " [3.39509e-01 6.60491e-01]\n",
      " [2.85225e-01 7.14775e-01]\n",
      " [6.19865e-03 9.93801e-01]\n",
      " [3.77031e-01 6.22969e-01]\n",
      " [1.05408e-01 8.94592e-01]\n",
      " [4.48475e-03 9.95515e-01]\n",
      " [1.01827e-01 8.98173e-01]\n",
      " [2.12965e-02 9.78704e-01]\n",
      " [3.68693e-02 9.63131e-01]\n",
      " [5.12145e-03 9.94879e-01]\n",
      " [1.16040e-02 9.88396e-01]\n",
      " [1.42579e-01 8.57421e-01]\n",
      " [1.28085e-02 9.87191e-01]\n",
      " [3.15149e-02 9.68485e-01]\n",
      " [1.49890e-01 8.50110e-01]\n",
      " [1.70629e-02 9.82937e-01]\n",
      " [2.25482e-02 9.77452e-01]\n",
      " [1.76529e-01 8.23471e-01]\n",
      " [1.75787e-02 9.82421e-01]\n",
      " [1.37390e-01 8.62610e-01]\n",
      " [6.57046e-01 3.42954e-01]\n",
      " [4.30001e-01 5.69999e-01]\n",
      " [1.01603e-01 8.98397e-01]\n",
      " [1.01359e-01 8.98641e-01]\n",
      " [1.98544e-01 8.01456e-01]\n",
      " [6.71152e-01 3.28848e-01]\n",
      " [8.02123e-02 9.19788e-01]\n",
      " [5.49059e-02 9.45094e-01]\n",
      " [1.95412e-01 8.04588e-01]\n",
      " [5.87633e-03 9.94124e-01]\n",
      " [2.99757e-02 9.70024e-01]\n",
      " [2.19899e-01 7.80101e-01]\n",
      " [1.71072e-02 9.82893e-01]\n",
      " [7.56574e-02 9.24343e-01]\n",
      " [2.86294e-02 9.71371e-01]\n",
      " [2.28223e-03 9.97718e-01]\n",
      " [7.18861e-02 9.28114e-01]\n",
      " [2.34469e-01 7.65531e-01]\n",
      " [9.83998e-03 9.90160e-01]\n",
      " [6.22419e-02 9.37758e-01]\n",
      " [1.25791e-01 8.74209e-01]\n",
      " [3.01041e-01 6.98959e-01]\n",
      " [1.97800e-02 9.80220e-01]\n",
      " [8.31413e-02 9.16859e-01]\n",
      " [3.35015e-01 6.64985e-01]\n",
      " [7.91860e-02 9.20814e-01]\n",
      " [9.62779e-02 9.03722e-01]\n",
      " [1.20247e-02 9.87975e-01]\n",
      " [5.37001e-01 4.62999e-01]\n",
      " [5.09721e-03 9.94903e-01]\n",
      " [6.62803e-01 3.37197e-01]\n",
      " [1.10995e-02 9.88900e-01]\n",
      " [8.94855e-02 9.10515e-01]\n",
      " [7.61803e-03 9.92382e-01]\n",
      " [1.77384e-02 9.82262e-01]\n",
      " [1.08118e-01 8.91882e-01]\n",
      " [3.78564e-03 9.96214e-01]\n",
      " [6.96417e-02 9.30358e-01]\n",
      " [1.61537e-01 8.38463e-01]\n",
      " [3.37795e-02 9.66221e-01]\n",
      " [1.80120e-02 9.81988e-01]\n",
      " [7.35277e-02 9.26472e-01]\n",
      " [2.27236e-02 9.77276e-01]\n",
      " [3.81102e-01 6.18898e-01]\n",
      " [4.94417e-02 9.50558e-01]\n",
      " [2.15027e-01 7.84973e-01]\n",
      " [3.01580e-01 6.98420e-01]\n",
      " [1.91527e-01 8.08473e-01]\n",
      " [8.88865e-02 9.11114e-01]\n",
      " [6.87357e-02 9.31264e-01]\n",
      " [3.85587e-03 9.96144e-01]\n",
      " [2.46687e-02 9.75331e-01]\n",
      " [2.51609e-02 9.74839e-01]\n",
      " [1.47138e-02 9.85286e-01]\n",
      " [1.73194e-01 8.26806e-01]\n",
      " [1.93055e-02 9.80694e-01]\n",
      " [4.95729e-03 9.95043e-01]\n",
      " [4.33218e-02 9.56678e-01]\n",
      " [3.33918e-02 9.66608e-01]\n",
      " [5.43077e-02 9.45692e-01]\n",
      " [2.04581e-01 7.95419e-01]\n",
      " [3.35779e-02 9.66422e-01]\n",
      " [2.62752e-01 7.37248e-01]\n",
      " [4.90128e-01 5.09872e-01]\n",
      " [5.32443e-01 4.67557e-01]\n",
      " [1.94300e-02 9.80570e-01]\n",
      " [2.75793e-01 7.24207e-01]\n",
      " [1.01296e-01 8.98704e-01]\n",
      " [1.59207e-02 9.84079e-01]\n",
      " [1.27247e-01 8.72753e-01]\n",
      " [1.48239e-01 8.51761e-01]\n",
      " [4.28872e-01 5.71128e-01]\n",
      " [9.51137e-02 9.04886e-01]\n",
      " [4.34834e-01 5.65166e-01]\n",
      " [5.95559e-03 9.94044e-01]\n",
      " [1.27969e-01 8.72031e-01]\n",
      " [1.25042e-01 8.74958e-01]\n",
      " [6.14692e-02 9.38531e-01]\n",
      " [2.55376e-02 9.74462e-01]\n",
      " [6.04720e-02 9.39528e-01]\n",
      " [7.55515e-02 9.24449e-01]\n",
      " [4.63271e-03 9.95367e-01]\n",
      " [4.52238e-01 5.47762e-01]\n",
      " [7.23237e-03 9.92768e-01]\n",
      " [1.01967e-02 9.89803e-01]\n",
      " [8.41052e-03 9.91589e-01]\n",
      " [1.62797e-01 8.37203e-01]\n",
      " [1.09312e-01 8.90688e-01]\n",
      " [2.78658e-01 7.21342e-01]\n",
      " [9.52376e-02 9.04762e-01]\n",
      " [9.91749e-02 9.00825e-01]\n",
      " [1.70956e-01 8.29044e-01]\n",
      " [4.03634e-02 9.59637e-01]\n",
      " [1.50162e-01 8.49838e-01]\n",
      " [4.38587e-03 9.95614e-01]\n",
      " [1.55469e-01 8.44531e-01]\n",
      " [3.32592e-03 9.96674e-01]\n",
      " [3.05448e-03 9.96946e-01]\n",
      " [5.23500e-01 4.76500e-01]\n",
      " [6.42125e-02 9.35788e-01]\n",
      " [1.64692e-01 8.35308e-01]\n",
      " [6.26725e-02 9.37328e-01]\n",
      " [2.88966e-02 9.71103e-01]\n",
      " [1.30576e-01 8.69424e-01]\n",
      " [6.48566e-02 9.35143e-01]\n",
      " [4.02595e-01 5.97405e-01]\n",
      " [1.97834e-01 8.02166e-01]\n",
      " [3.30732e-02 9.66927e-01]\n",
      " [8.65344e-03 9.91347e-01]\n",
      " [1.23979e-01 8.76021e-01]\n",
      " [9.07454e-03 9.90925e-01]\n",
      " [8.38842e-02 9.16116e-01]\n",
      " [1.04341e-01 8.95659e-01]\n",
      " [1.06606e-01 8.93394e-01]\n",
      " [9.10308e-02 9.08969e-01]\n",
      " [4.85567e-01 5.14433e-01]\n",
      " [4.34100e-02 9.56590e-01]\n",
      " [3.70192e-01 6.29808e-01]\n",
      " [2.83862e-02 9.71614e-01]\n",
      " [6.15759e-02 9.38424e-01]\n",
      " [1.45777e-02 9.85422e-01]\n",
      " [4.60582e-01 5.39418e-01]\n",
      " [5.31670e-01 4.68330e-01]\n",
      " [4.09146e-01 5.90854e-01]\n",
      " [3.35898e-02 9.66410e-01]\n",
      " [6.58993e-03 9.93410e-01]\n",
      " [6.15633e-01 3.84367e-01]\n",
      " [1.85563e-02 9.81444e-01]\n",
      " [1.13952e-01 8.86048e-01]\n",
      " [1.35186e-02 9.86481e-01]\n",
      " [2.32372e-02 9.76763e-01]\n",
      " [1.36721e-01 8.63279e-01]\n",
      " [8.84058e-03 9.91159e-01]\n",
      " [1.59774e-02 9.84023e-01]\n",
      " [2.70547e-01 7.29453e-01]\n",
      " [3.06864e-01 6.93136e-01]\n",
      " [2.79555e-03 9.97204e-01]\n",
      " [1.17147e-02 9.88285e-01]\n",
      " [8.32528e-02 9.16747e-01]\n",
      " [8.14200e-02 9.18580e-01]\n",
      " [5.52976e-02 9.44702e-01]\n",
      " [4.78763e-02 9.52124e-01]\n",
      " [1.96949e-01 8.03051e-01]\n",
      " [7.52039e-02 9.24796e-01]\n",
      " [7.55414e-02 9.24459e-01]\n",
      " [1.24278e-02 9.87572e-01]\n",
      " [8.23243e-01 1.76757e-01]\n",
      " [7.95909e-02 9.20409e-01]\n",
      " [4.35541e-01 5.64459e-01]\n",
      " [2.34962e-01 7.65038e-01]\n",
      " [4.35563e-02 9.56444e-01]\n",
      " [3.13711e-02 9.68629e-01]\n",
      " [5.51923e-03 9.94481e-01]\n",
      " [4.50285e-01 5.49715e-01]\n",
      " [1.88928e-01 8.11072e-01]\n",
      " [1.50232e-02 9.84977e-01]\n",
      " [3.27483e-03 9.96725e-01]\n",
      " [1.51221e-02 9.84878e-01]\n",
      " [4.68639e-02 9.53136e-01]\n",
      " [9.43399e-03 9.90566e-01]\n",
      " [3.72416e-03 9.96276e-01]\n",
      " [1.42642e-02 9.85736e-01]\n",
      " [7.19653e-03 9.92803e-01]\n",
      " [3.49267e-02 9.65073e-01]\n",
      " [2.07891e-01 7.92109e-01]\n",
      " [1.40746e-01 8.59254e-01]\n",
      " [1.64822e-01 8.35178e-01]\n",
      " [3.93788e-02 9.60621e-01]\n",
      " [8.42853e-02 9.15715e-01]\n",
      " [8.36708e-02 9.16329e-01]\n",
      " [4.16149e-02 9.58385e-01]\n",
      " [6.78320e-02 9.32168e-01]\n",
      " [3.35858e-02 9.66414e-01]\n",
      " [1.09008e-02 9.89099e-01]\n",
      " [1.19442e-02 9.88056e-01]\n",
      " [3.99501e-01 6.00499e-01]\n",
      " [6.54101e-03 9.93459e-01]\n",
      " [1.72310e-01 8.27690e-01]\n",
      " [2.54925e-01 7.45075e-01]\n",
      " [6.86289e-03 9.93137e-01]\n",
      " [7.68228e-02 9.23177e-01]\n",
      " [2.38334e-01 7.61666e-01]\n",
      " [1.37121e-01 8.62879e-01]\n",
      " [5.21075e-03 9.94789e-01]\n",
      " [6.81919e-02 9.31808e-01]\n",
      " [2.90681e-01 7.09319e-01]\n",
      " [8.05964e-02 9.19404e-01]\n",
      " [7.14842e-02 9.28516e-01]\n",
      " [1.43017e-01 8.56983e-01]\n",
      " [2.44219e-01 7.55781e-01]\n",
      " [1.36737e-01 8.63263e-01]\n",
      " [8.29500e-03 9.91705e-01]\n",
      " [2.58653e-01 7.41347e-01]\n",
      " [1.02771e-01 8.97229e-01]\n",
      " [1.58994e-02 9.84101e-01]\n",
      " [7.53902e-02 9.24610e-01]\n",
      " [8.01230e-02 9.19877e-01]\n",
      " [4.05129e-02 9.59487e-01]\n",
      " [1.50641e-02 9.84936e-01]\n",
      " [1.46780e-02 9.85322e-01]\n",
      " [2.10966e-01 7.89034e-01]\n",
      " [7.75335e-02 9.22466e-01]\n",
      " [1.01067e-01 8.98933e-01]\n",
      " [9.11601e-02 9.08840e-01]\n",
      " [4.51792e-03 9.95482e-01]\n",
      " [1.28900e-02 9.87110e-01]\n",
      " [1.10003e-02 9.89000e-01]\n",
      " [1.41603e-01 8.58397e-01]\n",
      " [2.92244e-02 9.70776e-01]\n",
      " [1.38176e-01 8.61824e-01]\n",
      " [1.63458e-03 9.98365e-01]\n",
      " [2.50320e-02 9.74968e-01]\n",
      " [4.04688e-02 9.59531e-01]\n",
      " [6.49682e-02 9.35032e-01]\n",
      " [5.61038e-02 9.43896e-01]\n",
      " [9.26456e-03 9.90735e-01]\n",
      " [3.22392e-02 9.67761e-01]\n",
      " [1.81087e-02 9.81891e-01]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(prb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=LinearSVC(C=0.01, class_weight='balanced',\n",
       "                                                dual=True, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                loss='squared_hinge',\n",
       "                                                max_iter=10000,\n",
       "                                                multi_class='ovr', penalty='l2',\n",
       "                                                random_state=None, tol=0.0001,\n",
       "                                                verbose=0),\n",
       "                       cv=10, method='isotonic')"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated = SVCclbr(clf3, method='isotonic', cv='prefit')\n",
    "calibrate1 = SVCclbr(clf3, method='sigmoid', cv='prefit')\n",
    "calibrate2 = SVCclbr(clfLC, method='sigmoid', cv='prefit')\n",
    "calib= SVCclbr(clf3, method='isotonic', cv=10)\n",
    "calibrated.fit(X_train, y_train)\n",
    "calibrate1.fit(X_train, y_train)\n",
    "calibrate2.fit(X_train, y_train)\n",
    "calib.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "#print(calibrated.predict_proba(X_test)[:,1])\n",
    "\n",
    "#inpTech=[' #userexperience #ux heart #digitaltransformation @rautsan read #digital #innovation #ai #artificialintelligence #ml #machinelearning #deeplearning #dl Cc @dpatil @hackingdata']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "from matplotlib import pyplot\n",
    "# predict probabilities\n",
    "probs = calibrated.predict_proba(X_test)[:, 1]\n",
    "probs2=calibrate2.predict_proba(X_test)[:, 1]\n",
    "# reliability diagram\n",
    "fop, mpv = calibration_curve(y_train, probtrn, n_bins=10, normalize=True)\n",
    "# plot perfectly calibrated\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot calibrated reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (brier_score_loss, precision_score, recall_score, f1_score)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr = LogisticRegression(C=1, solver='lbfgs')\n",
    "nb = GaussianNB()\n",
    "svc = SVC(max_iter=10000,probability =True)\n",
    "\n",
    "clf_list=[lr,nb,svc]\n",
    "for clfs in clf_list:\n",
    "    clf = CalibratedClassifierCV(clfs,method='isotonic',cv=5)\n",
    "    clf.fit(X_train,y_train)\n",
    "    pos_prob = clf.predict_proba(X_test)[:,1]\n",
    "    sortedY,sortedYhat=outputsort(y_test,pos_prob)\n",
    "    print(clf)\n",
    "    calib_plot(sortedY,sortedYhat,10000)\n",
    "    clf_score = brier_score_loss(y_test, pos_prob, pos_label=y.max())\n",
    "    print('Brier Score: '+str(clf_score))\n",
    "    print('='*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\tekin\\\\Desktop\\\\ML\\\\Tweedy\\\\deploy\\\\TechnologySVCPipe.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe2,r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\TechnologySVCPipe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clfTech=joblib.load(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\TechnologySVCPipe.pkl')\n",
    "clfBsns=joblib.load(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\deploy\\BusinessSVCPipe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del prb1,prb2\n",
    "inpBsns=['By_statistacharts US import 2.66 million light vehicle worth total 52.6 billion #mexico plus another59.4 billion worth part via @commercegov #mexicotariffs']\n",
    "inpTech=['By_ronald_vanloon #userexperience #ux heart #digitaltransformation @rautsan read #digital #innovation #ai #artificialintelligence #ml #machinelearning #deeplearning #dl Cc @dpatil @hackingdata']\n",
    "inp=['not any is']\n",
    "prb1=clfBsns.predict(inpBsns)\n",
    "prb2=clfTech.predict(inpTech)\n",
    "clbprdc\n",
    "print(prb1)\n",
    "prb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('vect', TweetVect(lowercase=False, max_features=1500, min_df=1, ngram_range=(1, 5),\n",
      "          stop_words=None, token_pattern='\\\\S+', tokenizer=None)), ('prep', MinMaxScaler(copy=True, feature_range=(0, 1))), ('classifier', SVC(C=0.001, break_ties=False, cache_size=200, class_weight='balanced',\n",
      "    coef0=0.0, decision_function_shape='ovr', degree=3, gamma='auto',\n",
      "    kernel='rbf', max_iter=3000, probability=True, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False))]\n"
     ]
    }
   ],
   "source": [
    "x=pipe2.steps\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11087946876689059\n"
     ]
    }
   ],
   "source": [
    "xx=pipe2.score(X_train,y_train)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.35255\tvalidation_1-error:0.35979\n",
      "[1]\tvalidation_0-error:0.35057\tvalidation_1-error:0.38056\n",
      "[2]\tvalidation_0-error:0.31354\tvalidation_1-error:0.34421\n",
      "[3]\tvalidation_0-error:0.34018\tvalidation_1-error:0.34867\n",
      "[4]\tvalidation_0-error:0.34835\tvalidation_1-error:0.35460\n",
      "[5]\tvalidation_0-error:0.33185\tvalidation_1-error:0.33680\n",
      "[6]\tvalidation_0-error:0.32946\tvalidation_1-error:0.33309\n",
      "[7]\tvalidation_0-error:0.32987\tvalidation_1-error:0.33309\n",
      "[8]\tvalidation_0-error:0.32649\tvalidation_1-error:0.33160\n",
      "[9]\tvalidation_0-error:0.32723\tvalidation_1-error:0.33160\n",
      "[10]\tvalidation_0-error:0.32805\tvalidation_1-error:0.33309\n",
      "[11]\tvalidation_0-error:0.31411\tvalidation_1-error:0.32493\n",
      "[12]\tvalidation_0-error:0.31164\tvalidation_1-error:0.32493\n",
      "[13]\tvalidation_0-error:0.31172\tvalidation_1-error:0.32418\n",
      "[14]\tvalidation_0-error:0.30529\tvalidation_1-error:0.31825\n",
      "[15]\tvalidation_0-error:0.30273\tvalidation_1-error:0.31306\n",
      "[16]\tvalidation_0-error:0.30182\tvalidation_1-error:0.31454\n",
      "[17]\tvalidation_0-error:0.30199\tvalidation_1-error:0.31380\n",
      "[18]\tvalidation_0-error:0.29918\tvalidation_1-error:0.31157\n",
      "[19]\tvalidation_0-error:0.30149\tvalidation_1-error:0.31825\n",
      "[20]\tvalidation_0-error:0.30001\tvalidation_1-error:0.31677\n",
      "[21]\tvalidation_0-error:0.29712\tvalidation_1-error:0.31232\n",
      "[22]\tvalidation_0-error:0.29399\tvalidation_1-error:0.30490\n",
      "[23]\tvalidation_0-error:0.29192\tvalidation_1-error:0.30267\n",
      "[24]\tvalidation_0-error:0.28747\tvalidation_1-error:0.30564\n",
      "[25]\tvalidation_0-error:0.28755\tvalidation_1-error:0.30638\n",
      "[26]\tvalidation_0-error:0.28549\tvalidation_1-error:0.30490\n",
      "[27]\tvalidation_0-error:0.28747\tvalidation_1-error:0.30861\n",
      "[28]\tvalidation_0-error:0.28755\tvalidation_1-error:0.30119\n",
      "[29]\tvalidation_0-error:0.28203\tvalidation_1-error:0.29822\n",
      "[30]\tvalidation_0-error:0.27625\tvalidation_1-error:0.29748\n",
      "[31]\tvalidation_0-error:0.27526\tvalidation_1-error:0.29599\n",
      "[32]\tvalidation_0-error:0.27543\tvalidation_1-error:0.29525\n",
      "[33]\tvalidation_0-error:0.27188\tvalidation_1-error:0.29303\n",
      "[34]\tvalidation_0-error:0.27138\tvalidation_1-error:0.29377\n",
      "[35]\tvalidation_0-error:0.27287\tvalidation_1-error:0.29303\n",
      "[36]\tvalidation_0-error:0.27262\tvalidation_1-error:0.29377\n",
      "[37]\tvalidation_0-error:0.27312\tvalidation_1-error:0.29525\n",
      "[38]\tvalidation_0-error:0.26990\tvalidation_1-error:0.29377\n",
      "[39]\tvalidation_0-error:0.26891\tvalidation_1-error:0.29154\n",
      "[40]\tvalidation_0-error:0.26635\tvalidation_1-error:0.28858\n",
      "[41]\tvalidation_0-error:0.26553\tvalidation_1-error:0.28783\n",
      "[42]\tvalidation_0-error:0.26248\tvalidation_1-error:0.28635\n",
      "[43]\tvalidation_0-error:0.26223\tvalidation_1-error:0.28561\n",
      "[44]\tvalidation_0-error:0.26479\tvalidation_1-error:0.28264\n",
      "[45]\tvalidation_0-error:0.26157\tvalidation_1-error:0.28561\n",
      "[46]\tvalidation_0-error:0.26363\tvalidation_1-error:0.28264\n",
      "[47]\tvalidation_0-error:0.26149\tvalidation_1-error:0.28338\n",
      "[48]\tvalidation_0-error:0.26124\tvalidation_1-error:0.28338\n",
      "[49]\tvalidation_0-error:0.26190\tvalidation_1-error:0.28413\n",
      "[50]\tvalidation_0-error:0.26190\tvalidation_1-error:0.28338\n",
      "[51]\tvalidation_0-error:0.26074\tvalidation_1-error:0.28190\n",
      "[52]\tvalidation_0-error:0.25942\tvalidation_1-error:0.28116\n",
      "[53]\tvalidation_0-error:0.25695\tvalidation_1-error:0.28116\n",
      "[54]\tvalidation_0-error:0.25629\tvalidation_1-error:0.27671\n",
      "[55]\tvalidation_0-error:0.25546\tvalidation_1-error:0.27671\n",
      "[56]\tvalidation_0-error:0.25546\tvalidation_1-error:0.27596\n",
      "[57]\tvalidation_0-error:0.25439\tvalidation_1-error:0.27596\n",
      "[58]\tvalidation_0-error:0.25258\tvalidation_1-error:0.27522\n",
      "[59]\tvalidation_0-error:0.25225\tvalidation_1-error:0.27448\n",
      "[60]\tvalidation_0-error:0.25167\tvalidation_1-error:0.27300\n",
      "[61]\tvalidation_0-error:0.25076\tvalidation_1-error:0.27300\n",
      "[62]\tvalidation_0-error:0.25043\tvalidation_1-error:0.27374\n",
      "[63]\tvalidation_0-error:0.25002\tvalidation_1-error:0.27300\n",
      "[64]\tvalidation_0-error:0.24854\tvalidation_1-error:0.27077\n",
      "[65]\tvalidation_0-error:0.24771\tvalidation_1-error:0.26780\n",
      "[66]\tvalidation_0-error:0.24680\tvalidation_1-error:0.26484\n",
      "[67]\tvalidation_0-error:0.24689\tvalidation_1-error:0.26335\n",
      "[68]\tvalidation_0-error:0.24590\tvalidation_1-error:0.26261\n",
      "[69]\tvalidation_0-error:0.24532\tvalidation_1-error:0.26335\n",
      "[70]\tvalidation_0-error:0.24499\tvalidation_1-error:0.26410\n",
      "[71]\tvalidation_0-error:0.24243\tvalidation_1-error:0.25816\n",
      "[72]\tvalidation_0-error:0.24185\tvalidation_1-error:0.25816\n",
      "[73]\tvalidation_0-error:0.24070\tvalidation_1-error:0.25964\n",
      "[74]\tvalidation_0-error:0.24012\tvalidation_1-error:0.25594\n",
      "[75]\tvalidation_0-error:0.23922\tvalidation_1-error:0.25445\n",
      "[76]\tvalidation_0-error:0.23913\tvalidation_1-error:0.25594\n",
      "[77]\tvalidation_0-error:0.23773\tvalidation_1-error:0.25519\n",
      "[78]\tvalidation_0-error:0.23715\tvalidation_1-error:0.25519\n",
      "[79]\tvalidation_0-error:0.23633\tvalidation_1-error:0.25445\n",
      "[80]\tvalidation_0-error:0.23575\tvalidation_1-error:0.25371\n",
      "[81]\tvalidation_0-error:0.23517\tvalidation_1-error:0.25223\n",
      "[82]\tvalidation_0-error:0.23410\tvalidation_1-error:0.25148\n",
      "[83]\tvalidation_0-error:0.23220\tvalidation_1-error:0.25000\n",
      "[84]\tvalidation_0-error:0.23163\tvalidation_1-error:0.24926\n",
      "[85]\tvalidation_0-error:0.23130\tvalidation_1-error:0.24926\n",
      "[86]\tvalidation_0-error:0.22989\tvalidation_1-error:0.24926\n",
      "[87]\tvalidation_0-error:0.22874\tvalidation_1-error:0.24852\n",
      "[88]\tvalidation_0-error:0.22866\tvalidation_1-error:0.24852\n",
      "[89]\tvalidation_0-error:0.22833\tvalidation_1-error:0.24852\n",
      "[90]\tvalidation_0-error:0.22742\tvalidation_1-error:0.24852\n",
      "[91]\tvalidation_0-error:0.22709\tvalidation_1-error:0.24777\n",
      "[92]\tvalidation_0-error:0.22668\tvalidation_1-error:0.24777\n",
      "[93]\tvalidation_0-error:0.22668\tvalidation_1-error:0.24703\n",
      "[94]\tvalidation_0-error:0.22453\tvalidation_1-error:0.24852\n",
      "[95]\tvalidation_0-error:0.22453\tvalidation_1-error:0.24926\n",
      "[96]\tvalidation_0-error:0.22445\tvalidation_1-error:0.25000\n",
      "[97]\tvalidation_0-error:0.22428\tvalidation_1-error:0.24926\n",
      "[98]\tvalidation_0-error:0.22445\tvalidation_1-error:0.25074\n",
      "[99]\tvalidation_0-error:0.22371\tvalidation_1-error:0.25074\n",
      "[100]\tvalidation_0-error:0.22346\tvalidation_1-error:0.25074\n",
      "[101]\tvalidation_0-error:0.22321\tvalidation_1-error:0.24926\n",
      "[102]\tvalidation_0-error:0.22206\tvalidation_1-error:0.24926\n",
      "[103]\tvalidation_0-error:0.22173\tvalidation_1-error:0.24852\n",
      "[104]\tvalidation_0-error:0.22181\tvalidation_1-error:0.24703\n",
      "[105]\tvalidation_0-error:0.22239\tvalidation_1-error:0.24703\n",
      "[106]\tvalidation_0-error:0.22313\tvalidation_1-error:0.24555\n",
      "[107]\tvalidation_0-error:0.22239\tvalidation_1-error:0.24555\n",
      "[108]\tvalidation_0-error:0.22222\tvalidation_1-error:0.24703\n",
      "[109]\tvalidation_0-error:0.22165\tvalidation_1-error:0.24777\n",
      "[110]\tvalidation_0-error:0.22024\tvalidation_1-error:0.24629\n",
      "[111]\tvalidation_0-error:0.21975\tvalidation_1-error:0.24629\n",
      "[112]\tvalidation_0-error:0.21934\tvalidation_1-error:0.24629\n",
      "[113]\tvalidation_0-error:0.21934\tvalidation_1-error:0.24703\n",
      "[114]\tvalidation_0-error:0.21950\tvalidation_1-error:0.24629\n",
      "[115]\tvalidation_0-error:0.21868\tvalidation_1-error:0.24555\n",
      "[116]\tvalidation_0-error:0.21843\tvalidation_1-error:0.24555\n",
      "[117]\tvalidation_0-error:0.21785\tvalidation_1-error:0.24555\n",
      "[118]\tvalidation_0-error:0.21793\tvalidation_1-error:0.24555\n",
      "[119]\tvalidation_0-error:0.21851\tvalidation_1-error:0.24184\n",
      "[120]\tvalidation_0-error:0.21628\tvalidation_1-error:0.24332\n",
      "[121]\tvalidation_0-error:0.21604\tvalidation_1-error:0.24258\n",
      "[122]\tvalidation_0-error:0.21571\tvalidation_1-error:0.24184\n",
      "[123]\tvalidation_0-error:0.21562\tvalidation_1-error:0.24184\n",
      "[124]\tvalidation_0-error:0.21496\tvalidation_1-error:0.24110\n",
      "[125]\tvalidation_0-error:0.21554\tvalidation_1-error:0.23665\n",
      "[126]\tvalidation_0-error:0.21521\tvalidation_1-error:0.23591\n",
      "[127]\tvalidation_0-error:0.21364\tvalidation_1-error:0.23887\n",
      "[128]\tvalidation_0-error:0.21315\tvalidation_1-error:0.23739\n",
      "[129]\tvalidation_0-error:0.21315\tvalidation_1-error:0.23813\n",
      "[130]\tvalidation_0-error:0.21340\tvalidation_1-error:0.23813\n",
      "[131]\tvalidation_0-error:0.21274\tvalidation_1-error:0.23813\n",
      "[132]\tvalidation_0-error:0.21191\tvalidation_1-error:0.23887\n",
      "[133]\tvalidation_0-error:0.21224\tvalidation_1-error:0.23961\n",
      "[134]\tvalidation_0-error:0.21125\tvalidation_1-error:0.23887\n",
      "[135]\tvalidation_0-error:0.21059\tvalidation_1-error:0.23739\n",
      "[136]\tvalidation_0-error:0.21043\tvalidation_1-error:0.23739\n",
      "[137]\tvalidation_0-error:0.21010\tvalidation_1-error:0.23813\n",
      "[138]\tvalidation_0-error:0.20960\tvalidation_1-error:0.23739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139]\tvalidation_0-error:0.20911\tvalidation_1-error:0.23813\n",
      "[140]\tvalidation_0-error:0.20894\tvalidation_1-error:0.23739\n",
      "[141]\tvalidation_0-error:0.20779\tvalidation_1-error:0.23665\n",
      "[142]\tvalidation_0-error:0.20770\tvalidation_1-error:0.23665\n",
      "[143]\tvalidation_0-error:0.20746\tvalidation_1-error:0.23665\n",
      "[144]\tvalidation_0-error:0.20729\tvalidation_1-error:0.23591\n",
      "[145]\tvalidation_0-error:0.20696\tvalidation_1-error:0.23516\n",
      "[146]\tvalidation_0-error:0.20680\tvalidation_1-error:0.23516\n",
      "[147]\tvalidation_0-error:0.20680\tvalidation_1-error:0.23516\n",
      "[148]\tvalidation_0-error:0.20688\tvalidation_1-error:0.23516\n",
      "[149]\tvalidation_0-error:0.20647\tvalidation_1-error:0.23516\n",
      "[150]\tvalidation_0-error:0.20639\tvalidation_1-error:0.23591\n",
      "[151]\tvalidation_0-error:0.20539\tvalidation_1-error:0.23591\n",
      "[152]\tvalidation_0-error:0.20515\tvalidation_1-error:0.23591\n",
      "[153]\tvalidation_0-error:0.20474\tvalidation_1-error:0.23591\n",
      "[154]\tvalidation_0-error:0.20424\tvalidation_1-error:0.23516\n",
      "[155]\tvalidation_0-error:0.20375\tvalidation_1-error:0.23368\n",
      "[156]\tvalidation_0-error:0.20375\tvalidation_1-error:0.23368\n",
      "[157]\tvalidation_0-error:0.20408\tvalidation_1-error:0.23220\n",
      "[158]\tvalidation_0-error:0.20408\tvalidation_1-error:0.23145\n",
      "[159]\tvalidation_0-error:0.20284\tvalidation_1-error:0.23368\n",
      "[160]\tvalidation_0-error:0.20267\tvalidation_1-error:0.23294\n",
      "[161]\tvalidation_0-error:0.20135\tvalidation_1-error:0.23220\n",
      "[162]\tvalidation_0-error:0.20078\tvalidation_1-error:0.23145\n",
      "[163]\tvalidation_0-error:0.20102\tvalidation_1-error:0.23145\n",
      "[164]\tvalidation_0-error:0.20020\tvalidation_1-error:0.23220\n",
      "[165]\tvalidation_0-error:0.19987\tvalidation_1-error:0.23294\n",
      "[166]\tvalidation_0-error:0.20020\tvalidation_1-error:0.23294\n",
      "[167]\tvalidation_0-error:0.20011\tvalidation_1-error:0.23145\n",
      "[168]\tvalidation_0-error:0.19954\tvalidation_1-error:0.23145\n",
      "[169]\tvalidation_0-error:0.19929\tvalidation_1-error:0.23071\n",
      "[170]\tvalidation_0-error:0.19871\tvalidation_1-error:0.23145\n",
      "[171]\tvalidation_0-error:0.19805\tvalidation_1-error:0.23071\n",
      "[172]\tvalidation_0-error:0.19772\tvalidation_1-error:0.23145\n",
      "[173]\tvalidation_0-error:0.19723\tvalidation_1-error:0.23145\n",
      "[174]\tvalidation_0-error:0.19731\tvalidation_1-error:0.23294\n",
      "[175]\tvalidation_0-error:0.19715\tvalidation_1-error:0.23220\n",
      "[176]\tvalidation_0-error:0.19665\tvalidation_1-error:0.23220\n",
      "[177]\tvalidation_0-error:0.19657\tvalidation_1-error:0.22997\n",
      "[178]\tvalidation_0-error:0.19640\tvalidation_1-error:0.22923\n",
      "[179]\tvalidation_0-error:0.19624\tvalidation_1-error:0.23071\n",
      "[180]\tvalidation_0-error:0.19574\tvalidation_1-error:0.23071\n",
      "[181]\tvalidation_0-error:0.19583\tvalidation_1-error:0.23220\n",
      "[182]\tvalidation_0-error:0.19533\tvalidation_1-error:0.23220\n",
      "[183]\tvalidation_0-error:0.19475\tvalidation_1-error:0.23220\n",
      "[184]\tvalidation_0-error:0.19426\tvalidation_1-error:0.23071\n",
      "[185]\tvalidation_0-error:0.19442\tvalidation_1-error:0.22997\n",
      "[186]\tvalidation_0-error:0.19418\tvalidation_1-error:0.22997\n",
      "[187]\tvalidation_0-error:0.19401\tvalidation_1-error:0.22849\n",
      "[188]\tvalidation_0-error:0.19385\tvalidation_1-error:0.22700\n",
      "[189]\tvalidation_0-error:0.19376\tvalidation_1-error:0.22775\n",
      "[190]\tvalidation_0-error:0.19385\tvalidation_1-error:0.22626\n",
      "[191]\tvalidation_0-error:0.19385\tvalidation_1-error:0.22626\n",
      "[192]\tvalidation_0-error:0.19368\tvalidation_1-error:0.22552\n",
      "[193]\tvalidation_0-error:0.19327\tvalidation_1-error:0.22552\n",
      "[194]\tvalidation_0-error:0.19294\tvalidation_1-error:0.22626\n",
      "[195]\tvalidation_0-error:0.19269\tvalidation_1-error:0.22478\n",
      "[196]\tvalidation_0-error:0.19269\tvalidation_1-error:0.22849\n",
      "[197]\tvalidation_0-error:0.19244\tvalidation_1-error:0.22997\n",
      "[198]\tvalidation_0-error:0.19211\tvalidation_1-error:0.22997\n",
      "[199]\tvalidation_0-error:0.19211\tvalidation_1-error:0.22997\n",
      "[200]\tvalidation_0-error:0.19170\tvalidation_1-error:0.22775\n",
      "[201]\tvalidation_0-error:0.19145\tvalidation_1-error:0.22700\n",
      "[202]\tvalidation_0-error:0.19137\tvalidation_1-error:0.22700\n",
      "[203]\tvalidation_0-error:0.19063\tvalidation_1-error:0.22775\n",
      "[204]\tvalidation_0-error:0.19022\tvalidation_1-error:0.22775\n",
      "[205]\tvalidation_0-error:0.18997\tvalidation_1-error:0.22775\n",
      "[206]\tvalidation_0-error:0.18997\tvalidation_1-error:0.22849\n",
      "[207]\tvalidation_0-error:0.18972\tvalidation_1-error:0.22775\n",
      "[208]\tvalidation_0-error:0.18956\tvalidation_1-error:0.22700\n",
      "[209]\tvalidation_0-error:0.18939\tvalidation_1-error:0.22700\n",
      "[210]\tvalidation_0-error:0.18948\tvalidation_1-error:0.22626\n",
      "[211]\tvalidation_0-error:0.18873\tvalidation_1-error:0.22700\n",
      "[212]\tvalidation_0-error:0.18890\tvalidation_1-error:0.22700\n",
      "[213]\tvalidation_0-error:0.18898\tvalidation_1-error:0.22775\n",
      "[214]\tvalidation_0-error:0.18882\tvalidation_1-error:0.22700\n",
      "[215]\tvalidation_0-error:0.18824\tvalidation_1-error:0.22626\n",
      "[216]\tvalidation_0-error:0.18832\tvalidation_1-error:0.22700\n",
      "[217]\tvalidation_0-error:0.18815\tvalidation_1-error:0.22626\n",
      "[218]\tvalidation_0-error:0.18774\tvalidation_1-error:0.22552\n",
      "[219]\tvalidation_0-error:0.18741\tvalidation_1-error:0.22552\n",
      "[220]\tvalidation_0-error:0.18716\tvalidation_1-error:0.22552\n",
      "[221]\tvalidation_0-error:0.18708\tvalidation_1-error:0.22552\n",
      "[222]\tvalidation_0-error:0.18684\tvalidation_1-error:0.22626\n",
      "[223]\tvalidation_0-error:0.18700\tvalidation_1-error:0.22626\n",
      "[224]\tvalidation_0-error:0.18675\tvalidation_1-error:0.22626\n",
      "[225]\tvalidation_0-error:0.18659\tvalidation_1-error:0.22700\n",
      "[226]\tvalidation_0-error:0.18642\tvalidation_1-error:0.22700\n",
      "[227]\tvalidation_0-error:0.18593\tvalidation_1-error:0.22700\n",
      "[228]\tvalidation_0-error:0.18568\tvalidation_1-error:0.22626\n",
      "[229]\tvalidation_0-error:0.18552\tvalidation_1-error:0.22626\n",
      "[230]\tvalidation_0-error:0.18568\tvalidation_1-error:0.22552\n",
      "[231]\tvalidation_0-error:0.18535\tvalidation_1-error:0.22700\n",
      "[232]\tvalidation_0-error:0.18527\tvalidation_1-error:0.22700\n",
      "[233]\tvalidation_0-error:0.18510\tvalidation_1-error:0.22700\n",
      "[234]\tvalidation_0-error:0.18527\tvalidation_1-error:0.22700\n",
      "[235]\tvalidation_0-error:0.18543\tvalidation_1-error:0.22626\n",
      "[236]\tvalidation_0-error:0.18469\tvalidation_1-error:0.22552\n",
      "[237]\tvalidation_0-error:0.18469\tvalidation_1-error:0.22626\n",
      "[238]\tvalidation_0-error:0.18419\tvalidation_1-error:0.22700\n",
      "[239]\tvalidation_0-error:0.18436\tvalidation_1-error:0.22700\n",
      "[240]\tvalidation_0-error:0.18403\tvalidation_1-error:0.22700\n",
      "[241]\tvalidation_0-error:0.18428\tvalidation_1-error:0.22775\n",
      "[242]\tvalidation_0-error:0.18387\tvalidation_1-error:0.22478\n",
      "[243]\tvalidation_0-error:0.18370\tvalidation_1-error:0.22626\n",
      "[244]\tvalidation_0-error:0.18304\tvalidation_1-error:0.22552\n",
      "[245]\tvalidation_0-error:0.18279\tvalidation_1-error:0.22626\n",
      "[246]\tvalidation_0-error:0.18263\tvalidation_1-error:0.22552\n",
      "[247]\tvalidation_0-error:0.18279\tvalidation_1-error:0.22700\n",
      "[248]\tvalidation_0-error:0.18271\tvalidation_1-error:0.22626\n",
      "[249]\tvalidation_0-error:0.18255\tvalidation_1-error:0.22626\n",
      "[250]\tvalidation_0-error:0.18246\tvalidation_1-error:0.22552\n",
      "[251]\tvalidation_0-error:0.18156\tvalidation_1-error:0.22329\n",
      "[252]\tvalidation_0-error:0.18172\tvalidation_1-error:0.22329\n",
      "[253]\tvalidation_0-error:0.18114\tvalidation_1-error:0.22552\n",
      "[254]\tvalidation_0-error:0.18131\tvalidation_1-error:0.22552\n",
      "[255]\tvalidation_0-error:0.18106\tvalidation_1-error:0.22552\n",
      "[256]\tvalidation_0-error:0.18114\tvalidation_1-error:0.22552\n",
      "[257]\tvalidation_0-error:0.18123\tvalidation_1-error:0.22552\n",
      "[258]\tvalidation_0-error:0.18131\tvalidation_1-error:0.22404\n",
      "[259]\tvalidation_0-error:0.18147\tvalidation_1-error:0.22404\n",
      "[260]\tvalidation_0-error:0.18123\tvalidation_1-error:0.22404\n",
      "[261]\tvalidation_0-error:0.18073\tvalidation_1-error:0.22404\n",
      "[262]\tvalidation_0-error:0.18007\tvalidation_1-error:0.22478\n",
      "[263]\tvalidation_0-error:0.18040\tvalidation_1-error:0.22329\n",
      "[264]\tvalidation_0-error:0.17974\tvalidation_1-error:0.22404\n",
      "[265]\tvalidation_0-error:0.17941\tvalidation_1-error:0.22404\n",
      "[266]\tvalidation_0-error:0.17933\tvalidation_1-error:0.22404\n",
      "[267]\tvalidation_0-error:0.17941\tvalidation_1-error:0.22255\n",
      "[268]\tvalidation_0-error:0.17933\tvalidation_1-error:0.22033\n",
      "[269]\tvalidation_0-error:0.17883\tvalidation_1-error:0.22033\n",
      "[270]\tvalidation_0-error:0.17826\tvalidation_1-error:0.21959\n",
      "[271]\tvalidation_0-error:0.17900\tvalidation_1-error:0.21959\n",
      "[272]\tvalidation_0-error:0.17826\tvalidation_1-error:0.22033\n",
      "[273]\tvalidation_0-error:0.17776\tvalidation_1-error:0.22181\n",
      "[274]\tvalidation_0-error:0.17776\tvalidation_1-error:0.22255\n",
      "[275]\tvalidation_0-error:0.17718\tvalidation_1-error:0.22181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[276]\tvalidation_0-error:0.17694\tvalidation_1-error:0.22181\n",
      "[277]\tvalidation_0-error:0.17694\tvalidation_1-error:0.22255\n",
      "[278]\tvalidation_0-error:0.17727\tvalidation_1-error:0.22329\n",
      "[279]\tvalidation_0-error:0.17669\tvalidation_1-error:0.22329\n",
      "[280]\tvalidation_0-error:0.17685\tvalidation_1-error:0.22255\n",
      "[281]\tvalidation_0-error:0.17636\tvalidation_1-error:0.22255\n",
      "[282]\tvalidation_0-error:0.17644\tvalidation_1-error:0.22255\n",
      "[283]\tvalidation_0-error:0.17595\tvalidation_1-error:0.22181\n",
      "[284]\tvalidation_0-error:0.17611\tvalidation_1-error:0.22255\n",
      "[285]\tvalidation_0-error:0.17611\tvalidation_1-error:0.22255\n",
      "[286]\tvalidation_0-error:0.17537\tvalidation_1-error:0.22478\n",
      "[287]\tvalidation_0-error:0.17504\tvalidation_1-error:0.22404\n",
      "[288]\tvalidation_0-error:0.17471\tvalidation_1-error:0.22404\n",
      "[289]\tvalidation_0-error:0.17413\tvalidation_1-error:0.22404\n",
      "[290]\tvalidation_0-error:0.17397\tvalidation_1-error:0.22552\n",
      "[291]\tvalidation_0-error:0.17388\tvalidation_1-error:0.22329\n",
      "[292]\tvalidation_0-error:0.17372\tvalidation_1-error:0.22329\n",
      "[293]\tvalidation_0-error:0.17372\tvalidation_1-error:0.22478\n",
      "[294]\tvalidation_0-error:0.17380\tvalidation_1-error:0.22478\n",
      "[295]\tvalidation_0-error:0.17388\tvalidation_1-error:0.22478\n",
      "[296]\tvalidation_0-error:0.17397\tvalidation_1-error:0.22329\n",
      "[297]\tvalidation_0-error:0.17397\tvalidation_1-error:0.22329\n",
      "[298]\tvalidation_0-error:0.17413\tvalidation_1-error:0.22404\n",
      "[299]\tvalidation_0-error:0.17413\tvalidation_1-error:0.22404\n",
      "[300]\tvalidation_0-error:0.17413\tvalidation_1-error:0.22478\n",
      "[301]\tvalidation_0-error:0.17388\tvalidation_1-error:0.22404\n",
      "[302]\tvalidation_0-error:0.17347\tvalidation_1-error:0.22478\n",
      "[303]\tvalidation_0-error:0.17355\tvalidation_1-error:0.22255\n",
      "[304]\tvalidation_0-error:0.17339\tvalidation_1-error:0.22255\n",
      "[305]\tvalidation_0-error:0.17331\tvalidation_1-error:0.22329\n",
      "[306]\tvalidation_0-error:0.17306\tvalidation_1-error:0.22329\n",
      "[307]\tvalidation_0-error:0.17281\tvalidation_1-error:0.22552\n",
      "[308]\tvalidation_0-error:0.17298\tvalidation_1-error:0.22552\n",
      "[309]\tvalidation_0-error:0.17240\tvalidation_1-error:0.22329\n",
      "[310]\tvalidation_0-error:0.17256\tvalidation_1-error:0.22329\n",
      "[311]\tvalidation_0-error:0.17223\tvalidation_1-error:0.22255\n",
      "[312]\tvalidation_0-error:0.17223\tvalidation_1-error:0.22255\n",
      "[313]\tvalidation_0-error:0.17256\tvalidation_1-error:0.22478\n",
      "[314]\tvalidation_0-error:0.17248\tvalidation_1-error:0.22478\n",
      "[315]\tvalidation_0-error:0.17256\tvalidation_1-error:0.22552\n",
      "[316]\tvalidation_0-error:0.17248\tvalidation_1-error:0.22478\n",
      "[317]\tvalidation_0-error:0.17248\tvalidation_1-error:0.22478\n",
      "[318]\tvalidation_0-error:0.17191\tvalidation_1-error:0.22404\n",
      "[319]\tvalidation_0-error:0.17174\tvalidation_1-error:0.22478\n",
      "[320]\tvalidation_0-error:0.17191\tvalidation_1-error:0.22478\n",
      "[321]\tvalidation_0-error:0.17182\tvalidation_1-error:0.22404\n",
      "[322]\tvalidation_0-error:0.17125\tvalidation_1-error:0.22181\n",
      "[323]\tvalidation_0-error:0.17141\tvalidation_1-error:0.22255\n",
      "[324]\tvalidation_0-error:0.17149\tvalidation_1-error:0.22107\n",
      "[325]\tvalidation_0-error:0.17149\tvalidation_1-error:0.22107\n",
      "[326]\tvalidation_0-error:0.17141\tvalidation_1-error:0.22033\n",
      "[327]\tvalidation_0-error:0.17133\tvalidation_1-error:0.21959\n",
      "[328]\tvalidation_0-error:0.17092\tvalidation_1-error:0.21884\n",
      "[329]\tvalidation_0-error:0.17075\tvalidation_1-error:0.21810\n",
      "[330]\tvalidation_0-error:0.17042\tvalidation_1-error:0.21736\n",
      "[331]\tvalidation_0-error:0.17042\tvalidation_1-error:0.21884\n",
      "[332]\tvalidation_0-error:0.17050\tvalidation_1-error:0.21959\n",
      "[333]\tvalidation_0-error:0.17058\tvalidation_1-error:0.21959\n",
      "[334]\tvalidation_0-error:0.17050\tvalidation_1-error:0.22181\n",
      "[335]\tvalidation_0-error:0.17034\tvalidation_1-error:0.22181\n",
      "[336]\tvalidation_0-error:0.17083\tvalidation_1-error:0.22181\n",
      "[337]\tvalidation_0-error:0.17067\tvalidation_1-error:0.22181\n",
      "[338]\tvalidation_0-error:0.17050\tvalidation_1-error:0.22329\n",
      "[339]\tvalidation_0-error:0.17050\tvalidation_1-error:0.22478\n",
      "[340]\tvalidation_0-error:0.17034\tvalidation_1-error:0.22404\n",
      "[341]\tvalidation_0-error:0.17083\tvalidation_1-error:0.22478\n",
      "[342]\tvalidation_0-error:0.17050\tvalidation_1-error:0.22478\n",
      "[343]\tvalidation_0-error:0.17042\tvalidation_1-error:0.22478\n",
      "[344]\tvalidation_0-error:0.17034\tvalidation_1-error:0.22478\n",
      "[345]\tvalidation_0-error:0.17025\tvalidation_1-error:0.22478\n",
      "[346]\tvalidation_0-error:0.17042\tvalidation_1-error:0.22552\n",
      "[347]\tvalidation_0-error:0.16968\tvalidation_1-error:0.22478\n",
      "[348]\tvalidation_0-error:0.16959\tvalidation_1-error:0.22478\n",
      "[349]\tvalidation_0-error:0.16910\tvalidation_1-error:0.22478\n",
      "[350]\tvalidation_0-error:0.16902\tvalidation_1-error:0.22404\n",
      "[351]\tvalidation_0-error:0.16877\tvalidation_1-error:0.22329\n",
      "[352]\tvalidation_0-error:0.16894\tvalidation_1-error:0.22329\n",
      "[353]\tvalidation_0-error:0.16926\tvalidation_1-error:0.22478\n",
      "[354]\tvalidation_0-error:0.16894\tvalidation_1-error:0.22329\n",
      "[355]\tvalidation_0-error:0.16852\tvalidation_1-error:0.22329\n",
      "[356]\tvalidation_0-error:0.16828\tvalidation_1-error:0.22181\n",
      "[357]\tvalidation_0-error:0.16778\tvalidation_1-error:0.22181\n",
      "[358]\tvalidation_0-error:0.16803\tvalidation_1-error:0.22181\n",
      "[359]\tvalidation_0-error:0.16803\tvalidation_1-error:0.22255\n",
      "[360]\tvalidation_0-error:0.16819\tvalidation_1-error:0.22255\n",
      "[361]\tvalidation_0-error:0.16803\tvalidation_1-error:0.22255\n",
      "[362]\tvalidation_0-error:0.16761\tvalidation_1-error:0.22404\n",
      "[363]\tvalidation_0-error:0.16745\tvalidation_1-error:0.22404\n",
      "[364]\tvalidation_0-error:0.16712\tvalidation_1-error:0.22255\n",
      "[365]\tvalidation_0-error:0.16728\tvalidation_1-error:0.22329\n",
      "[366]\tvalidation_0-error:0.16728\tvalidation_1-error:0.22329\n",
      "[367]\tvalidation_0-error:0.16745\tvalidation_1-error:0.22329\n",
      "[368]\tvalidation_0-error:0.16753\tvalidation_1-error:0.22329\n",
      "[369]\tvalidation_0-error:0.16737\tvalidation_1-error:0.22329\n",
      "[370]\tvalidation_0-error:0.16745\tvalidation_1-error:0.22329\n",
      "[371]\tvalidation_0-error:0.16728\tvalidation_1-error:0.22033\n",
      "[372]\tvalidation_0-error:0.16728\tvalidation_1-error:0.21959\n",
      "[373]\tvalidation_0-error:0.16687\tvalidation_1-error:0.22033\n",
      "[374]\tvalidation_0-error:0.16638\tvalidation_1-error:0.21959\n",
      "[375]\tvalidation_0-error:0.16621\tvalidation_1-error:0.22033\n",
      "[376]\tvalidation_0-error:0.16629\tvalidation_1-error:0.21959\n",
      "[377]\tvalidation_0-error:0.16621\tvalidation_1-error:0.21959\n",
      "[378]\tvalidation_0-error:0.16597\tvalidation_1-error:0.22033\n",
      "[379]\tvalidation_0-error:0.16605\tvalidation_1-error:0.22033\n",
      "[380]\tvalidation_0-error:0.16613\tvalidation_1-error:0.22033\n",
      "[381]\tvalidation_0-error:0.16646\tvalidation_1-error:0.22033\n",
      "[382]\tvalidation_0-error:0.16629\tvalidation_1-error:0.22033\n",
      "[383]\tvalidation_0-error:0.16638\tvalidation_1-error:0.21810\n",
      "[384]\tvalidation_0-error:0.16597\tvalidation_1-error:0.21736\n",
      "[385]\tvalidation_0-error:0.16605\tvalidation_1-error:0.21736\n",
      "[386]\tvalidation_0-error:0.16613\tvalidation_1-error:0.21810\n",
      "[387]\tvalidation_0-error:0.16588\tvalidation_1-error:0.21736\n",
      "[388]\tvalidation_0-error:0.16621\tvalidation_1-error:0.21662\n",
      "[389]\tvalidation_0-error:0.16564\tvalidation_1-error:0.21662\n",
      "[390]\tvalidation_0-error:0.16580\tvalidation_1-error:0.21884\n",
      "[391]\tvalidation_0-error:0.16547\tvalidation_1-error:0.21810\n",
      "[392]\tvalidation_0-error:0.16489\tvalidation_1-error:0.21884\n",
      "[393]\tvalidation_0-error:0.16473\tvalidation_1-error:0.21959\n",
      "[394]\tvalidation_0-error:0.16456\tvalidation_1-error:0.21959\n",
      "[395]\tvalidation_0-error:0.16456\tvalidation_1-error:0.21884\n",
      "[396]\tvalidation_0-error:0.16465\tvalidation_1-error:0.21810\n",
      "[397]\tvalidation_0-error:0.16432\tvalidation_1-error:0.21959\n",
      "[398]\tvalidation_0-error:0.16423\tvalidation_1-error:0.21810\n",
      "[399]\tvalidation_0-error:0.16440\tvalidation_1-error:0.21959\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "clf1 = SVCclbr()\n",
    "clf2=\n",
    "\n",
    "clf.fit(X_train, y_train_all,\n",
    "        eval_set=[(X_train, y_train_all), (X_test, y_test)],\n",
    "        verbose=True)\n",
    "\n",
    "evals_result = clf.evals_result()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#{'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
    "#'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`sklearn.svm.LinearSVC` or\n",
      " |  :class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, optional (default=1.0)\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : string, optional (default='rbf')\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, optional (default='scale')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  probability : boolean, optional (default=False)\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, optional (default=False)\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator used when shuffling\n",
      " |      the data for probability estimates. If int, random_state is the\n",
      " |      seed used by the random number generator; If RandomState instance,\n",
      " |      random_state is the random number generator; If None, the random\n",
      " |      number generator is the RandomState instance used by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the section about multi-class classification in the\n",
      " |      SVM section of the User Guide for details.\n",
      " |  \n",
      " |  coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_class * (n_class-1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  classes_ : array of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  probA_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |  probB_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  class_weight_ : ndarray of shape (n_class,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = SVC(gamma='auto')\n",
      " |  >>> clf.fit(X, y)\n",
      " |  SVC(gamma='auto')\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  n_support_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CalibratedClassifierCV in module sklearn.calibration:\n",
      "\n",
      "class CalibratedClassifierCV(sklearn.base.BaseEstimator, sklearn.base.ClassifierMixin, sklearn.base.MetaEstimatorMixin)\n",
      " |  Probability calibration with isotonic regression or sigmoid.\n",
      " |  \n",
      " |  See glossary entry for :term:`cross-validation estimator`.\n",
      " |  \n",
      " |  With this class, the base_estimator is fit on the train set of the\n",
      " |  cross-validation generator and the test set is used for calibration.\n",
      " |  The probabilities for each of the folds are then averaged\n",
      " |  for prediction. In case that cv=\"prefit\" is passed to __init__,\n",
      " |  it is assumed that base_estimator has been fitted already and all\n",
      " |  data is used for calibration. Note that data for fitting the\n",
      " |  classifier and for calibrating it must be disjoint.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <calibration>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  base_estimator : instance BaseEstimator\n",
      " |      The classifier whose output decision function needs to be calibrated\n",
      " |      to offer more accurate predict_proba outputs. If cv=prefit, the\n",
      " |      classifier must have been fit already on data.\n",
      " |  \n",
      " |  method : 'sigmoid' or 'isotonic'\n",
      " |      The method to use for calibration. Can be 'sigmoid' which\n",
      " |      corresponds to Platt's method or 'isotonic' which is a\n",
      " |      non-parametric approach. It is not advised to use isotonic calibration\n",
      " |      with too few calibration samples ``(<<1000)`` since it tends to\n",
      " |      overfit.\n",
      " |      Use sigmoids (Platt's calibration) in this case.\n",
      " |  \n",
      " |  cv : integer, cross-validation generator, iterable or \"prefit\", optional\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross-validation,\n",
      " |      - integer, to specify the number of folds.\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if ``y`` is binary or multiclass,\n",
      " |      :class:`sklearn.model_selection.StratifiedKFold` is used. If ``y`` is\n",
      " |      neither binary nor multiclass, :class:`sklearn.model_selection.KFold`\n",
      " |      is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      If \"prefit\" is passed, it is assumed that base_estimator has been\n",
      " |      fitted already and all data is used for calibration.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array, shape (n_classes)\n",
      " |      The class labels.\n",
      " |  \n",
      " |  calibrated_classifiers_ : list (len() equal to cv or 1 if cv == \"prefit\")\n",
      " |      The list of calibrated classifiers, one for each crossvalidation fold,\n",
      " |      which has been fitted on all but the validation fold and calibrated\n",
      " |      on the validation fold.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] Obtaining calibrated probability estimates from decision trees\n",
      " |         and naive Bayesian classifiers, B. Zadrozny & C. Elkan, ICML 2001\n",
      " |  \n",
      " |  .. [2] Transforming Classifier Scores into Accurate Multiclass\n",
      " |         Probability Estimates, B. Zadrozny & C. Elkan, (KDD 2002)\n",
      " |  \n",
      " |  .. [3] Probabilistic Outputs for Support Vector Machines and Comparisons to\n",
      " |         Regularized Likelihood Methods, J. Platt, (1999)\n",
      " |  \n",
      " |  .. [4] Predicting Good Probabilities with Supervised Learning,\n",
      " |         A. Niculescu-Mizil & R. Caruana, ICML 2005\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CalibratedClassifierCV\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, base_estimator=None, method='sigmoid', cv=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the calibrated model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns an instance of self.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the target of new samples. Can be different from the\n",
      " |      prediction of the uncalibrated classifier.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          The samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          The predicted class.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Posterior probabilities of classification\n",
      " |      \n",
      " |      This function returns posterior probabilities of classification\n",
      " |      according to each class on an array of test vectors X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          The samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples, n_classes)\n",
      " |          The predicted probas.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVCclbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
