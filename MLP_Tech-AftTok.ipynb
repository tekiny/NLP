{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.compat.v2 import random as tfrandom\n",
    "#for tf version > 2 use from tensorflow import random as tfrandom\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.utils import class_weight as sk_class_wgt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer as Normalizer\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer,PowerTransformer,MinMaxScaler,MaxAbsScaler,RobustScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from datetime import datetime \n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14390, 4)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df01=pd.read_csv(r'C:\\Users\\tekin\\Desktop\\ML\\Tweedy\\TechCntVctUsnm_D1906.csv',index_col=False)\n",
    "#print(dt_cl[:300])\n",
    "df01.shape\n",
    "#posset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "SEED=7\n",
    "np.random.seed(SEED)\n",
    "tfrandom.set_seed(SEED)\n",
    "keras.wrappers.scikit_learn.KerasClassifier.random_state=SEED\n",
    "#help(grid)\n",
    "print(keras.wrappers.scikit_learn.KerasClassifier.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vect=np.array(df01.edInput)\n",
    "text_vect=np.array(df01.text[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, y_train_all, y_test =train_test_split(text_vect,\n",
    "            y_vect,random_state=SEED,test_size=0.1,stratify=y_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use count vectorizer then tfid\n",
    "#!!!!!!!!! we can add a column with a flag value that shows the tweet has pic or video into word vector\n",
    "\n",
    "#lemma_vect =  TfidfVectorizer(tokenizer=None,token_pattern='\\S+',\n",
    "#                             min_df=4,lowercase=False,stop_words=None,ngram_range=(1,4),max_features=12000)\n",
    "lemma_vect =  CountVectorizer(tokenizer=None,token_pattern='\\S+',\n",
    "                             min_df=1,lowercase=False,stop_words=None,ngram_range=(1,5),max_features=4200)\n",
    "X_train_tmp=lemma_vect.fit_transform(X_train_raw)\n",
    "X_test=lemma_vect.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12951, 4200)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tmp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kdnuggets.com/2019/04/normalization-vs-standardization-quantitative-analysis.html\n",
    "\n",
    "Best classifier from each model:\n",
    "\n",
    "    SVM + StandardScaler : 0.849\n",
    "    MLP + PowerTransformer-Yeo-Johnson : 0.839\n",
    "    KNN + MinMaxScaler : 0.813\n",
    "    LR + QuantileTransformer-Uniform : 0.808\n",
    "    NB + PowerTransformer-Yeo-Johnson : 0.752\n",
    "    LDA + PowerTransformer-Yeo-Johnson : 0.747\n",
    "    CART + QuantileTransformer-Uniform : 0.74\n",
    "    RF + Normalizer : 0.723\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix \n",
    "sclPT=PowerTransformer()\n",
    "#sclSTD=StandardScaler()\n",
    "#normalizer=Normalizer()\n",
    "#without normalizing\n",
    "X_train_scl=sclPT.fit_transform(X_train_tmp.toarray())\n",
    "#X_train_scl=X_train_tmp\n",
    "\n",
    "X_test=sclPT.transform(X_test_tmp)\n",
    "#X_test=X_test_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svd= TruncatedSVD(n_components=Dim_num)\n",
    "\n",
    "\n",
    "#X_train_scl = svd.fit_transform(X_train_scl)\n",
    "#X_test = svd.transform(X_test_scl)\n",
    "#print(svd.explained_variance_ratio_.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section is to print the names of the best features obtained from SVD\n",
    "#check the names see if they are reasonable with your category\n",
    "\n",
    "#feature_names=lemma_vect.get_feature_names()\n",
    "#best_features = [feature_names[i] for i in svd.components_[0].argsort()[::-1]]\n",
    "#print(best_features[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_tmp, y_train_all, \n",
    "                                                  test_size=0.2,stratify=y_train_all,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595 \n",
      " 12795\n",
      "Weight for class 0: 4.51\n",
      "Weight for class 1: 0.56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.11747905])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WEIGHTED MODEL\n",
    "\n",
    "negative = len(df01[df01['edInput'] == 0])\n",
    "positive = len(df01[df01['edInput'] == 1])\n",
    "print(negative,'\\n',positive)\n",
    "total = negative + positive\n",
    "weight_for_0 = (1 / negative)*(total)/2.0 \n",
    "weight_for_1 = (1 / positive)*(total)/2.0\n",
    "#weight_for_1 = 100\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "val_sample_weights = sk_class_wgt.compute_sample_weight(class_weight, y_val)\n",
    "train_sample_weights = sk_class_wgt.compute_sample_weight(class_weight, y_train)\n",
    "test_sample_weights = sk_class_wgt.compute_sample_weight(class_weight, y_test)\n",
    "initial_bias = np.log([positive/total])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_raw\n",
    "del X_train_tmp\n",
    "del df01\n",
    "del text_vect\n",
    "#del X_train_scl\n",
    "#del X_train_rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def my_metric_fn(y_true, y_pred):\n",
    "    sensitivity = keras.metrics.TrueNegatives(y_true, y_pred)/(keras.metrics.TrueNegatives(y_true, y_pred)+keras.metrics.FalsePositives(y_true, y_pred))\n",
    "    return sensitivity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "NEURONS=360\n",
    "learn_rate=0.0001\n",
    "krn_reg=regularizers.l2(0.01)\n",
    "activation='relu'\n",
    "act_reg=regularizers.l2(0.1)\n",
    "dropout_rate=0.5\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='mean_squared_error', metrics=[my_metric_fn])\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.SpecificityAtSensitivity(0.5,name='spcsens'),\n",
    "      keras.metrics.SensitivityAtSpecificity(0.70,name='snsspec')    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateDecay:\n",
    "    def plot(self, epochs, title=\"Learning Rate Schedule\"):\n",
    "        # compute the set of learning rates for each corresponding\n",
    "        # epoch\n",
    "        lrs = [self(i) for i in epochs]\n",
    "        # the learning rate schedule\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.figure()\n",
    "        plt.plot(epochs, lrs)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Epoch #\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "        \n",
    "class PolynomialDecay():\n",
    "    def __init__(self, maxEpochs=100, initAlpha=0.01, power=1.0):\n",
    "        # store the maximum number of epochs, base learning rate,\n",
    "        # and power of the polynomial\n",
    "        self.maxEpochs = maxEpochs\n",
    "        self.initAlpha = initAlpha\n",
    "        self.power = power\n",
    "    def __call__(self, epoch):\n",
    "        # compute the new learning rate based on polynomial decay\n",
    "        decay = (1 - (epoch / float(self.maxEpochs))) ** self.power\n",
    "\n",
    "        alpha = self.initAlpha * decay\n",
    "        print(\"decay:\",decay,\">> lr:\",alpha)\n",
    "        # return the new learning rate\n",
    "        return float(alpha)\n",
    "schedule = PolynomialDecay(maxEpochs=EPOCHS, initAlpha=3e-4, power=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#schedule.__call__(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_bias = keras.initializers.Constant(initial_bias)\n",
    "def make_model(metrics = METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "          keras.layers.Dense(\n",
    "              NEURONS, activation=activation,\n",
    "              input_shape=(X_train.shape[-1],),kernel_regularizer=krn_reg\n",
    "              ,activity_regularizer=act_reg),\n",
    "          keras.layers.Dropout(dropout_rate),\n",
    "          keras.layers.Dense(\n",
    "              NEURONS/2, activation=activation,\n",
    "              input_shape=(X_train.shape[-1],),kernel_regularizer=krn_reg\n",
    "          ,activity_regularizer=act_reg),\n",
    "          keras.layers.Dropout(dropout_rate),\n",
    "\n",
    "          keras.layers.Dense(1, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "#    model.compile(\n",
    "#      optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "#      loss=keras.losses.BinaryCrossentropy(),\n",
    "#      metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch=100\n",
    "ep=lambda epoch: 1e-8 * 10**(epoch / 20)\n",
    "float(ep(100))\n",
    "#10**(1/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "optimizer = keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "model.compile(loss=keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=METRICS)\n",
    "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.axis([1e-5, 1e-3, 0, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = make_model() \n",
    "model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=METRICS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpnt_filepath=r\"D:\\work\\SavedModels\\Tweedy\\Ckpt\\chkpntwghts.{epoch:02d}-{val_weighted_accuracy:.4f}.hdf5\" \n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_weighted_accuracy', \n",
    "    verbose=1,\n",
    "    patience=80,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=chkpnt_filepath,\n",
    "     save_best_only=True,  monitor=\"val_weighted_accuracy\")\n",
    "lrscheduler=keras.callbacks.LearningRateScheduler(schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = make_model()\n",
    "baseline_history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (12, 12)\n",
    "plot_metrics(baseline_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_predictions = model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions= model.predict(X_test, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results = model.evaluate(X_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 360)               1512360   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 180)               64980     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 181       \n",
      "=================================================================\n",
      "Total params: 1,577,521\n",
      "Trainable params: 1,577,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weighted_model = make_model(output_bias=initial_bias)\n",
    "#weighted_model = make_model()\n",
    "weighted_model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=METRICS,weighted_metrics=[METRICS[4]])\n",
    "weighted_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10360 samples, validate on 2591 samples\n",
      "decay: 1.0 >> lr: 0.0003\n",
      "Epoch 1/200\n",
      "10360/10360 [==============================] - 7s 707us/sample - loss: 3.2234 - tp: 60.0000 - fp: 5.0000 - tn: 1144.0000 - fn: 9151.0000 - weighted_accuracy: 0.8861 - precision: 0.9231 - recall: 0.0065 - spcsens: 0.7285 - snsspec: 0.5539 - val_loss: 1.4907 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 287.0000 - val_fn: 2304.0000 - val_weighted_accuracy: 0.4998 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_spcsens: 0.9129 - val_snsspec: 0.8142\n",
      "decay: 0.995 >> lr: 0.0002985\n",
      "Epoch 2/200\n",
      "10360/10360 [==============================] - 6s 608us/sample - loss: 1.1198 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1149.0000 - fn: 9211.0000 - weighted_accuracy: 0.8892 - precision: 0.0000e+00 - recall: 0.0000e+00 - spcsens: 0.9669 - snsspec: 0.8720 - val_loss: 1.0709 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 287.0000 - val_fn: 2304.0000 - val_weighted_accuracy: 0.4998 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_spcsens: 0.9268 - val_snsspec: 0.8377\n",
      "decay: 0.99 >> lr: 0.00029699999999999996\n",
      "Epoch 3/200\n",
      "10360/10360 [==============================] - 6s 613us/sample - loss: 0.8773 - tp: 4.0000 - fp: 0.0000e+00 - tn: 1149.0000 - fn: 9207.0000 - weighted_accuracy: 0.8893 - precision: 1.0000 - recall: 4.3426e-04 - spcsens: 0.9809 - snsspec: 0.8909 - val_loss: 0.9817 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 287.0000 - val_fn: 2304.0000 - val_weighted_accuracy: 0.4998 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_spcsens: 0.9199 - val_snsspec: 0.8312\n",
      "decay: 0.985 >> lr: 0.00029549999999999997\n",
      "Epoch 4/200\n",
      "10360/10360 [==============================] - 7s 640us/sample - loss: 0.8040 - tp: 320.0000 - fp: 0.0000e+00 - tn: 1149.0000 - fn: 8891.0000 - weighted_accuracy: 0.8931 - precision: 1.0000 - recall: 0.0347 - spcsens: 0.9843 - snsspec: 0.8990 - val_loss: 0.9434 - val_tp: 63.0000 - val_fp: 0.0000e+00 - val_tn: 287.0000 - val_fn: 2241.0000 - val_weighted_accuracy: 0.5135 - val_precision: 1.0000 - val_recall: 0.0273 - val_spcsens: 0.9303 - val_snsspec: 0.8142\n",
      "decay: 0.98 >> lr: 0.000294\n",
      "Epoch 5/200\n",
      "10360/10360 [==============================] - 7s 627us/sample - loss: 0.7667 - tp: 1827.0000 - fp: 5.0000 - tn: 1144.0000 - fn: 7384.0000 - weighted_accuracy: 0.9073 - precision: 0.9973 - recall: 0.1983 - spcsens: 0.9852 - snsspec: 0.9082 - val_loss: 0.9617 - val_tp: 567.0000 - val_fp: 7.0000 - val_tn: 280.0000 - val_fn: 1737.0000 - val_weighted_accuracy: 0.6107 - val_precision: 0.9878 - val_recall: 0.2461 - val_spcsens: 0.9268 - val_snsspec: 0.8190\n",
      "decay: 0.975 >> lr: 0.00029249999999999995\n",
      "Epoch 6/200\n",
      "10360/10360 [==============================] - 6s 621us/sample - loss: 0.7451 - tp: 2874.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 6337.0000 - weighted_accuracy: 0.9207 - precision: 0.9986 - recall: 0.3120 - spcsens: 0.9904 - snsspec: 0.9085 - val_loss: 0.9855 - val_tp: 796.0000 - val_fp: 14.0000 - val_tn: 273.0000 - val_fn: 1508.0000 - val_weighted_accuracy: 0.6482 - val_precision: 0.9827 - val_recall: 0.3455 - val_spcsens: 0.9268 - val_snsspec: 0.8307\n",
      "decay: 0.97 >> lr: 0.00029099999999999997\n",
      "Epoch 7/200\n",
      "10360/10360 [==============================] - 7s 636us/sample - loss: 0.7204 - tp: 3741.0000 - fp: 5.0000 - tn: 1144.0000 - fn: 5470.0000 - weighted_accuracy: 0.9303 - precision: 0.9987 - recall: 0.4061 - spcsens: 0.9930 - snsspec: 0.9169 - val_loss: 0.8986 - val_tp: 1030.0000 - val_fp: 18.0000 - val_tn: 269.0000 - val_fn: 1274.0000 - val_weighted_accuracy: 0.6921 - val_precision: 0.9828 - val_recall: 0.4470 - val_spcsens: 0.9199 - val_snsspec: 0.8121\n",
      "decay: 0.965 >> lr: 0.0002895\n",
      "Epoch 8/200\n",
      "10360/10360 [==============================] - 7s 633us/sample - loss: 0.7042 - tp: 4246.0000 - fp: 5.0000 - tn: 1144.0000 - fn: 4965.0000 - weighted_accuracy: 0.9364 - precision: 0.9988 - recall: 0.4610 - spcsens: 0.9922 - snsspec: 0.9260 - val_loss: 0.9230 - val_tp: 1025.0000 - val_fp: 22.0000 - val_tn: 265.0000 - val_fn: 1279.0000 - val_weighted_accuracy: 0.6840 - val_precision: 0.9790 - val_recall: 0.4449 - val_spcsens: 0.9094 - val_snsspec: 0.8229\n",
      "decay: 0.96 >> lr: 0.00028799999999999995\n",
      "Epoch 9/200\n",
      "10360/10360 [==============================] - 6s 616us/sample - loss: 0.6848 - tp: 4571.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 4640.0000 - weighted_accuracy: 0.9427 - precision: 0.9996 - recall: 0.4963 - spcsens: 0.9983 - snsspec: 0.9229 - val_loss: 0.9312 - val_tp: 1043.0000 - val_fp: 23.0000 - val_tn: 264.0000 - val_fn: 1261.0000 - val_weighted_accuracy: 0.6862 - val_precision: 0.9784 - val_recall: 0.4527 - val_spcsens: 0.9129 - val_snsspec: 0.8060\n",
      "decay: 0.955 >> lr: 0.00028649999999999997\n",
      "Epoch 10/200\n",
      "10360/10360 [==============================] - 7s 642us/sample - loss: 0.6642 - tp: 4978.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 4233.0000 - weighted_accuracy: 0.9475 - precision: 0.9996 - recall: 0.5404 - spcsens: 0.9991 - snsspec: 0.9248 - val_loss: 0.9054 - val_tp: 1170.0000 - val_fp: 28.0000 - val_tn: 259.0000 - val_fn: 1134.0000 - val_weighted_accuracy: 0.7051 - val_precision: 0.9766 - val_recall: 0.5078 - val_spcsens: 0.9059 - val_snsspec: 0.8125\n",
      "decay: 0.95 >> lr: 0.000285\n",
      "Epoch 11/200\n",
      "10360/10360 [==============================] - 7s 629us/sample - loss: 0.6491 - tp: 5208.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 4003.0000 - weighted_accuracy: 0.9488 - precision: 0.9992 - recall: 0.5654 - spcsens: 0.9991 - snsspec: 0.9351 - val_loss: 0.8426 - val_tp: 1345.0000 - val_fp: 35.0000 - val_tn: 252.0000 - val_fn: 959.0000 - val_weighted_accuracy: 0.7309 - val_precision: 0.9746 - val_recall: 0.5838 - val_spcsens: 0.9024 - val_snsspec: 0.8190\n",
      "decay: 0.945 >> lr: 0.00028349999999999995\n",
      "Epoch 12/200\n",
      "10360/10360 [==============================] - 7s 632us/sample - loss: 0.6284 - tp: 5456.0000 - fp: 5.0000 - tn: 1144.0000 - fn: 3755.0000 - weighted_accuracy: 0.9510 - precision: 0.9991 - recall: 0.5923 - spcsens: 0.9983 - snsspec: 0.9376 - val_loss: 0.8848 - val_tp: 1237.0000 - val_fp: 28.0000 - val_tn: 259.0000 - val_fn: 1067.0000 - val_weighted_accuracy: 0.7196 - val_precision: 0.9779 - val_recall: 0.5369 - val_spcsens: 0.9094 - val_snsspec: 0.8121\n",
      "decay: 0.94 >> lr: 0.00028199999999999997\n",
      "Epoch 13/200\n",
      "10360/10360 [==============================] - 7s 629us/sample - loss: 0.6147 - tp: 5597.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 3614.0000 - weighted_accuracy: 0.9558 - precision: 0.9998 - recall: 0.6076 - spcsens: 0.9991 - snsspec: 0.9363 - val_loss: 0.8689 - val_tp: 1317.0000 - val_fp: 39.0000 - val_tn: 248.0000 - val_fn: 987.0000 - val_weighted_accuracy: 0.7178 - val_precision: 0.9712 - val_recall: 0.5716 - val_spcsens: 0.8990 - val_snsspec: 0.8008\n",
      "decay: 0.935 >> lr: 0.0002805\n",
      "Epoch 14/200\n",
      "10360/10360 [==============================] - 7s 632us/sample - loss: 0.6124 - tp: 5653.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 3558.0000 - weighted_accuracy: 0.9549 - precision: 0.9995 - recall: 0.6137 - spcsens: 0.9983 - snsspec: 0.9421 - val_loss: 0.8758 - val_tp: 1277.0000 - val_fp: 32.0000 - val_tn: 255.0000 - val_fn: 1027.0000 - val_weighted_accuracy: 0.7213 - val_precision: 0.9756 - val_recall: 0.5543 - val_spcsens: 0.9024 - val_snsspec: 0.8203\n",
      "decay: 0.9299999999999999 >> lr: 0.00027899999999999995\n",
      "Epoch 15/200\n",
      "10360/10360 [==============================] - 7s 632us/sample - loss: 0.5928 - tp: 5806.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 3405.0000 - weighted_accuracy: 0.9583 - precision: 0.9998 - recall: 0.6303 - spcsens: 0.9991 - snsspec: 0.9451 - val_loss: 0.8471 - val_tp: 1403.0000 - val_fp: 42.0000 - val_tn: 245.0000 - val_fn: 901.0000 - val_weighted_accuracy: 0.7313 - val_precision: 0.9709 - val_recall: 0.6089 - val_spcsens: 0.8920 - val_snsspec: 0.8116\n",
      "decay: 0.925 >> lr: 0.00027749999999999997\n",
      "Epoch 16/200\n",
      "10360/10360 [==============================] - 7s 660us/sample - loss: 0.5907 - tp: 5890.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 3321.0000 - weighted_accuracy: 0.9593 - precision: 0.9998 - recall: 0.6395 - spcsens: 1.0000 - snsspec: 0.9479 - val_loss: 0.8212 - val_tp: 1474.0000 - val_fp: 46.0000 - val_tn: 241.0000 - val_fn: 830.0000 - val_weighted_accuracy: 0.7397 - val_precision: 0.9697 - val_recall: 0.6398 - val_spcsens: 0.9129 - val_snsspec: 0.8082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decay: 0.92 >> lr: 0.000276\n",
      "Epoch 17/200\n",
      "10360/10360 [==============================] - 7s 634us/sample - loss: 0.5761 - tp: 6043.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 3168.0000 - weighted_accuracy: 0.9611 - precision: 0.9998 - recall: 0.6561 - spcsens: 0.9991 - snsspec: 0.9492 - val_loss: 0.8649 - val_tp: 1420.0000 - val_fp: 41.0000 - val_tn: 246.0000 - val_fn: 884.0000 - val_weighted_accuracy: 0.7367 - val_precision: 0.9719 - val_recall: 0.6163 - val_spcsens: 0.9059 - val_snsspec: 0.8099\n",
      "decay: 0.915 >> lr: 0.0002745\n",
      "Epoch 18/200\n",
      "10360/10360 [==============================] - 6s 624us/sample - loss: 0.5688 - tp: 6126.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 3085.0000 - weighted_accuracy: 0.9598 - precision: 0.9993 - recall: 0.6651 - spcsens: 1.0000 - snsspec: 0.9480 - val_loss: 0.8349 - val_tp: 1495.0000 - val_fp: 46.0000 - val_tn: 241.0000 - val_fn: 809.0000 - val_weighted_accuracy: 0.7443 - val_precision: 0.9701 - val_recall: 0.6489 - val_spcsens: 0.9024 - val_snsspec: 0.8073\n",
      "decay: 0.91 >> lr: 0.00027299999999999997\n",
      "Epoch 19/200\n",
      "10360/10360 [==============================] - 7s 632us/sample - loss: 0.5583 - tp: 6213.0000 - fp: 0.0000e+00 - tn: 1149.0000 - fn: 2998.0000 - weighted_accuracy: 0.9639 - precision: 1.0000 - recall: 0.6745 - spcsens: 1.0000 - snsspec: 0.9508 - val_loss: 0.8470 - val_tp: 1473.0000 - val_fp: 46.0000 - val_tn: 241.0000 - val_fn: 831.0000 - val_weighted_accuracy: 0.7395 - val_precision: 0.9697 - val_recall: 0.6393 - val_spcsens: 0.9024 - val_snsspec: 0.7947\n",
      "decay: 0.905 >> lr: 0.0002715\n",
      "Epoch 20/200\n",
      "10360/10360 [==============================] - 7s 630us/sample - loss: 0.5505 - tp: 6364.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 2847.0000 - weighted_accuracy: 0.9634 - precision: 0.9995 - recall: 0.6909 - spcsens: 0.9991 - snsspec: 0.9510 - val_loss: 0.8421 - val_tp: 1473.0000 - val_fp: 45.0000 - val_tn: 242.0000 - val_fn: 831.0000 - val_weighted_accuracy: 0.7412 - val_precision: 0.9704 - val_recall: 0.6393 - val_spcsens: 0.9094 - val_snsspec: 0.8069\n",
      "decay: 0.9 >> lr: 0.00027\n",
      "Epoch 21/200\n",
      "10360/10360 [==============================] - 7s 639us/sample - loss: 0.5431 - tp: 6374.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 2837.0000 - weighted_accuracy: 0.9636 - precision: 0.9995 - recall: 0.6920 - spcsens: 1.0000 - snsspec: 0.9561 - val_loss: 0.8308 - val_tp: 1520.0000 - val_fp: 46.0000 - val_tn: 241.0000 - val_fn: 784.0000 - val_weighted_accuracy: 0.7497 - val_precision: 0.9706 - val_recall: 0.6597 - val_spcsens: 0.8990 - val_snsspec: 0.7969\n",
      "decay: 0.895 >> lr: 0.00026849999999999997\n",
      "Epoch 22/200\n",
      "10360/10360 [==============================] - 7s 633us/sample - loss: 0.5343 - tp: 6417.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2794.0000 - weighted_accuracy: 0.9649 - precision: 0.9997 - recall: 0.6967 - spcsens: 1.0000 - snsspec: 0.9606 - val_loss: 0.8486 - val_tp: 1469.0000 - val_fp: 48.0000 - val_tn: 239.0000 - val_fn: 835.0000 - val_weighted_accuracy: 0.7351 - val_precision: 0.9684 - val_recall: 0.6376 - val_spcsens: 0.9059 - val_snsspec: 0.7990\n",
      "decay: 0.89 >> lr: 0.000267\n",
      "Epoch 23/200\n",
      "10360/10360 [==============================] - 6s 624us/sample - loss: 0.5335 - tp: 6451.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 2760.0000 - weighted_accuracy: 0.9645 - precision: 0.9995 - recall: 0.7004 - spcsens: 1.0000 - snsspec: 0.9570 - val_loss: 0.8669 - val_tp: 1439.0000 - val_fp: 50.0000 - val_tn: 237.0000 - val_fn: 865.0000 - val_weighted_accuracy: 0.7251 - val_precision: 0.9664 - val_recall: 0.6246 - val_spcsens: 0.9024 - val_snsspec: 0.8008\n",
      "decay: 0.885 >> lr: 0.0002655\n",
      "Epoch 24/200\n",
      "10360/10360 [==============================] - 7s 638us/sample - loss: 0.5282 - tp: 6463.0000 - fp: 5.0000 - tn: 1144.0000 - fn: 2748.0000 - weighted_accuracy: 0.9631 - precision: 0.9992 - recall: 0.7017 - spcsens: 1.0000 - snsspec: 0.9607 - val_loss: 0.8422 - val_tp: 1517.0000 - val_fp: 51.0000 - val_tn: 236.0000 - val_fn: 787.0000 - val_weighted_accuracy: 0.7403 - val_precision: 0.9675 - val_recall: 0.6584 - val_spcsens: 0.9024 - val_snsspec: 0.7782\n",
      "decay: 0.88 >> lr: 0.00026399999999999997\n",
      "Epoch 25/200\n",
      "10360/10360 [==============================] - 7s 650us/sample - loss: 0.5144 - tp: 6628.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2583.0000 - weighted_accuracy: 0.9674 - precision: 0.9997 - recall: 0.7196 - spcsens: 1.0000 - snsspec: 0.9612 - val_loss: 0.8358 - val_tp: 1540.0000 - val_fp: 54.0000 - val_tn: 233.0000 - val_fn: 764.0000 - val_weighted_accuracy: 0.7401 - val_precision: 0.9661 - val_recall: 0.6684 - val_spcsens: 0.9024 - val_snsspec: 0.8034\n",
      "decay: 0.875 >> lr: 0.0002625\n",
      "Epoch 26/200\n",
      "10360/10360 [==============================] - 7s 642us/sample - loss: 0.5153 - tp: 6614.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 2597.0000 - weighted_accuracy: 0.9657 - precision: 0.9994 - recall: 0.7181 - spcsens: 1.0000 - snsspec: 0.9635 - val_loss: 0.8248 - val_tp: 1572.0000 - val_fp: 58.0000 - val_tn: 229.0000 - val_fn: 732.0000 - val_weighted_accuracy: 0.7401 - val_precision: 0.9644 - val_recall: 0.6823 - val_spcsens: 0.9059 - val_snsspec: 0.7925\n",
      "decay: 0.87 >> lr: 0.000261\n",
      "Epoch 27/200\n",
      "10360/10360 [==============================] - 7s 645us/sample - loss: 0.5005 - tp: 6748.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 2463.0000 - weighted_accuracy: 0.9681 - precision: 0.9996 - recall: 0.7326 - spcsens: 1.0000 - snsspec: 0.9659 - val_loss: 0.8496 - val_tp: 1555.0000 - val_fp: 59.0000 - val_tn: 228.0000 - val_fn: 749.0000 - val_weighted_accuracy: 0.7346 - val_precision: 0.9634 - val_recall: 0.6749 - val_spcsens: 0.8990 - val_snsspec: 0.7839\n",
      "decay: 0.865 >> lr: 0.00025949999999999997\n",
      "Epoch 28/200\n",
      "10360/10360 [==============================] - 6s 626us/sample - loss: 0.5052 - tp: 6729.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 2482.0000 - weighted_accuracy: 0.9671 - precision: 0.9994 - recall: 0.7305 - spcsens: 0.9991 - snsspec: 0.9638 - val_loss: 0.8402 - val_tp: 1549.0000 - val_fp: 59.0000 - val_tn: 228.0000 - val_fn: 755.0000 - val_weighted_accuracy: 0.7333 - val_precision: 0.9633 - val_recall: 0.6723 - val_spcsens: 0.9094 - val_snsspec: 0.7804\n",
      "decay: 0.86 >> lr: 0.000258\n",
      "Epoch 29/200\n",
      "10360/10360 [==============================] - 7s 648us/sample - loss: 0.4918 - tp: 6825.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2386.0000 - weighted_accuracy: 0.9698 - precision: 0.9997 - recall: 0.7410 - spcsens: 0.9991 - snsspec: 0.9695 - val_loss: 0.8203 - val_tp: 1656.0000 - val_fp: 67.0000 - val_tn: 220.0000 - val_fn: 648.0000 - val_weighted_accuracy: 0.7426 - val_precision: 0.9611 - val_recall: 0.7188 - val_spcsens: 0.9199 - val_snsspec: 0.7721\n",
      "decay: 0.855 >> lr: 0.00025649999999999995\n",
      "Epoch 30/200\n",
      "10360/10360 [==============================] - 7s 661us/sample - loss: 0.4911 - tp: 6786.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 2425.0000 - weighted_accuracy: 0.9685 - precision: 0.9996 - recall: 0.7367 - spcsens: 1.0000 - snsspec: 0.9722 - val_loss: 0.8067 - val_tp: 1686.0000 - val_fp: 66.0000 - val_tn: 221.0000 - val_fn: 618.0000 - val_weighted_accuracy: 0.7509 - val_precision: 0.9623 - val_recall: 0.7318 - val_spcsens: 0.8990 - val_snsspec: 0.7869\n",
      "decay: 0.85 >> lr: 0.00025499999999999996\n",
      "Epoch 31/200\n",
      "10360/10360 [==============================] - 7s 681us/sample - loss: 0.4827 - tp: 6845.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 2366.0000 - weighted_accuracy: 0.9708 - precision: 0.9999 - recall: 0.7431 - spcsens: 1.0000 - snsspec: 0.9708 - val_loss: 0.8296 - val_tp: 1660.0000 - val_fp: 70.0000 - val_tn: 217.0000 - val_fn: 644.0000 - val_weighted_accuracy: 0.7383 - val_precision: 0.9595 - val_recall: 0.7205 - val_spcsens: 0.9129 - val_snsspec: 0.7804\n",
      "decay: 0.845 >> lr: 0.0002535\n",
      "Epoch 32/200\n",
      "10360/10360 [==============================] - 7s 658us/sample - loss: 0.4837 - tp: 6883.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2328.0000 - weighted_accuracy: 0.9705 - precision: 0.9997 - recall: 0.7473 - spcsens: 1.0000 - snsspec: 0.9713 - val_loss: 0.8184 - val_tp: 1643.0000 - val_fp: 62.0000 - val_tn: 225.0000 - val_fn: 661.0000 - val_weighted_accuracy: 0.7485 - val_precision: 0.9636 - val_recall: 0.7131 - val_spcsens: 0.9094 - val_snsspec: 0.7951\n",
      "decay: 0.84 >> lr: 0.00025199999999999995\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10360/10360 [==============================] - 6s 607us/sample - loss: 0.4806 - tp: 6892.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 2319.0000 - weighted_accuracy: 0.9713 - precision: 0.9999 - recall: 0.7482 - spcsens: 0.9991 - snsspec: 0.9735 - val_loss: 0.8098 - val_tp: 1716.0000 - val_fp: 75.0000 - val_tn: 212.0000 - val_fn: 588.0000 - val_weighted_accuracy: 0.7417 - val_precision: 0.9581 - val_recall: 0.7448 - val_spcsens: 0.9059 - val_snsspec: 0.7912\n",
      "decay: 0.835 >> lr: 0.00025049999999999996\n",
      "Epoch 34/200\n",
      "10360/10360 [==============================] - 6s 619us/sample - loss: 0.4729 - tp: 6922.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 2289.0000 - weighted_accuracy: 0.9702 - precision: 0.9996 - recall: 0.7515 - spcsens: 1.0000 - snsspec: 0.9777 - val_loss: 0.8285 - val_tp: 1628.0000 - val_fp: 59.0000 - val_tn: 228.0000 - val_fn: 676.0000 - val_weighted_accuracy: 0.7505 - val_precision: 0.9650 - val_recall: 0.7066 - val_spcsens: 0.9024 - val_snsspec: 0.7938\n",
      "decay: 0.83 >> lr: 0.000249\n",
      "Epoch 35/200\n",
      "10360/10360 [==============================] - 6s 607us/sample - loss: 0.4651 - tp: 6987.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 2224.0000 - weighted_accuracy: 0.9725 - precision: 0.9999 - recall: 0.7585 - spcsens: 0.9991 - snsspec: 0.9782 - val_loss: 0.8137 - val_tp: 1690.0000 - val_fp: 72.0000 - val_tn: 215.0000 - val_fn: 614.0000 - val_weighted_accuracy: 0.7413 - val_precision: 0.9591 - val_recall: 0.7335 - val_spcsens: 0.9059 - val_snsspec: 0.7812\n",
      "decay: 0.825 >> lr: 0.00024749999999999994\n",
      "Epoch 36/200\n",
      "10360/10360 [==============================] - 6s 607us/sample - loss: 0.4656 - tp: 7038.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2173.0000 - weighted_accuracy: 0.9723 - precision: 0.9997 - recall: 0.7641 - spcsens: 0.9991 - snsspec: 0.9761 - val_loss: 0.8175 - val_tp: 1680.0000 - val_fp: 71.0000 - val_tn: 216.0000 - val_fn: 624.0000 - val_weighted_accuracy: 0.7409 - val_precision: 0.9595 - val_recall: 0.7292 - val_spcsens: 0.9024 - val_snsspec: 0.7778\n",
      "decay: 0.8200000000000001 >> lr: 0.000246\n",
      "Epoch 37/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.4619 - tp: 7063.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 2148.0000 - weighted_accuracy: 0.9734 - precision: 0.9999 - recall: 0.7668 - spcsens: 1.0000 - snsspec: 0.9780 - val_loss: 0.8275 - val_tp: 1638.0000 - val_fp: 66.0000 - val_tn: 221.0000 - val_fn: 666.0000 - val_weighted_accuracy: 0.7405 - val_precision: 0.9613 - val_recall: 0.7109 - val_spcsens: 0.9164 - val_snsspec: 0.7852\n",
      "decay: 0.815 >> lr: 0.0002445\n",
      "Epoch 38/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.4637 - tp: 6983.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2228.0000 - weighted_accuracy: 0.9717 - precision: 0.9997 - recall: 0.7581 - spcsens: 1.0000 - snsspec: 0.9780 - val_loss: 0.8196 - val_tp: 1687.0000 - val_fp: 69.0000 - val_tn: 218.0000 - val_fn: 617.0000 - val_weighted_accuracy: 0.7459 - val_precision: 0.9607 - val_recall: 0.7322 - val_spcsens: 0.9059 - val_snsspec: 0.7730\n",
      "decay: 0.81 >> lr: 0.000243\n",
      "Epoch 39/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.4607 - tp: 7050.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 2161.0000 - weighted_accuracy: 0.9709 - precision: 0.9994 - recall: 0.7654 - spcsens: 1.0000 - snsspec: 0.9803 - val_loss: 0.8260 - val_tp: 1655.0000 - val_fp: 67.0000 - val_tn: 220.0000 - val_fn: 649.0000 - val_weighted_accuracy: 0.7424 - val_precision: 0.9611 - val_recall: 0.7183 - val_spcsens: 0.9024 - val_snsspec: 0.7826\n",
      "decay: 0.8049999999999999 >> lr: 0.00024149999999999996\n",
      "Epoch 40/200\n",
      "10360/10360 [==============================] - 6s 601us/sample - loss: 0.4486 - tp: 7118.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2093.0000 - weighted_accuracy: 0.9733 - precision: 0.9997 - recall: 0.7728 - spcsens: 1.0000 - snsspec: 0.9799 - val_loss: 0.8155 - val_tp: 1713.0000 - val_fp: 71.0000 - val_tn: 216.0000 - val_fn: 591.0000 - val_weighted_accuracy: 0.7480 - val_precision: 0.9602 - val_recall: 0.7435 - val_spcsens: 0.8920 - val_snsspec: 0.7821\n",
      "decay: 0.8 >> lr: 0.00023999999999999998\n",
      "Epoch 41/200\n",
      "10360/10360 [==============================] - 6s 603us/sample - loss: 0.4478 - tp: 7137.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 2074.0000 - weighted_accuracy: 0.9727 - precision: 0.9996 - recall: 0.7748 - spcsens: 0.9991 - snsspec: 0.9813 - val_loss: 0.8181 - val_tp: 1701.0000 - val_fp: 75.0000 - val_tn: 212.0000 - val_fn: 603.0000 - val_weighted_accuracy: 0.7385 - val_precision: 0.9578 - val_recall: 0.7383 - val_spcsens: 0.8920 - val_snsspec: 0.7852\n",
      "decay: 0.795 >> lr: 0.0002385\n",
      "Epoch 42/200\n",
      "10360/10360 [==============================] - 6s 605us/sample - loss: 0.4490 - tp: 7104.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2107.0000 - weighted_accuracy: 0.9731 - precision: 0.9997 - recall: 0.7713 - spcsens: 0.9991 - snsspec: 0.9807 - val_loss: 0.8316 - val_tp: 1684.0000 - val_fp: 71.0000 - val_tn: 216.0000 - val_fn: 620.0000 - val_weighted_accuracy: 0.7418 - val_precision: 0.9595 - val_recall: 0.7309 - val_spcsens: 0.9024 - val_snsspec: 0.7739\n",
      "decay: 0.79 >> lr: 0.000237\n",
      "Epoch 43/200\n",
      "10360/10360 [==============================] - 6s 611us/sample - loss: 0.4339 - tp: 7221.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 1990.0000 - weighted_accuracy: 0.9737 - precision: 0.9996 - recall: 0.7840 - spcsens: 1.0000 - snsspec: 0.9823 - val_loss: 0.8339 - val_tp: 1636.0000 - val_fp: 62.0000 - val_tn: 225.0000 - val_fn: 668.0000 - val_weighted_accuracy: 0.7470 - val_precision: 0.9635 - val_recall: 0.7101 - val_spcsens: 0.8955 - val_snsspec: 0.7878\n",
      "decay: 0.785 >> lr: 0.00023549999999999998\n",
      "Epoch 44/200\n",
      "10360/10360 [==============================] - 6s 605us/sample - loss: 0.4372 - tp: 7174.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 2037.0000 - weighted_accuracy: 0.9740 - precision: 0.9997 - recall: 0.7789 - spcsens: 0.9991 - snsspec: 0.9859 - val_loss: 0.8469 - val_tp: 1630.0000 - val_fp: 66.0000 - val_tn: 221.0000 - val_fn: 674.0000 - val_weighted_accuracy: 0.7387 - val_precision: 0.9611 - val_recall: 0.7075 - val_spcsens: 0.8990 - val_snsspec: 0.7691\n",
      "decay: 0.78 >> lr: 0.000234\n",
      "Epoch 45/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.4270 - tp: 7284.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 1927.0000 - weighted_accuracy: 0.9745 - precision: 0.9996 - recall: 0.7908 - spcsens: 1.0000 - snsspec: 0.9844 - val_loss: 0.8152 - val_tp: 1730.0000 - val_fp: 82.0000 - val_tn: 205.0000 - val_fn: 574.0000 - val_weighted_accuracy: 0.7326 - val_precision: 0.9547 - val_recall: 0.7509 - val_spcsens: 0.8990 - val_snsspec: 0.7656\n",
      "decay: 0.775 >> lr: 0.00023249999999999999\n",
      "Epoch 46/200\n",
      "10360/10360 [==============================] - 6s 603us/sample - loss: 0.4317 - tp: 7281.0000 - fp: 5.0000 - tn: 1144.0000 - fn: 1930.0000 - weighted_accuracy: 0.9729 - precision: 0.9993 - recall: 0.7905 - spcsens: 0.9991 - snsspec: 0.9857 - val_loss: 0.8071 - val_tp: 1761.0000 - val_fp: 85.0000 - val_tn: 202.0000 - val_fn: 543.0000 - val_weighted_accuracy: 0.7341 - val_precision: 0.9540 - val_recall: 0.7643 - val_spcsens: 0.9024 - val_snsspec: 0.7734\n",
      "decay: 0.77 >> lr: 0.00023099999999999998\n",
      "Epoch 47/200\n",
      "10360/10360 [==============================] - 6s 605us/sample - loss: 0.4304 - tp: 7231.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 1980.0000 - weighted_accuracy: 0.9739 - precision: 0.9996 - recall: 0.7850 - spcsens: 1.0000 - snsspec: 0.9845 - val_loss: 0.8254 - val_tp: 1654.0000 - val_fp: 66.0000 - val_tn: 221.0000 - val_fn: 650.0000 - val_weighted_accuracy: 0.7439 - val_precision: 0.9616 - val_recall: 0.7179 - val_spcsens: 0.9059 - val_snsspec: 0.7986\n",
      "decay: 0.765 >> lr: 0.0002295\n",
      "Epoch 48/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.4226 - tp: 7298.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 1913.0000 - weighted_accuracy: 0.9739 - precision: 0.9995 - recall: 0.7923 - spcsens: 1.0000 - snsspec: 0.9855 - val_loss: 0.8157 - val_tp: 1724.0000 - val_fp: 79.0000 - val_tn: 208.0000 - val_fn: 580.0000 - val_weighted_accuracy: 0.7365 - val_precision: 0.9562 - val_recall: 0.7483 - val_spcsens: 0.8955 - val_snsspec: 0.7769\n",
      "decay: 0.76 >> lr: 0.00022799999999999999\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10360/10360 [==============================] - 6s 601us/sample - loss: 0.4171 - tp: 7378.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 1833.0000 - weighted_accuracy: 0.9749 - precision: 0.9995 - recall: 0.8010 - spcsens: 1.0000 - snsspec: 0.9866 - val_loss: 0.8060 - val_tp: 1747.0000 - val_fp: 79.0000 - val_tn: 208.0000 - val_fn: 557.0000 - val_weighted_accuracy: 0.7415 - val_precision: 0.9567 - val_recall: 0.7582 - val_spcsens: 0.9094 - val_snsspec: 0.7865\n",
      "decay: 0.755 >> lr: 0.00022649999999999998\n",
      "Epoch 50/200\n",
      "10360/10360 [==============================] - 6s 601us/sample - loss: 0.4252 - tp: 7280.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 1931.0000 - weighted_accuracy: 0.9737 - precision: 0.9995 - recall: 0.7904 - spcsens: 0.9991 - snsspec: 0.9863 - val_loss: 0.8311 - val_tp: 1672.0000 - val_fp: 68.0000 - val_tn: 219.0000 - val_fn: 632.0000 - val_weighted_accuracy: 0.7444 - val_precision: 0.9609 - val_recall: 0.7257 - val_spcsens: 0.8990 - val_snsspec: 0.7834\n",
      "decay: 0.75 >> lr: 0.000225\n",
      "Epoch 51/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.4124 - tp: 7401.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 1810.0000 - weighted_accuracy: 0.9775 - precision: 0.9999 - recall: 0.8035 - spcsens: 1.0000 - snsspec: 0.9879 - val_loss: 0.8166 - val_tp: 1708.0000 - val_fp: 71.0000 - val_tn: 216.0000 - val_fn: 596.0000 - val_weighted_accuracy: 0.7470 - val_precision: 0.9601 - val_recall: 0.7413 - val_spcsens: 0.8955 - val_snsspec: 0.7882\n",
      "decay: 0.745 >> lr: 0.00022349999999999998\n",
      "Epoch 52/200\n",
      "10360/10360 [==============================] - 6s 603us/sample - loss: 0.4042 - tp: 7427.0000 - fp: 0.0000e+00 - tn: 1149.0000 - fn: 1784.0000 - weighted_accuracy: 0.9785 - precision: 1.0000 - recall: 0.8063 - spcsens: 1.0000 - snsspec: 0.9875 - val_loss: 0.8112 - val_tp: 1773.0000 - val_fp: 81.0000 - val_tn: 206.0000 - val_fn: 531.0000 - val_weighted_accuracy: 0.7437 - val_precision: 0.9563 - val_recall: 0.7695 - val_spcsens: 0.9129 - val_snsspec: 0.7852\n",
      "decay: 0.74 >> lr: 0.00022199999999999998\n",
      "Epoch 53/200\n",
      "10360/10360 [==============================] - 6s 601us/sample - loss: 0.3995 - tp: 7507.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 1704.0000 - weighted_accuracy: 0.9772 - precision: 0.9996 - recall: 0.8150 - spcsens: 1.0000 - snsspec: 0.9879 - val_loss: 0.8144 - val_tp: 1744.0000 - val_fp: 82.0000 - val_tn: 205.0000 - val_fn: 560.0000 - val_weighted_accuracy: 0.7356 - val_precision: 0.9551 - val_recall: 0.7569 - val_spcsens: 0.8990 - val_snsspec: 0.7778\n",
      "decay: 0.735 >> lr: 0.00022049999999999997\n",
      "Epoch 54/200\n",
      "10360/10360 [==============================] - 6s 603us/sample - loss: 0.4012 - tp: 7478.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 1733.0000 - weighted_accuracy: 0.9776 - precision: 0.9997 - recall: 0.8119 - spcsens: 0.9991 - snsspec: 0.9886 - val_loss: 0.8220 - val_tp: 1749.0000 - val_fp: 89.0000 - val_tn: 198.0000 - val_fn: 555.0000 - val_weighted_accuracy: 0.7245 - val_precision: 0.9516 - val_recall: 0.7591 - val_spcsens: 0.8850 - val_snsspec: 0.7565\n",
      "decay: 0.73 >> lr: 0.00021899999999999998\n",
      "Epoch 55/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.3966 - tp: 7528.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 1683.0000 - weighted_accuracy: 0.9767 - precision: 0.9995 - recall: 0.8173 - spcsens: 1.0000 - snsspec: 0.9903 - val_loss: 0.8255 - val_tp: 1672.0000 - val_fp: 73.0000 - val_tn: 214.0000 - val_fn: 632.0000 - val_weighted_accuracy: 0.7357 - val_precision: 0.9582 - val_recall: 0.7257 - val_spcsens: 0.8990 - val_snsspec: 0.7587\n",
      "decay: 0.725 >> lr: 0.00021749999999999997\n",
      "Epoch 56/200\n",
      "10360/10360 [==============================] - 6s 601us/sample - loss: 0.4029 - tp: 7441.0000 - fp: 5.0000 - tn: 1144.0000 - fn: 1770.0000 - weighted_accuracy: 0.9748 - precision: 0.9993 - recall: 0.8078 - spcsens: 0.9991 - snsspec: 0.9910 - val_loss: 0.8107 - val_tp: 1804.0000 - val_fp: 91.0000 - val_tn: 196.0000 - val_fn: 500.0000 - val_weighted_accuracy: 0.7330 - val_precision: 0.9520 - val_recall: 0.7830 - val_spcsens: 0.9059 - val_snsspec: 0.7713\n",
      "decay: 0.72 >> lr: 0.00021599999999999996\n",
      "Epoch 57/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.3998 - tp: 7489.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 1722.0000 - weighted_accuracy: 0.9770 - precision: 0.9996 - recall: 0.8130 - spcsens: 0.9991 - snsspec: 0.9890 - val_loss: 0.8165 - val_tp: 1723.0000 - val_fp: 79.0000 - val_tn: 208.0000 - val_fn: 581.0000 - val_weighted_accuracy: 0.7363 - val_precision: 0.9562 - val_recall: 0.7478 - val_spcsens: 0.9164 - val_snsspec: 0.7648\n",
      "decay: 0.7150000000000001 >> lr: 0.0002145\n",
      "Epoch 58/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.3849 - tp: 7569.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 1642.0000 - weighted_accuracy: 0.9787 - precision: 0.9997 - recall: 0.8217 - spcsens: 1.0000 - snsspec: 0.9913 - val_loss: 0.8232 - val_tp: 1759.0000 - val_fp: 84.0000 - val_tn: 203.0000 - val_fn: 545.0000 - val_weighted_accuracy: 0.7354 - val_precision: 0.9544 - val_recall: 0.7635 - val_spcsens: 0.9059 - val_snsspec: 0.7717\n",
      "decay: 0.71 >> lr: 0.00021299999999999997\n",
      "Epoch 59/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.3891 - tp: 7612.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 1599.0000 - weighted_accuracy: 0.9784 - precision: 0.9996 - recall: 0.8264 - spcsens: 1.0000 - snsspec: 0.9926 - val_loss: 0.8225 - val_tp: 1763.0000 - val_fp: 82.0000 - val_tn: 205.0000 - val_fn: 541.0000 - val_weighted_accuracy: 0.7397 - val_precision: 0.9556 - val_recall: 0.7652 - val_spcsens: 0.9094 - val_snsspec: 0.7908\n",
      "decay: 0.7050000000000001 >> lr: 0.0002115\n",
      "Epoch 60/200\n",
      "10360/10360 [==============================] - 6s 604us/sample - loss: 0.3931 - tp: 7520.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 1691.0000 - weighted_accuracy: 0.9781 - precision: 0.9997 - recall: 0.8164 - spcsens: 0.9991 - snsspec: 0.9920 - val_loss: 0.8145 - val_tp: 1741.0000 - val_fp: 81.0000 - val_tn: 206.0000 - val_fn: 563.0000 - val_weighted_accuracy: 0.7367 - val_precision: 0.9555 - val_recall: 0.7556 - val_spcsens: 0.9024 - val_snsspec: 0.7852\n",
      "decay: 0.7 >> lr: 0.00020999999999999998\n",
      "Epoch 61/200\n",
      "10360/10360 [==============================] - 6s 612us/sample - loss: 0.3875 - tp: 7569.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 1642.0000 - weighted_accuracy: 0.9772 - precision: 0.9995 - recall: 0.8217 - spcsens: 1.0000 - snsspec: 0.9913 - val_loss: 0.8147 - val_tp: 1763.0000 - val_fp: 81.0000 - val_tn: 206.0000 - val_fn: 541.0000 - val_weighted_accuracy: 0.7415 - val_precision: 0.9561 - val_recall: 0.7652 - val_spcsens: 0.9059 - val_snsspec: 0.7886\n",
      "decay: 0.6950000000000001 >> lr: 0.0002085\n",
      "Epoch 62/200\n",
      "10360/10360 [==============================] - 7s 648us/sample - loss: 0.3843 - tp: 7598.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 1613.0000 - weighted_accuracy: 0.9791 - precision: 0.9997 - recall: 0.8249 - spcsens: 0.9991 - snsspec: 0.9933 - val_loss: 0.8135 - val_tp: 1769.0000 - val_fp: 83.0000 - val_tn: 204.0000 - val_fn: 535.0000 - val_weighted_accuracy: 0.7393 - val_precision: 0.9552 - val_recall: 0.7678 - val_spcsens: 0.8990 - val_snsspec: 0.7856\n",
      "decay: 0.69 >> lr: 0.00020699999999999996\n",
      "Epoch 63/200\n",
      "10360/10360 [==============================] - 7s 689us/sample - loss: 0.3816 - tp: 7601.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 1610.0000 - weighted_accuracy: 0.9791 - precision: 0.9997 - recall: 0.8252 - spcsens: 1.0000 - snsspec: 0.9921 - val_loss: 0.8175 - val_tp: 1771.0000 - val_fp: 84.0000 - val_tn: 203.0000 - val_fn: 533.0000 - val_weighted_accuracy: 0.7380 - val_precision: 0.9547 - val_recall: 0.7687 - val_spcsens: 0.9059 - val_snsspec: 0.7847\n",
      "decay: 0.685 >> lr: 0.0002055\n",
      "Epoch 64/200\n",
      "10360/10360 [==============================] - 7s 674us/sample - loss: 0.3832 - tp: 7630.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 1581.0000 - weighted_accuracy: 0.9779 - precision: 0.9995 - recall: 0.8284 - spcsens: 0.9991 - snsspec: 0.9924 - val_loss: 0.8209 - val_tp: 1717.0000 - val_fp: 76.0000 - val_tn: 211.0000 - val_fn: 587.0000 - val_weighted_accuracy: 0.7402 - val_precision: 0.9576 - val_recall: 0.7452 - val_spcsens: 0.9094 - val_snsspec: 0.7756\n",
      "decay: 0.6799999999999999 >> lr: 0.00020399999999999997\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10360/10360 [==============================] - 6s 606us/sample - loss: 0.3775 - tp: 7659.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 1552.0000 - weighted_accuracy: 0.9798 - precision: 0.9997 - recall: 0.8315 - spcsens: 1.0000 - snsspec: 0.9937 - val_loss: 0.8064 - val_tp: 1815.0000 - val_fp: 86.0000 - val_tn: 201.0000 - val_fn: 489.0000 - val_weighted_accuracy: 0.7441 - val_precision: 0.9548 - val_recall: 0.7878 - val_spcsens: 0.9059 - val_snsspec: 0.7878\n",
      "decay: 0.675 >> lr: 0.0002025\n",
      "Epoch 66/200\n",
      "10360/10360 [==============================] - 7s 637us/sample - loss: 0.3663 - tp: 7726.0000 - fp: 1.0000 - tn: 1148.0000 - fn: 1485.0000 - weighted_accuracy: 0.9814 - precision: 0.9999 - recall: 0.8388 - spcsens: 1.0000 - snsspec: 0.9940 - val_loss: 0.8159 - val_tp: 1806.0000 - val_fp: 88.0000 - val_tn: 199.0000 - val_fn: 498.0000 - val_weighted_accuracy: 0.7386 - val_precision: 0.9535 - val_recall: 0.7839 - val_spcsens: 0.9094 - val_snsspec: 0.7704- tn: 409.0000 - fn: 462.0000 - weighted_accu\n",
      "decay: 0.6699999999999999 >> lr: 0.00020099999999999995\n",
      "Epoch 67/200\n",
      "10360/10360 [==============================] - 7s 627us/sample - loss: 0.3728 - tp: 7734.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 1477.0000 - weighted_accuracy: 0.9799 - precision: 0.9996 - recall: 0.8396 - spcsens: 0.9991 - snsspec: 0.9925 - val_loss: 0.8131 - val_tp: 1816.0000 - val_fp: 90.0000 - val_tn: 197.0000 - val_fn: 488.0000 - val_weighted_accuracy: 0.7373 - val_precision: 0.9528 - val_recall: 0.7882 - val_spcsens: 0.9024 - val_snsspec: 0.7747\n",
      "decay: 0.665 >> lr: 0.0001995\n",
      "Epoch 68/200\n",
      "10360/10360 [==============================] - 6s 624us/sample - loss: 0.3758 - tp: 7640.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 1571.0000 - weighted_accuracy: 0.9780 - precision: 0.9995 - recall: 0.8294 - spcsens: 1.0000 - snsspec: 0.9933 - val_loss: 0.8145 - val_tp: 1804.0000 - val_fp: 95.0000 - val_tn: 192.0000 - val_fn: 500.0000 - val_weighted_accuracy: 0.7260 - val_precision: 0.9500 - val_recall: 0.7830 - val_spcsens: 0.8955 - val_snsspec: 0.7635\n",
      "decay: 0.6599999999999999 >> lr: 0.00019799999999999996\n",
      "Epoch 69/200\n",
      "10360/10360 [==============================] - 7s 629us/sample - loss: 0.3715 - tp: 7651.0000 - fp: 4.0000 - tn: 1145.0000 - fn: 1560.0000 - weighted_accuracy: 0.9781 - precision: 0.9995 - recall: 0.8306 - spcsens: 1.0000 - snsspec: 0.9939 - val_loss: 0.8191 - val_tp: 1806.0000 - val_fp: 95.0000 - val_tn: 192.0000 - val_fn: 498.0000 - val_weighted_accuracy: 0.7264 - val_precision: 0.9500 - val_recall: 0.7839 - val_spcsens: 0.8920 - val_snsspec: 0.7582\n",
      "decay: 0.655 >> lr: 0.00019649999999999998\n",
      "Epoch 70/200\n",
      "10360/10360 [==============================] - 6s 623us/sample - loss: 0.3542 - tp: 7794.0000 - fp: 3.0000 - tn: 1146.0000 - fn: 1417.0000 - weighted_accuracy: 0.9806 - precision: 0.9996 - recall: 0.8462 - spcsens: 1.0000 - snsspec: 0.9946 - val_loss: 0.8294 - val_tp: 1755.0000 - val_fp: 89.0000 - val_tn: 198.0000 - val_fn: 549.0000 - val_weighted_accuracy: 0.7258 - val_precision: 0.9517 - val_recall: 0.7617 - val_spcsens: 0.8990 - val_snsspec: 0.7556\n",
      "decay: 0.65 >> lr: 0.000195\n",
      "Epoch 71/200\n",
      "10360/10360 [==============================] - 7s 634us/sample - loss: 0.3492 - tp: 7809.0000 - fp: 2.0000 - tn: 1147.0000 - fn: 1402.0000 - weighted_accuracy: 0.9816 - precision: 0.9997 - recall: 0.8478 - spcsens: 1.0000 - snsspec: 0.9944 - val_loss: 0.8184 - val_tp: 1864.0000 - val_fp: 101.0000 - val_tn: 186.0000 - val_fn: 440.0000 - val_weighted_accuracy: 0.7286 - val_precision: 0.9486 - val_recall: 0.8090 - val_spcsens: 0.8990 - val_snsspec: 0.7574\n",
      "decay: 0.645 >> lr: 0.0001935\n",
      "Epoch 72/200\n",
      " 8640/10360 [========================>.....] - ETA: 1s - loss: 0.3593 - tp: 6530.0000 - fp: 3.0000 - tn: 957.0000 - fn: 1150.0000 - weighted_accuracy: 0.9807 - precision: 0.9995 - recall: 0.8503 - spcsens: 1.0000 - snsspec: 0.9936"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-aa604b2c4b12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m      \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# The class weights go here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     class_weight=class_weight) \n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weighted_history = weighted_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    sample_weight=train_sample_weights,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "   callbacks = [early_stopping,model_checkpoint,lrscheduler],\n",
    "     validation_data=(X_val, y_val,val_sample_weights),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "\n",
    "#plot_graphs(weighted_history, \"binacc\")\n",
    "plot_graphs(weighted_history, \"weighted_accuracy\")\n",
    "plot_graphs(weighted_history, \"loss\")\n",
    "plot_graphs(weighted_history, \"precision\")\n",
    "plot_graphs(weighted_history, \"spcsens\")\n",
    "plot_graphs(weighted_history, \"snsspec\")\n",
    "plot_graphs(weighted_history, \"fp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_predictions_weighted = weighted_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "#test_predictions_weighted = weighted_model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_results = weighted_model.evaluate(X_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0,sample_weight=test_sample_weights)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "print(\"sensitivity:\",weighted_results[3]/(weighted_results[2]+weighted_results[3]))\n",
    "#plot_cm(y_test, test_predictions_weighted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCHS = 200;BATCH_SIZE = 32;NEURONS=240;act='linear'\n",
    "loss :  0.9864012012057539\n",
    "tp :  903.0\n",
    "fp :  32.0\n",
    "tn :  127.0\n",
    "fn :  377.0\n",
    "weighted_accuracy :  0.7520231\n",
    "precision :  0.96577543\n",
    "recall :  0.7054688\n",
    "spcsens :  0.9056604\n",
    "snsspec :  0.821875\n",
    "weighted_accuracy :  0.7520231\n",
    "\n",
    "sensitivity: 0.7987421\n",
    "\n",
    "\n",
    "EPOCHS = 200;BATCH_SIZE = 32;NEURONS=280\n",
    "\n",
    "\n",
    "loss :  0.9741253216619538\n",
    "tp :  837.0\n",
    "fp :  29.0\n",
    "tn :  130.0\n",
    "fn :  443.0\n",
    "weighted_accuracy :  0.7356135\n",
    "precision :  0.9665127\n",
    "recall :  0.6539062\n",
    "spcsens :  0.9056604\n",
    "snsspec :  0.828125\n",
    "weighted_accuracy :  0.7356135\n",
    "\n",
    "sensitivity: 0.8176101\n",
    "\n",
    "\n",
    "EPOCHS = 200;BATCH_SIZE = 32;NEURONS=240;act='relu'\n",
    "\n",
    "loss :  0.8104747441015449\n",
    "tp :  865.0\n",
    "fp :  31.0\n",
    "tn :  128.0\n",
    "fn :  415.0\n",
    "weighted_accuracy :  0.7402924\n",
    "precision :  0.96540177\n",
    "recall :  0.67578125\n",
    "spcsens :  0.918239\n",
    "snsspec :  0.8453125\n",
    "weighted_accuracy :  0.7402924\n",
    "\n",
    "sensitivity: 0.8050314\n",
    "\n",
    "EPOCHS = 200;BATCH_SIZE = 32;NEURONS=240;act='relu'; val_size=0.2\n",
    "\n",
    "loss :  0.8032975160388005\n",
    "tp :  934.0\n",
    "fp :  35.0\n",
    "tn :  124.0\n",
    "fn :  346.0\n",
    "weighted_accuracy :  0.7547364\n",
    "precision :  0.9638803\n",
    "recall :  0.7296875\n",
    "spcsens :  0.9119497\n",
    "snsspec :  0.8390625\n",
    "weighted_accuracy :  0.7547364\n",
    "\n",
    "sensitivity: 0.7798742\n",
    "\n",
    "1\n",
    "\n",
    "EPOCHS = 200;BATCH_SIZE = 32;NEURONS=240;act='relu'; val_size=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weighted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ld_model=keras.models.load_model(r\"D:\\work\\SavedModels\\Tweedy\\Ckpt\\chkpntwghts.158-0.7733.hdf5\")\n",
    "#chkpntwghts.44-0.7479.hdf5\n",
    "ld_model_results = ld_model.evaluate(X_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0,sample_weight=test_sample_weights)\n",
    "for name, value in zip(weighted_model.metrics_names, ld_model_results ):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(954*.56+127*4.54)/((954*.56+127*4.54)+31*4.54+326*.56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ct = datetime.now()\n",
    "ct=('Model_'+str(ct.month).zfill(2)+str(ct.day).zfill(2)+'_'+str(ct.hour).zfill(2)+str(ct.minute).zfill(2))\n",
    "print(ct)\n",
    "weighted_model.save(\"D:\\\\work\\\\SavedModels\\\\Tweedy\\\\Techmodels\\\\\"+ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/tensorflow/blob/f45d6083b766183e045552dafa8e46586eb3d4fc/tensorflow/python/keras/metrics.py#L1500\n",
    "\n",
    "    \n",
    "\n",
    "@keras_export('keras.metrics.SensitivityAtSpecificity')\n",
    "class SensitivityAtSpecificity(SensitivitySpecificityBase):\n",
    "  \"\"\"Computes best sensitivity where specificity is >= specified value.\n",
    "  the sensitivity at a given specificity.\n",
    "  `Sensitivity` measures the proportion of actual positives that are correctly\n",
    "  identified as such (tp / (tp + fn)).\n",
    "  `Specificity` measures the proportion of actual negatives that are correctly\n",
    "  identified as such (tn / (tn + fp)).\n",
    "  This metric creates four local variables, `true_positives`, `true_negatives`,\n",
    "  `false_positives` and `false_negatives` that are used to compute the\n",
    "  sensitivity at the given specificity. The threshold for the given specificity\n",
    "  value is computed and used to evaluate the corresponding sensitivity.\n",
    "  If `sample_weight` is `None`, weights default to 1.\n",
    "  Use `sample_weight` of 0 to mask values.\n",
    "  For additional information about specificity and sensitivity, see\n",
    "  [the following](https://en.wikipedia.org/wiki/Sensitivity_and_specificity).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
